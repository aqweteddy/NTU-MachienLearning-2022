{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AFEKWoh3p1Mv"
   },
   "source": [
    "# Homework Description\n",
    "- English to Chinese (Traditional) Translation\n",
    "  - Input: an English sentence         (e.g.\t\ttom is a student .)\n",
    "  - Output: the Chinese translation  (e.g. \t\t湯姆 是 個 學生 。)\n",
    "\n",
    "- TODO\n",
    "    - Train a simple RNN seq2seq to acheive translation\n",
    "    - Switch to transformer model to boost performance\n",
    "    - Apply Back-translation to furthur boost performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "3Vf1Q79XPQ3D"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Apr  2 14:23:32 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.103.01   Driver Version: 470.103.01   CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0 Off |                  N/A |\n",
      "| 32%   41C    P8    20W / 250W |    166MiB / 11016MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A       955      G   /usr/lib/xorg/Xorg                142MiB |\n",
      "|    0   N/A  N/A      1317      G   cinnamon                           22MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "59neB_Sxp5Ub"
   },
   "source": [
    "# Download and import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "rRlFbfFRpZYT"
   },
   "outputs": [],
   "source": [
    "# !pip install 'torch>=1.6.0' editdistance matplotlib sacrebleu sacremoses sentencepiece tqdm wandb\n",
    "# !pip install --upgrade jupyter ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "fSksMTdmp-Wt"
   },
   "outputs": [],
   "source": [
    "# !git clone https://github.com/pytorch/fairseq.git\n",
    "# !cd fairseq && git checkout 9a1c497\n",
    "# !pip install --upgrade ./fairseq/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "uRLTiuIuqGNc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-02 14:23:33 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pdb\n",
    "import pprint\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "import numpy as np\n",
    "import tqdm as tqdm\n",
    "from pathlib import Path\n",
    "from argparse import Namespace\n",
    "from fairseq import utils\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0n07Za1XqJzA"
   },
   "source": [
    "# Fix random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "xllxxyWxqI7s"
   },
   "outputs": [],
   "source": [
    "seed = 73\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  \n",
    "np.random.seed(seed)  \n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N5ORDJ-2qdYw"
   },
   "source": [
    "# Dataset\n",
    "\n",
    "## En-Zh Bilingual Parallel Corpus\n",
    "* [TED2020](#reimers-2020-multilingual-sentence-bert)\n",
    "    - Raw: 398,066 (sentences)   \n",
    "    - Processed: 393,980 (sentences)\n",
    "    \n",
    "\n",
    "## Testdata\n",
    "- Size: 4,000 (sentences)\n",
    "- **Chinese translation is undisclosed. The provided (.zh) file is psuedo translation, each line is a '。'**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GQw2mY4Dqkzd"
   },
   "source": [
    "## Dataset Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "SXT42xQtqijD"
   },
   "outputs": [],
   "source": [
    "data_dir = './DATA/rawdata'\n",
    "dataset_name = 'ted2020'\n",
    "urls = (\n",
    "    \"https://github.com/yuhsinchan/ML2022-HW5Dataset/releases/download/v1.0.2/ted2020.tgz\",\n",
    "    \"https://github.com/yuhsinchan/ML2022-HW5Dataset/releases/download/v1.0.2/test.tgz\",\n",
    ")\n",
    "file_names = (\n",
    "    'ted2020.tgz', # train & dev\n",
    "    'test.tgz', # test\n",
    ")\n",
    "prefix = Path(data_dir).absolute() / dataset_name\n",
    "\n",
    "# prefix.mkdir(parents=True, exist_ok=True)\n",
    "# for u, f in zip(urls, file_names):\n",
    "#     path = prefix/f\n",
    "#     if not path.exists():\n",
    "#         !wget {u} -O {path}\n",
    "#     if path.suffix == \".tgz\":\n",
    "#         !tar -xvf {path} -C {prefix}\n",
    "#     elif path.suffix == \".zip\":\n",
    "#         !unzip -o {path} -d {prefix}\n",
    "# !mv {prefix/'raw.en'} {prefix/'train_dev.raw.en'}\n",
    "# !mv {prefix/'raw.zh'} {prefix/'train_dev.raw.zh'}\n",
    "# !mv {prefix/'test/test.en'} {prefix/'test.raw.en'}\n",
    "# !mv {prefix/'test/test.zh'} {prefix/'test.raw.zh'}\n",
    "# !rm -rf {prefix/'test'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YLkJwNiFrIwZ"
   },
   "source": [
    "## Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "_uJYkCncrKJb"
   },
   "outputs": [],
   "source": [
    "src_lang = 'zh'\n",
    "tgt_lang = 'en'\n",
    "\n",
    "data_prefix = f'{prefix}/train_dev.raw'\n",
    "test_prefix = f'{prefix}/test.raw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "0t2CPt1brOT3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "非常謝謝你，克里斯。能有這個機會第二度踏上這個演講台\n",
      "真是一大榮幸。我非常感激。\n",
      "這個研討會給我留下了極為深刻的印象，我想感謝大家 對我之前演講的好評。\n",
      "我是由衷的想這麼說，有部份原因是因為 —— 我真的有需要!\n",
      "請你們設身處地為我想一想！\n",
      "Thank you so much, Chris.\n",
      "And it's truly a great honor to have the opportunity to come to this stage twice; I'm extremely grateful.\n",
      "I have been blown away by this conference, and I want to thank all of you for the many nice comments about what I had to say the other night.\n",
      "And I say that sincerely, partly because  I need that.\n",
      "Put yourselves in my position.\n"
     ]
    }
   ],
   "source": [
    "!head {data_prefix+'.'+src_lang} -n 5\n",
    "!head {data_prefix+'.'+tgt_lang} -n 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pRoE9UK7r1gY"
   },
   "source": [
    "## Preprocess files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "3tzFwtnFrle3"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def strQ2B(ustring):\n",
    "    \"\"\"Full width -> half width\"\"\"\n",
    "    # reference:https://ithelp.ithome.com.tw/articles/10233122\n",
    "    ss = []\n",
    "    for s in ustring:\n",
    "        rstring = \"\"\n",
    "        for uchar in s:\n",
    "            inside_code = ord(uchar)\n",
    "            if inside_code == 12288:  # Full width space: direct conversion\n",
    "                inside_code = 32\n",
    "            elif (inside_code >= 65281 and inside_code <= 65374):  # Full width chars (except space) conversion\n",
    "                inside_code -= 65248\n",
    "            rstring += chr(inside_code)\n",
    "        ss.append(rstring)\n",
    "    return ''.join(ss)\n",
    "                \n",
    "def clean_s(s, lang):\n",
    "    if lang == 'en':\n",
    "        s = re.sub(r\"\\([^()]*\\)\", \"\", s) # remove ([text])\n",
    "        s = s.replace('-', '') # remove '-'\n",
    "        s = re.sub('([.,;!?()\\\"])', r' \\1 ', s) # keep punctuation\n",
    "    elif lang == 'zh':\n",
    "        s = strQ2B(s) # Q2B\n",
    "        s = re.sub(r\"\\([^()]*\\)\", \"\", s) # remove ([text])\n",
    "        s = s.replace(' ', '')\n",
    "        s = s.replace('—', '')\n",
    "        s = s.replace('“', '\"')\n",
    "        s = s.replace('”', '\"')\n",
    "        s = s.replace('_', '')\n",
    "        s = re.sub('([。,;!?()\\\"~「」])', r' \\1 ', s) # keep punctuation\n",
    "    s = ' '.join(s.strip().split())\n",
    "    return s\n",
    "\n",
    "def len_s(s, lang):\n",
    "    if lang == 'zh':\n",
    "        return len(s)\n",
    "    return len(s.split())\n",
    "\n",
    "def clean_corpus(prefix, l1, l2, ratio=9, max_len=1000, min_len=1):\n",
    "    if Path(f'{prefix}.clean.{l1}').exists() and Path(f'{prefix}.clean.{l2}').exists():\n",
    "        print(f'{prefix}.clean.{l1} & {l2} exists. skipping clean.')\n",
    "        return\n",
    "    with open(f'{prefix}.{l1}', 'r') as l1_in_f:\n",
    "        with open(f'{prefix}.{l2}', 'r') as l2_in_f:\n",
    "            with open(f'{prefix}.clean.{l1}', 'w') as l1_out_f:\n",
    "                with open(f'{prefix}.clean.{l2}', 'w') as l2_out_f:\n",
    "                    for s1 in l1_in_f:\n",
    "                        s1 = s1.strip()\n",
    "                        s2 = l2_in_f.readline().strip()\n",
    "                        s1 = clean_s(s1, l1)\n",
    "                        s2 = clean_s(s2, l2)\n",
    "                        s1_len = len_s(s1, l1)\n",
    "                        s2_len = len_s(s2, l2)\n",
    "                        if min_len > 0: # remove short sentence\n",
    "                            if s1_len < min_len or s2_len < min_len:\n",
    "                                continue\n",
    "                        if max_len > 0: # remove long sentence\n",
    "                            if s1_len > max_len or s2_len > max_len:\n",
    "                                continue\n",
    "                        if ratio > 0: # remove by ratio of length\n",
    "                            if s1_len/s2_len > ratio or s2_len/s1_len > ratio:\n",
    "                                continue\n",
    "                        print(s1, file=l1_out_f)\n",
    "                        print(s2, file=l2_out_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "h_i8b1PRr9Nf"
   },
   "outputs": [],
   "source": [
    "# clean_corpus(data_prefix, src_lang, tgt_lang)\n",
    "# clean_corpus(test_prefix, src_lang, tgt_lang, ratio=-1, min_len=-1, max_len=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "gjT3XCy9r_rj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "非常謝謝你 , 克里斯 。 能有這個機會第二度踏上這個演講台\n",
      "真是一大榮幸 。 我非常感激 。\n",
      "這個研討會給我留下了極為深刻的印象 , 我想感謝大家對我之前演講的好評 。\n",
      "我是由衷的想這麼說 , 有部份原因是因為我真的有需要 !\n",
      "請你們設身處地為我想一想 !\n",
      "Thank you so much , Chris .\n",
      "And it's truly a great honor to have the opportunity to come to this stage twice ; I'm extremely grateful .\n",
      "I have been blown away by this conference , and I want to thank all of you for the many nice comments about what I had to say the other night .\n",
      "And I say that sincerely , partly because I need that .\n",
      "Put yourselves in my position .\n"
     ]
    }
   ],
   "source": [
    "!head {data_prefix+'.clean.'+src_lang} -n 5\n",
    "!head {data_prefix+'.clean.'+tgt_lang} -n 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nKb4u67-sT_Z"
   },
   "source": [
    "## Split into train/valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "AuFKeDz3sGHL"
   },
   "outputs": [],
   "source": [
    "valid_ratio = 0.01 # 3000~4000 would suffice\n",
    "train_ratio = 1 - valid_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "QR2NVldqsXyY"
   },
   "outputs": [],
   "source": [
    "# if (prefix/f'train.clean.{src_lang}').exists() \\\n",
    "# and (prefix/f'train.clean.{tgt_lang}').exists() \\\n",
    "# and (prefix/f'valid.clean.{src_lang}').exists() \\\n",
    "# and (prefix/f'valid.clean.{tgt_lang}').exists():\n",
    "#     print(f'train/valid splits exists. skipping split.')\n",
    "# else:\n",
    "#     line_num = sum(1 for line in open(f'{data_prefix}.clean.{src_lang}'))\n",
    "#     labels = list(range(line_num))\n",
    "#     random.shuffle(labels)\n",
    "#     for lang in [src_lang, tgt_lang]:\n",
    "#         train_f = open(os.path.join(data_dir, dataset_name, f'train.clean.{lang}'), 'w')\n",
    "#         valid_f = open(os.path.join(data_dir, dataset_name, f'valid.clean.{lang}'), 'w')\n",
    "#         count = 0\n",
    "#         for line in open(f'{data_prefix}.clean.{lang}', 'r'):\n",
    "#             if labels[count]/line_num < train_ratio:\n",
    "#                 train_f.write(line)\n",
    "#             else:\n",
    "#                 valid_f.write(line)\n",
    "#             count += 1\n",
    "#         train_f.close()\n",
    "#         valid_f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n1rwQysTsdJq"
   },
   "source": [
    "## Subword Units \n",
    "Out of vocabulary (OOV) has been a major problem in machine translation. This can be alleviated by using subword units.\n",
    "- We will use the [sentencepiece](#kudo-richardson-2018-sentencepiece) package\n",
    "- select 'unigram' or 'byte-pair encoding (BPE)' algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Ecwllsa7sZRA"
   },
   "outputs": [],
   "source": [
    "# import sentencepiece as spm\n",
    "# vocab_size = 8000\n",
    "# if (prefix/f'spm{vocab_size}.model').exists():\n",
    "#     print(f'{prefix}/spm{vocab_size}.model exists. skipping spm_train.')\n",
    "# else:\n",
    "#     spm.SentencePieceTrainer.train(\n",
    "#         input=','.join([f'{prefix}/train.clean.{src_lang}',\n",
    "#                         f'{prefix}/valid.clean.{src_lang}',\n",
    "#                         f'{prefix}/train.clean.{tgt_lang}',\n",
    "#                         f'{prefix}/valid.clean.{tgt_lang}']),\n",
    "#         model_prefix=prefix/f'spm{vocab_size}',\n",
    "#         vocab_size=vocab_size,\n",
    "#         character_coverage=1,\n",
    "#         model_type='unigram', # 'bpe' works as well\n",
    "#         input_sentence_size=1e6,\n",
    "#         shuffle_input_sentence=True,\n",
    "#         normalization_rule_name='nmt_nfkc_cf',\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "lQPRNldqse_V"
   },
   "outputs": [],
   "source": [
    "# spm_model = spm.SentencePieceProcessor(model_file=str(prefix/f'spm{vocab_size}.model'))\n",
    "# in_tag = {\n",
    "#     'train': 'train.clean',\n",
    "#     'valid': 'valid.clean',\n",
    "#     'test': 'test.raw.clean',\n",
    "# }\n",
    "# for split in ['train', 'valid', 'test']:\n",
    "#     for lang in [src_lang, tgt_lang]:\n",
    "#         out_path = prefix/f'{split}.{lang}'\n",
    "#         if out_path.exists():\n",
    "#             print(f\"{out_path} exists. skipping spm_encode.\")\n",
    "#         else:\n",
    "#             with open(prefix/f'{split}.{lang}', 'w') as out_f:\n",
    "#                 with open(prefix/f'{in_tag[split]}.{lang}', 'r') as in_f:\n",
    "#                     for line in in_f:\n",
    "#                         line = line.strip()\n",
    "#                         tok = spm_model.encode(line, out_type=str)\n",
    "#                         print(' '.join(tok), file=out_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "4j6lXHjAsjXa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▁ 非常 謝 謝 你 ▁, ▁ 克 里 斯 ▁。 ▁ 能 有 這個 機會 第二 度 踏 上 這個 演講 台\n",
      "▁ 真 是 一 大 榮 幸 ▁。 ▁我 非常 感 激 ▁。\n",
      "▁這個 研 討 會 給我 留 下 了 極 為 深 刻 的 印 象 ▁, ▁我想 感 謝 大家 對我 之前 演講 的 好 評 ▁。\n",
      "▁我 是由 衷 的 想 這麼 說 ▁, ▁有 部份 原因 是因為 我 真的 有 需要 ▁!\n",
      "▁ 請 你們 設 身 處 地 為 我想 一 想 ▁!\n",
      "▁thank ▁you ▁so ▁much ▁, ▁chris ▁.\n",
      "▁and ▁it ' s ▁ t ru ly ▁a ▁great ▁ho n or ▁to ▁have ▁the ▁ op port un ity ▁to ▁come ▁to ▁this ▁st age ▁ t wi ce ▁; ▁i ' m ▁ex t re me ly ▁gr ate ful ▁.\n",
      "▁i ▁have ▁been ▁ bl ow n ▁away ▁by ▁this ▁con fer ence ▁, ▁and ▁i ▁want ▁to ▁thank ▁all ▁of ▁you ▁for ▁the ▁many ▁ ni ce ▁ com ment s ▁about ▁what ▁i ▁had ▁to ▁say ▁the ▁other ▁night ▁.\n",
      "▁and ▁i ▁say ▁that ▁since re ly ▁, ▁part ly ▁because ▁i ▁need ▁that ▁.\n",
      "▁put ▁your s el ve s ▁in ▁my ▁po s ition ▁.\n"
     ]
    }
   ],
   "source": [
    "!head {data_dir+'/'+dataset_name+'/train.'+src_lang} -n 5\n",
    "!head {data_dir+'/'+dataset_name+'/train.'+tgt_lang} -n 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "59si_C0Wsms7"
   },
   "source": [
    "## Binarize the data with fairseq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "w-cHVLSpsknh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA/data-bin/ted2020 exists, will not overwrite!\n"
     ]
    }
   ],
   "source": [
    "binpath = Path('./DATA/data-bin', dataset_name)\n",
    "if binpath.exists():\n",
    "    print(binpath, \"exists, will not overwrite!\")\n",
    "else:\n",
    "    !python -m fairseq_cli.preprocess \\\n",
    "        --source-lang {src_lang}\\\n",
    "        --target-lang {tgt_lang}\\\n",
    "        --trainpref {prefix/'train'}\\\n",
    "        --validpref {prefix/'valid'}\\\n",
    "        --testpref {prefix/'test'}\\\n",
    "        --destdir {binpath}\\\n",
    "        --joined-dictionary\\\n",
    "        --workers 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "szMuH1SWLPWA"
   },
   "source": [
    "# Configuration for experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "5Luz3_tVLUxs"
   },
   "outputs": [],
   "source": [
    "#! config\n",
    "config = Namespace(\n",
    "    datadir = \"./DATA/data-bin/ted2020\",\n",
    "    savedir = \"./checkpoints/transformer_zh-en\",\n",
    "    source_lang = \"zh\",\n",
    "    target_lang = \"en\",\n",
    "    \n",
    "    # cpu threads when fetching & processing data.\n",
    "    num_workers=10,  \n",
    "    # batch size in terms of tokens. gradient accumulation increases the effective batchsize.\n",
    "    max_tokens=8192,\n",
    "    accum_steps=2,\n",
    "    \n",
    "    # the lr calculated from Noam lr scheduler. you can tune the maximum lr by this factor.\n",
    "    lr_factor=2,\n",
    "    lr_warmup=10000,\n",
    "    lr=5e-4,\n",
    "    \n",
    "    # clipping gradient norm helps alleviate gradient exploding\n",
    "    clip_norm=1.0,\n",
    "    \n",
    "    # maximum epochs for training\n",
    "    max_epoch=40,\n",
    "    start_epoch=1,\n",
    "    \n",
    "    # beam size for beam search\n",
    "    beam=5, \n",
    "    # generate sequences of maximum length ax + b, where x is the source length\n",
    "    max_len_a=1.2, \n",
    "    max_len_b=10, \n",
    "    # when decoding, post process sentence by removing sentencepiece symbols and jieba tokenization.\n",
    "    post_process = \"sentencepiece\",\n",
    "    \n",
    "    # checkpoints\n",
    "    keep_last_epochs=5,\n",
    "    resume=None, # if resume from checkpoint name (under config.savedir)\n",
    "    \n",
    "    # logging\n",
    "    use_wandb=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cjrJFvyQLg86"
   },
   "source": [
    "# Logging\n",
    "- logging package logs ordinary messages\n",
    "- wandb logs the loss, bleu, etc. in the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "-ZiMyDWALbDk"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-02 14:23:36 | ERROR | wandb.jupyter | Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtedli\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/user/homework/ML/hw5/wandb/run-20220402_142337-65mh8trz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/tedli/ml-hw5/runs/65mh8trz\" target=\"_blank\">transformer_zh-en</a></strong> to <a href=\"https://wandb.ai/tedli/ml-hw5\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s | %(levelname)s | %(name)s | %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    "    level=\"INFO\", # \"DEBUG\" \"WARNING\" \"ERROR\"\n",
    "    stream=sys.stdout,\n",
    ")\n",
    "proj = \"ml-hw5\"\n",
    "logger = logging.getLogger(proj)\n",
    "if config.use_wandb:\n",
    "    import wandb\n",
    "    wandb.init(project=proj, name=Path(config.savedir).stem, config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BNoSkK45Lmqc"
   },
   "source": [
    "# CUDA Environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "oqrsbmcoLqMl"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-02 14:23:39 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
      "2022-04-02 14:23:39 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 10.758 GB ; name = NVIDIA GeForce RTX 2080 Ti              \n",
      "2022-04-02 14:23:39 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n"
     ]
    }
   ],
   "source": [
    "cuda_env = utils.CudaEnvironment()\n",
    "utils.CudaEnvironment.pretty_print_cuda_env_list([cuda_env])\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TbJuBIHLLt2D"
   },
   "source": [
    "# Dataloading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oOpG4EBRLwe_"
   },
   "source": [
    "## We borrow the TranslationTask from fairseq\n",
    "* used to load the binarized data created above\n",
    "* well-implemented data iterator (dataloader)\n",
    "* built-in task.source_dictionary and task.target_dictionary are also handy\n",
    "* well-implemented beach search decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "3gSEy1uFLvVs"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-02 14:23:40 | INFO | fairseq.tasks.translation | [zh] dictionary: 8000 types\n",
      "2022-04-02 14:23:40 | INFO | fairseq.tasks.translation | [en] dictionary: 8000 types\n"
     ]
    }
   ],
   "source": [
    "from fairseq.tasks.translation import TranslationConfig, TranslationTask\n",
    "# from fairseq.tasks import translation\n",
    "## setup task\n",
    "task_cfg = TranslationConfig(\n",
    "    data=config.datadir,\n",
    "    source_lang=config.source_lang,\n",
    "    target_lang=config.target_lang,\n",
    "    train_subset=\"train\",\n",
    "    required_seq_len_multiple=8,\n",
    "    dataset_impl=\"mmap\",\n",
    "    upsample_primary=1,\n",
    ")\n",
    "task = TranslationTask.setup_task(task_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "mR7Bhov7L4IU"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-02 14:23:40 | INFO | ml-hw5 | loading data for epoch 1\n",
      "2022-04-02 14:23:40 | INFO | fairseq.data.data_utils | loaded 390,041 examples from: ./DATA/data-bin/ted2020/train.en-zh.zh\n",
      "2022-04-02 14:23:40 | INFO | fairseq.data.data_utils | loaded 390,041 examples from: ./DATA/data-bin/ted2020/train.en-zh.en\n",
      "2022-04-02 14:23:40 | INFO | fairseq.tasks.translation | ./DATA/data-bin/ted2020 train zh-en 390041 examples\n",
      "2022-04-02 14:23:40 | INFO | fairseq.data.data_utils | loaded 3,939 examples from: ./DATA/data-bin/ted2020/valid.en-zh.zh\n",
      "2022-04-02 14:23:40 | INFO | fairseq.data.data_utils | loaded 3,939 examples from: ./DATA/data-bin/ted2020/valid.en-zh.en\n",
      "2022-04-02 14:23:40 | INFO | fairseq.tasks.translation | ./DATA/data-bin/ted2020 valid zh-en 3939 examples\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"loading data for epoch 1\")\n",
    "task.load_dataset(split=\"train\", epoch=1, combine=True) # combine if you have back-translation data.\n",
    "task.load_dataset(split=\"valid\", epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "P0BCEm_9L6ig"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 1,\n",
      " 'source': tensor([ 140,  690,   28,  270,   45,  151, 1142,  660,  606,  369, 3114, 2434,\n",
      "        1434,  192,    2]),\n",
      " 'target': tensor([  18,   14,    6, 2234,   60,   19,   80,    5,  256,   16,  405, 1407,\n",
      "        1706,    7,    2])}\n",
      "'Source: 這實在就是我所做的--光學操控思想'\n",
      "\"Target: that's exactly what i do optical mind control .\"\n"
     ]
    }
   ],
   "source": [
    "sample = task.dataset(\"valid\")[1]\n",
    "pprint.pprint(sample)\n",
    "pprint.pprint(\n",
    "    \"Source: \" + \\\n",
    "    task.source_dictionary.string(\n",
    "        sample['source'],\n",
    "        config.post_process,\n",
    "    )\n",
    ")\n",
    "pprint.pprint(\n",
    "    \"Target: \" + \\\n",
    "    task.target_dictionary.string(\n",
    "        sample['target'],\n",
    "        config.post_process,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UcfCVa2FMBSE"
   },
   "source": [
    "# Dataset iterator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yBvc-B_6MKZM"
   },
   "source": [
    "* Controls every batch to contain no more than N tokens, which optimizes GPU memory efficiency\n",
    "* Shuffles the training set for every epoch\n",
    "* Ignore sentences exceeding maximum length\n",
    "* Pad all sentences in a batch to the same length, which enables parallel computing by GPU\n",
    "* Add eos and shift one token\n",
    "    - teacher forcing: to train the model to predict the next token based on prefix, we feed the right shifted target sequence as the decoder input.\n",
    "    - generally, prepending bos to the target would do the job (as shown below)\n",
    "![seq2seq](https://i.imgur.com/0zeDyuI.png)\n",
    "    - in fairseq however, this is done by moving the eos token to the begining. Empirically, this has the same effect. For instance:\n",
    "    ```\n",
    "    # output target (target) and Decoder input (prev_output_tokens): \n",
    "                   eos = 2\n",
    "                target = 419,  711,  238,  888,  792,   60,  968,    8,    2\n",
    "    prev_output_tokens = 2,  419,  711,  238,  888,  792,   60,  968,    8\n",
    "    ```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "OWFJFmCnMDXW"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-02 14:23:40 | WARNING | fairseq.tasks.fairseq_task | 2,532 samples have invalid sizes and will be skipped, max_positions=(20, 20), first few sample ids=[3525, 527, 1633, 76, 2861, 2415, 2890, 210, 880, 636]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': tensor([963]),\n",
       " 'nsentences': 1,\n",
       " 'ntokens': 18,\n",
       " 'net_input': {'src_tokens': tensor([[   1,    1,    1,    1,    1,    1,    1,    5,  971, 1132,  373,  160,\n",
       "            516,  315,  433,   33,    5, 3673, 2044,  339,  230,  102,  976,    2]]),\n",
       "  'src_lengths': tensor([17]),\n",
       "  'prev_output_tokens': tensor([[   2,  554,   36,   38,    7,   55,   24,  155,    4,  278,  407, 1362,\n",
       "             26, 1011,   25,  153, 2055,    7,    1,    1,    1,    1,    1,    1]])},\n",
       " 'target': tensor([[ 554,   36,   38,    7,   55,   24,  155,    4,  278,  407, 1362,   26,\n",
       "          1011,   25,  153, 2055,    7,    2,    1,    1,    1,    1,    1,    1]])}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_data_iterator(task, split, epoch=1, max_tokens=4000, num_workers=10, cached=True):\n",
    "    batch_iterator = task.get_batch_iterator(\n",
    "        dataset=task.dataset(split),\n",
    "        max_tokens=max_tokens,\n",
    "        max_sentences=None,\n",
    "        max_positions=utils.resolve_max_positions(\n",
    "            task.max_positions(),\n",
    "            max_tokens,\n",
    "        ),\n",
    "        ignore_invalid_inputs=True,\n",
    "        seed=seed,\n",
    "        num_workers=num_workers,\n",
    "        epoch=epoch,\n",
    "        disable_iterator_cache=not cached,\n",
    "        # Set this to False to speed up. However, if set to False, changing max_tokens beyond \n",
    "        # first call of this method has no effect. \n",
    "    )\n",
    "    return batch_iterator\n",
    "\n",
    "demo_epoch_obj = load_data_iterator(task, \"valid\", epoch=1, max_tokens=20, num_workers=1, cached=False)\n",
    "demo_iter = demo_epoch_obj.next_epoch_itr(shuffle=True)\n",
    "sample = next(demo_iter)\n",
    "sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p86K-0g7Me4M"
   },
   "source": [
    "* each batch is a python dict, with string key and Tensor value. Contents are described below:\n",
    "```python\n",
    "batch = {\n",
    "    \"id\": id, # id for each example \n",
    "    \"nsentences\": len(samples), # batch size (sentences)\n",
    "    \"ntokens\": ntokens, # batch size (tokens)\n",
    "    \"net_input\": {\n",
    "        \"src_tokens\": src_tokens, # sequence in source language\n",
    "        \"src_lengths\": src_lengths, # sequence length of each example before padding\n",
    "        \"prev_output_tokens\": prev_output_tokens, # right shifted target, as mentioned above.\n",
    "    },\n",
    "    \"target\": target, # target sequence\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9EyDBE5ZMkFZ"
   },
   "source": [
    "# Model Architecture\n",
    "* We again inherit fairseq's encoder, decoder and model, so that in the testing phase we can directly leverage fairseq's beam search decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "Hzh74qLIMfW_"
   },
   "outputs": [],
   "source": [
    "from fairseq.models import (\n",
    "    FairseqEncoder, \n",
    "    FairseqIncrementalDecoder,\n",
    "    FairseqEncoderDecoderModel\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OI46v1z7MotH"
   },
   "source": [
    "# Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wn0wSeLLMrbc"
   },
   "source": [
    "- The Encoder is a RNN or Transformer Encoder. The following description is for RNN. For every input token, Encoder will generate a output vector and a hidden states vector, and the hidden states vector is passed on to the next step. In other words, the Encoder sequentially reads in the input sequence, and outputs a single vector at each timestep, then finally outputs the final hidden states, or content vector, at the last timestep.\n",
    "- Parameters:\n",
    "  - *args*\n",
    "      - encoder_embed_dim: the dimension of embeddings, this compresses the one-hot vector into fixed dimensions, which achieves dimension reduction\n",
    "      - encoder_ffn_embed_dim is the dimension of hidden states and output vectors\n",
    "      - encoder_layers is the number of layers for Encoder RNN\n",
    "      - dropout determines the probability of a neuron's activation being set to 0, in order to prevent overfitting. Generally this is applied in training, and removed in testing.\n",
    "  - *dictionary*: the dictionary provided by fairseq. it's used to obtain the padding index, and in turn the encoder padding mask. \n",
    "  - *embed_tokens*: an instance of token embeddings (nn.Embedding)\n",
    "\n",
    "- Inputs: \n",
    "    - *src_tokens*: integer sequence representing english e.g. 1, 28, 29, 205, 2 \n",
    "- Outputs: \n",
    "    - *outputs*: the output of RNN at each timestep, can be furthur processed by Attention\n",
    "    - *final_hiddens*: the hidden states of each timestep, will be passed to decoder for decoding\n",
    "    - *encoder_padding_mask*: this tells the decoder which position to ignore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "WcX3W4iGMq-S"
   },
   "outputs": [],
   "source": [
    "class RNNEncoder(FairseqEncoder):\n",
    "    def __init__(self, args, dictionary, embed_tokens):\n",
    "        super().__init__(dictionary)\n",
    "        self.embed_tokens = embed_tokens\n",
    "        \n",
    "        self.embed_dim = args.encoder_embed_dim\n",
    "        self.hidden_dim = args.encoder_ffn_embed_dim\n",
    "        self.num_layers = args.encoder_layers\n",
    "        \n",
    "        self.dropout_in_module = nn.Dropout(args.dropout)\n",
    "        self.rnn = nn.GRU(\n",
    "            self.embed_dim, \n",
    "            self.hidden_dim, \n",
    "            self.num_layers, \n",
    "            dropout=args.dropout, \n",
    "            batch_first=False, \n",
    "            bidirectional=True\n",
    "        )\n",
    "        self.dropout_out_module = nn.Dropout(args.dropout)\n",
    "        \n",
    "        self.padding_idx = dictionary.pad()\n",
    "        \n",
    "    def combine_bidir(self, outs, bsz: int):\n",
    "        out = outs.view(self.num_layers, 2, bsz, -1).transpose(1, 2).contiguous()\n",
    "        return out.view(self.num_layers, bsz, -1)\n",
    "\n",
    "    def forward(self, src_tokens, **unused):\n",
    "        bsz, seqlen = src_tokens.size()\n",
    "        \n",
    "        # get embeddings\n",
    "        x = self.embed_tokens(src_tokens)\n",
    "        x = self.dropout_in_module(x)\n",
    "\n",
    "        # B x T x C -> T x B x C\n",
    "        x = x.transpose(0, 1)\n",
    "        \n",
    "        # pass thru bidirectional RNN\n",
    "        h0 = x.new_zeros(2 * self.num_layers, bsz, self.hidden_dim)\n",
    "        x, final_hiddens = self.rnn(x, h0)\n",
    "        outputs = self.dropout_out_module(x)\n",
    "        # outputs = [sequence len, batch size, hid dim * directions]\n",
    "        # hidden =  [num_layers * directions, batch size  , hid dim]\n",
    "        \n",
    "        # Since Encoder is bidirectional, we need to concatenate the hidden states of two directions\n",
    "        final_hiddens = self.combine_bidir(final_hiddens, bsz)\n",
    "        # hidden =  [num_layers x batch x num_directions*hidden]\n",
    "        \n",
    "        encoder_padding_mask = src_tokens.eq(self.padding_idx).t()\n",
    "        return tuple(\n",
    "            (\n",
    "                outputs,  # seq_len x batch x hidden\n",
    "                final_hiddens,  # num_layers x batch x num_directions*hidden\n",
    "                encoder_padding_mask,  # seq_len x batch\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    def reorder_encoder_out(self, encoder_out, new_order):\n",
    "        # This is used by fairseq's beam search. How and why is not particularly important here.\n",
    "        return tuple(\n",
    "            (\n",
    "                encoder_out[0].index_select(1, new_order),\n",
    "                encoder_out[1].index_select(1, new_order),\n",
    "                encoder_out[2].index_select(1, new_order),\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ZlE_1JnMv56"
   },
   "source": [
    "## Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZSFSKt_ZMzgh"
   },
   "source": [
    "- When the input sequence is long, \"content vector\" alone cannot accurately represent the whole sequence, attention mechanism can provide the Decoder more information.\n",
    "- According to the **Decoder embeddings** of the current timestep, match the **Encoder outputs** with decoder embeddings to determine correlation, and then sum the Encoder outputs weighted by the correlation as the input to **Decoder** RNN.\n",
    "- Common attention implementations use neural network / dot product as the correlation between **query** (decoder embeddings) and **key** (Encoder outputs), followed by **softmax**  to obtain a distribution, and finally **values** (Encoder outputs) is **weighted sum**-ed by said distribution.\n",
    "\n",
    "- Parameters:\n",
    "  - *input_embed_dim*: dimensionality of key, should be that of the vector in decoder to attend others\n",
    "  - *source_embed_dim*: dimensionality of query, should be that of the vector to be attended to (encoder outputs)\n",
    "  - *output_embed_dim*: dimensionality of value, should be that of the vector after attention, expected by the next layer\n",
    "\n",
    "- Inputs: \n",
    "    - *inputs*: is the key, the vector to attend to others\n",
    "    - *encoder_outputs*:  is the query/value, the vector to be attended to\n",
    "    - *encoder_padding_mask*: this tells the decoder which position to ignore\n",
    "- Outputs: \n",
    "    - *output*: the context vector after attention\n",
    "    - *attention score*: the attention distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "1Atf_YuCMyyF"
   },
   "outputs": [],
   "source": [
    "class AttentionLayer(nn.Module):\n",
    "    def __init__(self, input_embed_dim, source_embed_dim, output_embed_dim, bias=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_proj = nn.Linear(input_embed_dim, source_embed_dim, bias=bias)\n",
    "        self.output_proj = nn.Linear(\n",
    "            input_embed_dim + source_embed_dim, output_embed_dim, bias=bias\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs, encoder_outputs, encoder_padding_mask):\n",
    "        # inputs: T, B, dim\n",
    "        # encoder_outputs: S x B x dim\n",
    "        # padding mask:  S x B\n",
    "        \n",
    "        # convert all to batch first\n",
    "        inputs = inputs.transpose(1,0) # B, T, dim\n",
    "        encoder_outputs = encoder_outputs.transpose(1,0) # B, S, dim\n",
    "        encoder_padding_mask = encoder_padding_mask.transpose(1,0) # B, S\n",
    "        \n",
    "        # project to the dimensionality of encoder_outputs\n",
    "        x = self.input_proj(inputs)\n",
    "\n",
    "        # compute attention\n",
    "        # (B, T, dim) x (B, dim, S) = (B, T, S)\n",
    "        attn_scores = torch.bmm(x, encoder_outputs.transpose(1,2))\n",
    "\n",
    "        # cancel the attention at positions corresponding to padding\n",
    "        if encoder_padding_mask is not None:\n",
    "            # leveraging broadcast  B, S -> (B, 1, S)\n",
    "            encoder_padding_mask = encoder_padding_mask.unsqueeze(1)\n",
    "            attn_scores = (\n",
    "                attn_scores.float()\n",
    "                .masked_fill_(encoder_padding_mask, float(\"-inf\"))\n",
    "                .type_as(attn_scores)\n",
    "            )  # FP16 support: cast to float and back\n",
    "\n",
    "        # softmax on the dimension corresponding to source sequence\n",
    "        attn_scores = F.softmax(attn_scores, dim=-1)\n",
    "\n",
    "        # shape (B, T, S) x (B, S, dim) = (B, T, dim) weighted sum\n",
    "        x = torch.bmm(attn_scores, encoder_outputs)\n",
    "\n",
    "        # (B, T, dim)\n",
    "        x = torch.cat((x, inputs), dim=-1)\n",
    "        x = torch.tanh(self.output_proj(x)) # concat + linear + tanh\n",
    "        \n",
    "        # restore shape (B, T, dim) -> (T, B, dim)\n",
    "        return x.transpose(1,0), attn_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "doSCOA2gM7fK"
   },
   "source": [
    "# Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2M8Vod2gNABR"
   },
   "source": [
    "* The hidden states of **Decoder** will be initialized by the final hidden states of **Encoder** (the content vector)\n",
    "* At the same time, **Decoder** will change its hidden states based on the input of the current timestep (the outputs of previous timesteps), and generates an output\n",
    "* Attention improves the performance\n",
    "* The seq2seq steps are implemented in decoder, so that later the Seq2Seq class can accept RNN and Transformer, without furthur modification.\n",
    "- Parameters:\n",
    "  - *args*\n",
    "      - decoder_embed_dim: is the dimensionality of the decoder embeddings, similar to encoder_embed_dim，\n",
    "      - decoder_ffn_embed_dim: is the dimensionality of the decoder RNN hidden states, similar to encoder_ffn_embed_dim\n",
    "      - decoder_layers: number of layers of RNN decoder\n",
    "      - share_decoder_input_output_embed: usually, the projection matrix of the decoder will share weights with the decoder input embeddings\n",
    "  - *dictionary*: the dictionary provided by fairseq\n",
    "  - *embed_tokens*: an instance of token embeddings (nn.Embedding)\n",
    "- Inputs: \n",
    "    - *prev_output_tokens*: integer sequence representing the right-shifted target e.g. 1, 28, 29, 205, 2 \n",
    "    - *encoder_out*: encoder's output.\n",
    "    - *incremental_state*: in order to speed up decoding during test time, we will save the hidden state of each timestep. see forward() for details.\n",
    "- Outputs: \n",
    "    - *outputs*: the logits (before softmax) output of decoder for each timesteps\n",
    "    - *extra*: unsused"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "QfvgqHYDM6Lp"
   },
   "outputs": [],
   "source": [
    "class RNNDecoder(FairseqIncrementalDecoder):\n",
    "    def __init__(self, args, dictionary, embed_tokens):\n",
    "        super().__init__(dictionary)\n",
    "        self.embed_tokens = embed_tokens\n",
    "        \n",
    "        assert args.decoder_layers == args.encoder_layers, f\"\"\"seq2seq rnn requires that encoder \n",
    "        and decoder have same layers of rnn. got: {args.encoder_layers, args.decoder_layers}\"\"\"\n",
    "        assert args.decoder_ffn_embed_dim == args.encoder_ffn_embed_dim*2, f\"\"\"seq2seq-rnn requires \n",
    "        that decoder hidden to be 2*encoder hidden dim. got: {args.decoder_ffn_embed_dim, args.encoder_ffn_embed_dim*2}\"\"\"\n",
    "        \n",
    "        self.embed_dim = args.decoder_embed_dim\n",
    "        self.hidden_dim = args.decoder_ffn_embed_dim\n",
    "        self.num_layers = args.decoder_layers\n",
    "        \n",
    "        \n",
    "        self.dropout_in_module = nn.Dropout(args.dropout)\n",
    "        self.rnn = nn.GRU(\n",
    "            self.embed_dim, \n",
    "            self.hidden_dim, \n",
    "            self.num_layers, \n",
    "            dropout=args.dropout, \n",
    "            batch_first=False, \n",
    "            bidirectional=False\n",
    "        )\n",
    "        self.attention = AttentionLayer(\n",
    "            self.embed_dim, self.hidden_dim, self.embed_dim, bias=False\n",
    "        ) \n",
    "        # self.attention = None\n",
    "        self.dropout_out_module = nn.Dropout(args.dropout)\n",
    "        \n",
    "        if self.hidden_dim != self.embed_dim:\n",
    "            self.project_out_dim = nn.Linear(self.hidden_dim, self.embed_dim)\n",
    "        else:\n",
    "            self.project_out_dim = None\n",
    "        \n",
    "        if args.share_decoder_input_output_embed:\n",
    "            self.output_projection = nn.Linear(\n",
    "                self.embed_tokens.weight.shape[1],\n",
    "                self.embed_tokens.weight.shape[0],\n",
    "                bias=False,\n",
    "            )\n",
    "            self.output_projection.weight = self.embed_tokens.weight\n",
    "        else:\n",
    "            self.output_projection = nn.Linear(\n",
    "                self.output_embed_dim, len(dictionary), bias=False\n",
    "            )\n",
    "            nn.init.normal_(\n",
    "                self.output_projection.weight, mean=0, std=self.output_embed_dim ** -0.5\n",
    "            )\n",
    "        \n",
    "    def forward(self, prev_output_tokens, encoder_out, incremental_state=None, **unused):\n",
    "        # extract the outputs from encoder\n",
    "        encoder_outputs, encoder_hiddens, encoder_padding_mask = encoder_out\n",
    "        # outputs:          seq_len x batch x num_directions*hidden\n",
    "        # encoder_hiddens:  num_layers x batch x num_directions*encoder_hidden\n",
    "        # padding_mask:     seq_len x batch\n",
    "        \n",
    "        if incremental_state is not None and len(incremental_state) > 0:\n",
    "            # if the information from last timestep is retained, we can continue from there instead of starting from bos\n",
    "            prev_output_tokens = prev_output_tokens[:, -1:]\n",
    "            cache_state = self.get_incremental_state(incremental_state, \"cached_state\")\n",
    "            prev_hiddens = cache_state[\"prev_hiddens\"]\n",
    "        else:\n",
    "            # incremental state does not exist, either this is training time, or the first timestep of test time\n",
    "            # prepare for seq2seq: pass the encoder_hidden to the decoder hidden states\n",
    "            prev_hiddens = encoder_hiddens\n",
    "        \n",
    "        bsz, seqlen = prev_output_tokens.size()\n",
    "        \n",
    "        # embed tokens\n",
    "        x = self.embed_tokens(prev_output_tokens)\n",
    "        x = self.dropout_in_module(x)\n",
    "\n",
    "        # B x T x C -> T x B x C\n",
    "        x = x.transpose(0, 1)\n",
    "                \n",
    "        # decoder-to-encoder attention\n",
    "        if self.attention is not None:\n",
    "            x, attn = self.attention(x, encoder_outputs, encoder_padding_mask)\n",
    "                        \n",
    "        # pass thru unidirectional RNN\n",
    "        x, final_hiddens = self.rnn(x, prev_hiddens)\n",
    "        # outputs = [sequence len, batch size, hid dim]\n",
    "        # hidden =  [num_layers * directions, batch size  , hid dim]\n",
    "        x = self.dropout_out_module(x)\n",
    "                \n",
    "        # project to embedding size (if hidden differs from embed size, and share_embedding is True, \n",
    "        # we need to do an extra projection)\n",
    "        if self.project_out_dim != None:\n",
    "            x = self.project_out_dim(x)\n",
    "        \n",
    "        # project to vocab size\n",
    "        x = self.output_projection(x)\n",
    "        \n",
    "        # T x B x C -> B x T x C\n",
    "        x = x.transpose(1, 0)\n",
    "        \n",
    "        # if incremental, record the hidden states of current timestep, which will be restored in the next timestep\n",
    "        cache_state = {\n",
    "            \"prev_hiddens\": final_hiddens,\n",
    "        }\n",
    "        self.set_incremental_state(incremental_state, \"cached_state\", cache_state)\n",
    "        \n",
    "        return x, None\n",
    "    \n",
    "    def reorder_incremental_state(\n",
    "        self,\n",
    "        incremental_state,\n",
    "        new_order,\n",
    "    ):\n",
    "        # This is used by fairseq's beam search. How and why is not particularly important here.\n",
    "        cache_state = self.get_incremental_state(incremental_state, \"cached_state\")\n",
    "        prev_hiddens = cache_state[\"prev_hiddens\"]\n",
    "        prev_hiddens = [p.index_select(0, new_order) for p in prev_hiddens]\n",
    "        cache_state = {\n",
    "            \"prev_hiddens\": torch.stack(prev_hiddens),\n",
    "        }\n",
    "        self.set_incremental_state(incremental_state, \"cached_state\", cache_state)\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UDAPmxjRNEEL"
   },
   "source": [
    "## Seq2Seq\n",
    "- Composed of **Encoder** and **Decoder**\n",
    "- Recieves inputs and pass to **Encoder** \n",
    "- Pass the outputs from **Encoder** to **Decoder**\n",
    "- **Decoder** will decode according to outputs of previous timesteps as well as **Encoder** outputs  \n",
    "- Once done decoding, return the **Decoder** outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "oRwKdLa0NEU6"
   },
   "outputs": [],
   "source": [
    "class Seq2Seq(FairseqEncoderDecoderModel):\n",
    "    def __init__(self, args, encoder, decoder):\n",
    "        super().__init__(encoder, decoder)\n",
    "        self.args = args\n",
    "    \n",
    "    def forward(\n",
    "        self,\n",
    "        src_tokens,\n",
    "        src_lengths,\n",
    "        prev_output_tokens,\n",
    "        return_all_hiddens: bool = True,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Run the forward pass for an encoder-decoder model.\n",
    "        \"\"\"\n",
    "        encoder_out = self.encoder(\n",
    "            src_tokens, src_lengths=src_lengths, return_all_hiddens=return_all_hiddens\n",
    "        )\n",
    "        logits, extra = self.decoder(\n",
    "            prev_output_tokens,\n",
    "            encoder_out=encoder_out,\n",
    "            src_lengths=src_lengths,\n",
    "            return_all_hiddens=return_all_hiddens,\n",
    "        )\n",
    "        return logits, extra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zu3C2JfqNHzk"
   },
   "source": [
    "# Model Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "nyI9FOx-NJ2m"
   },
   "outputs": [],
   "source": [
    "# # HINT: transformer architecture\n",
    "from fairseq.models.transformer import (\n",
    "    TransformerEncoder, \n",
    "    TransformerDecoder,\n",
    ")\n",
    "\n",
    "def build_model(args, task):\n",
    "    \"\"\" build a model instance based on hyperparameters \"\"\"\n",
    "    src_dict, tgt_dict = task.source_dictionary, task.target_dictionary\n",
    "\n",
    "    # token embeddings\n",
    "    encoder_embed_tokens = nn.Embedding(len(src_dict), args.encoder_embed_dim, src_dict.pad())\n",
    "    decoder_embed_tokens = nn.Embedding(len(tgt_dict), args.decoder_embed_dim, tgt_dict.pad())\n",
    "    \n",
    "    # encoder decoder\n",
    "    # encoder = RNNEncoder(args, src_dict, encoder_embed_tokens)\n",
    "    # decoder = RNNDecoder(args, tgt_dict, decoder_embed_tokens)\n",
    "    encoder = TransformerEncoder(args, src_dict, encoder_embed_tokens)\n",
    "    decoder = TransformerDecoder(args, tgt_dict, decoder_embed_tokens)\n",
    "\n",
    "    # sequence to sequence model\n",
    "    model = Seq2Seq(args, encoder, decoder)\n",
    "    \n",
    "    # initialization for seq2seq model is important, requires extra handling\n",
    "    def init_params(module):\n",
    "        from fairseq.modules import MultiheadAttention\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        if isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=0.02)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        if isinstance(module, MultiheadAttention):\n",
    "            module.q_proj.weight.data.normal_(mean=0.0, std=0.02)\n",
    "            module.k_proj.weight.data.normal_(mean=0.0, std=0.02)\n",
    "            module.v_proj.weight.data.normal_(mean=0.0, std=0.02)\n",
    "        if isinstance(module, nn.RNNBase):\n",
    "            for name, param in module.named_parameters():\n",
    "                if \"weight\" in name or \"bias\" in name:\n",
    "                    param.data.uniform_(-0.1, 0.1)\n",
    "            \n",
    "    # weight initialization\n",
    "    model.apply(init_params)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ce5n4eS7NQNy"
   },
   "source": [
    "## Architecture Related Configuration\n",
    "\n",
    "For strong baseline, please refer to the hyperparameters for *transformer-base* in Table 3 in [Attention is all you need](#vaswani2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "Cyn30VoGNT6N"
   },
   "outputs": [],
   "source": [
    "arch_args = Namespace(\n",
    "    encoder_embed_dim=512,\n",
    "    encoder_ffn_embed_dim=1024,\n",
    "    encoder_layers=4,\n",
    "    decoder_embed_dim=512,\n",
    "    decoder_ffn_embed_dim=1024,\n",
    "    decoder_layers=4,\n",
    "    share_decoder_input_output_embed=True,\n",
    "    dropout=0.2,\n",
    ")\n",
    "\n",
    "# HINT: these patches on parameters for Transformer\n",
    "def add_transformer_args(args):\n",
    "    args.encoder_attention_heads=4\n",
    "    args.encoder_normalize_before=True\n",
    "    \n",
    "    args.decoder_attention_heads=4\n",
    "    args.decoder_normalize_before=True\n",
    "    \n",
    "    args.activation_fn=\"gelu\"\n",
    "    args.max_source_positions=512\n",
    "    args.max_target_positions=512\n",
    "    \n",
    "    # patches on default parameters for Transformer (those not set above)\n",
    "    from fairseq.models.transformer import base_architecture\n",
    "    base_architecture(arch_args)\n",
    "\n",
    "add_transformer_args(arch_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "Nbb76QLCNZZZ"
   },
   "outputs": [],
   "source": [
    "if config.use_wandb:\n",
    "    wandb.config.update(vars(arch_args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "7ZWfxsCDNatH"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-02 14:23:43 | INFO | ml-hw5 | Seq2Seq(\n",
      "  (encoder): TransformerEncoder(\n",
      "    (dropout_module): FairseqDropout()\n",
      "    (embed_tokens): Embedding(8000, 512, padding_idx=1)\n",
      "    (embed_positions): SinusoidalPositionalEmbedding()\n",
      "    (layers): ModuleList(\n",
      "      (0): TransformerEncoderLayerBase(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n",
      "        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (1): TransformerEncoderLayerBase(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n",
      "        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (2): TransformerEncoderLayerBase(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n",
      "        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (3): TransformerEncoderLayerBase(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n",
      "        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (decoder): TransformerDecoder(\n",
      "    (dropout_module): FairseqDropout()\n",
      "    (embed_tokens): Embedding(8000, 512, padding_idx=1)\n",
      "    (embed_positions): SinusoidalPositionalEmbedding()\n",
      "    (layers): ModuleList(\n",
      "      (0): TransformerDecoderLayerBase(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n",
      "        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (1): TransformerDecoderLayerBase(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n",
      "        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (2): TransformerDecoderLayerBase(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n",
      "        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (3): TransformerDecoderLayerBase(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n",
      "        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    (output_projection): Linear(in_features=512, out_features=8000, bias=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = build_model(arch_args, task)\n",
    "logger.info(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aHll7GRNNdqc"
   },
   "source": [
    "# Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rUB9f1WCNgMH"
   },
   "source": [
    "## Loss: Label Smoothing Regularization\n",
    "* let the model learn to generate less concentrated distribution, and prevent over-confidence\n",
    "* sometimes the ground truth may not be the only answer. thus, when calculating loss, we reserve some probability for incorrect labels\n",
    "* avoids overfitting\n",
    "\n",
    "code [source](https://fairseq.readthedocs.io/en/latest/_modules/fairseq/criterions/label_smoothed_cross_entropy.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "IgspdJn0NdYF"
   },
   "outputs": [],
   "source": [
    "class LabelSmoothedCrossEntropyCriterion(nn.Module):\n",
    "    def __init__(self, smoothing, ignore_index=None, reduce=True):\n",
    "        super().__init__()\n",
    "        self.smoothing = smoothing\n",
    "        self.ignore_index = ignore_index\n",
    "        self.reduce = reduce\n",
    "    \n",
    "    def forward(self, lprobs, target):\n",
    "        if target.dim() == lprobs.dim() - 1:\n",
    "            target = target.unsqueeze(-1)\n",
    "        # nll: Negative log likelihood，the cross-entropy when target is one-hot. following line is same as F.nll_loss\n",
    "        nll_loss = -lprobs.gather(dim=-1, index=target)\n",
    "        #  reserve some probability for other labels. thus when calculating cross-entropy, \n",
    "        # equivalent to summing the log probs of all labels\n",
    "        smooth_loss = -lprobs.sum(dim=-1, keepdim=True)\n",
    "        if self.ignore_index is not None:\n",
    "            pad_mask = target.eq(self.ignore_index)\n",
    "            nll_loss.masked_fill_(pad_mask, 0.0)\n",
    "            smooth_loss.masked_fill_(pad_mask, 0.0)\n",
    "        else:\n",
    "            nll_loss = nll_loss.squeeze(-1)\n",
    "            smooth_loss = smooth_loss.squeeze(-1)\n",
    "        if self.reduce:\n",
    "            nll_loss = nll_loss.sum()\n",
    "            smooth_loss = smooth_loss.sum()\n",
    "        # when calculating cross-entropy, add the loss of other labels\n",
    "        eps_i = self.smoothing / lprobs.size(-1)\n",
    "        loss = (1.0 - self.smoothing) * nll_loss + eps_i * smooth_loss\n",
    "        return loss\n",
    "\n",
    "# generally, 0.1 is good enough\n",
    "criterion = LabelSmoothedCrossEntropyCriterion(\n",
    "    smoothing=0.1,\n",
    "    ignore_index=task.target_dictionary.pad(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aRalDto2NkJJ"
   },
   "source": [
    "## Optimizer: Adam + lr scheduling\n",
    "Inverse square root scheduling is important to the stability when training Transformer. It's later used on RNN as well.\n",
    "Update the learning rate according to the following equation. Linearly increase the first stage, then decay proportionally to the inverse square root of timestep.\n",
    "$$lrate = d_{\\text{model}}^{-0.5}\\cdot\\min({step\\_num}^{-0.5},{step\\_num}\\cdot{warmup\\_steps}^{-1.5})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "sS7tQj1ROBYm"
   },
   "outputs": [],
   "source": [
    "def get_rate(d_model, step_num, warmup_step):\n",
    "    lr = d_model **(-.5) * min(step_num ** (-.5), step_num * warmup_step ** (-1.5))\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "J8hoAjHPNkh3"
   },
   "outputs": [],
   "source": [
    "class NoamOpt:\n",
    "    \"Optim wrapper that implements rate.\"\n",
    "    def __init__(self, model_size, factor, warmup, optimizer):\n",
    "        self.optimizer = optimizer\n",
    "        self._step = 0\n",
    "        self.warmup = warmup\n",
    "        self.factor = factor\n",
    "        self.model_size = model_size\n",
    "        self._rate = 0\n",
    "    \n",
    "    @property\n",
    "    def param_groups(self):\n",
    "        return self.optimizer.param_groups\n",
    "        \n",
    "    def multiply_grads(self, c):\n",
    "        \"\"\"Multiplies grads by a constant *c*.\"\"\"                \n",
    "        for group in self.param_groups:\n",
    "            for p in group['params']:\n",
    "                if p.grad is not None:\n",
    "                    p.grad.data.mul_(c)\n",
    "        \n",
    "    def step(self):\n",
    "        \"Update parameters and rate\"\n",
    "        self._step += 1\n",
    "        rate = self.rate()\n",
    "        for p in self.param_groups:\n",
    "            p['lr'] = rate\n",
    "        self._rate = rate\n",
    "        self.optimizer.step()\n",
    "        \n",
    "    def rate(self, step = None):\n",
    "        \"Implement `lrate` above\"\n",
    "        if step is None:\n",
    "            step = self._step\n",
    "        return 0 if not step else self.factor * get_rate(self.model_size, step, self.warmup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VFJlkOMONsc6"
   },
   "source": [
    "## Scheduling Visualized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "A135fwPCNrQs"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f7d8f880460>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "optimizer = NoamOpt(\n",
    "    model_size=arch_args.encoder_embed_dim, \n",
    "    factor=config.lr_factor, \n",
    "    warmup=config.lr_warmup, \n",
    "    optimizer=torch.optim.AdamW(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9, weight_decay=0.0001))\n",
    "plt.plot(np.arange(1, 100000), [optimizer.rate(i) for i in range(1, 100000)])\n",
    "plt.legend([f\"{optimizer.model_size}:{optimizer.warmup}\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TOR0g-cVO5ZO"
   },
   "source": [
    "# Training Procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f-0ZjbK3O8Iv"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "foal3xM1O404"
   },
   "outputs": [],
   "source": [
    "from fairseq.data import iterators\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "def batch_cosine_similarity(a:torch.tensor, b: torch.tensor, eps=1e-6):\n",
    "    a_n, b_n = a.norm(dim=1)[:, None], b.norm(dim=1)[:, None]\n",
    "    a_norm = a / torch.clamp(a_n, min=eps)\n",
    "    b_norm = b / torch.clamp(b_n, min=eps)\n",
    "    sim_mt = torch.mm(a_norm, b_norm.transpose(0, 1))\n",
    "    return sim_mt\n",
    "\n",
    "\n",
    "def train_one_epoch(epoch_itr, model, task, criterion, optimizer, accum_steps=1):\n",
    "    itr = epoch_itr.next_epoch_itr(shuffle=True)\n",
    "    itr = iterators.GroupedIterator(itr, accum_steps) # gradient accumulation: update every accum_steps samples\n",
    "    \n",
    "    stats = {\"loss\": []}\n",
    "    scaler = GradScaler() # automatic mixed precision (amp) \n",
    "    \n",
    "    model.train()\n",
    "    progress = tqdm.tqdm(itr, desc=f\"train epoch {epoch_itr.epoch}\", leave=False)\n",
    "    for samples in progress:\n",
    "        model.zero_grad()\n",
    "        accum_loss = 0\n",
    "        sample_size = 0\n",
    "        # gradient accumulation: update every accum_steps samples\n",
    "        for i, sample in enumerate(samples):\n",
    "            if i == 1:\n",
    "                # emptying the CUDA cache after the first step can reduce the chance of OOM\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "            sample = utils.move_to_cuda(sample, device=device)\n",
    "            target = sample[\"target\"]\n",
    "            sample_size_i = sample[\"ntokens\"]\n",
    "            sample_size += sample_size_i\n",
    "            \n",
    "            # mixed precision training\n",
    "            with autocast():\n",
    "                net_output = model.forward(**sample[\"net_input\"])\n",
    "                lprobs = F.log_softmax(net_output[0], -1)            \n",
    "                loss = criterion(lprobs.view(-1, lprobs.size(-1)), target.view(-1))\n",
    "                \n",
    "                # logging\n",
    "                accum_loss += loss.item()\n",
    "                # back-prop\n",
    "                scaler.scale(loss).backward()                \n",
    "        \n",
    "        scaler.unscale_(optimizer)\n",
    "        optimizer.multiply_grads(1 / (sample_size or 1.0)) # (sample_size or 1.0) handles the case of a zero gradient\n",
    "        gnorm = nn.utils.clip_grad_norm_(model.parameters(), config.clip_norm) # grad norm clipping prevents gradient exploding\n",
    "        \n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        # logging\n",
    "        loss_print = accum_loss/sample_size\n",
    "        stats[\"loss\"].append(loss_print)\n",
    "        progress.set_postfix(loss=loss_print)\n",
    "        if config.use_wandb:\n",
    "            wandb.log({\n",
    "                \"train/loss\": loss_print,\n",
    "                \"train/grad_norm\": gnorm.item(),\n",
    "                \"train/lr\": optimizer.rate(),\n",
    "                \"train/sample_size\": sample_size,\n",
    "            })\n",
    "    pos_emb = model.decoder.embed_positions.weights.cpu().detach()\n",
    "    if config.use_wandb:\n",
    "        wandb.log({\"decoder_positional_embedding\": wandb.Image(batch_cosine_similarity(pos_emb, pos_emb))})\n",
    "\n",
    "    loss_print = np.mean(stats[\"loss\"])\n",
    "    logger.info(f\"training loss: {loss_print:.4f}\")\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gt1lX3DRO_yU"
   },
   "source": [
    "## Validation & Inference\n",
    "To prevent overfitting, validation is required every epoch to validate the performance on unseen data.\n",
    "- the procedure is essensially same as training, with the addition of inference step\n",
    "- after validation we can save the model weights\n",
    "\n",
    "Validation loss alone cannot describe the actual performance of the model\n",
    "- Directly produce translation hypotheses based on current model, then calculate BLEU with the reference translation\n",
    "- We can also manually examine the hypotheses' quality\n",
    "- We use fairseq's sequence generator for beam search to generate translation hypotheses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "2og80HYQPAKq"
   },
   "outputs": [],
   "source": [
    "# fairseq's beam search generator\n",
    "# given model and input seqeunce, produce translation hypotheses by beam search\n",
    "sequence_generator = task.build_generator([model], config)\n",
    "\n",
    "def decode(toks, dictionary):\n",
    "    # convert from Tensor to human readable sentence\n",
    "    s = dictionary.string(\n",
    "        toks.int().cpu(),\n",
    "        config.post_process,\n",
    "    )\n",
    "    return s if s else \"<unk>\"\n",
    "\n",
    "def inference_step(sample, model):\n",
    "    gen_out = sequence_generator.generate([model], sample)\n",
    "    srcs = []\n",
    "    hyps = []\n",
    "    refs = []\n",
    "    for i in range(len(gen_out)):\n",
    "        # for each sample, collect the input, hypothesis and reference, later be used to calculate BLEU\n",
    "        srcs.append(decode(\n",
    "            utils.strip_pad(sample[\"net_input\"][\"src_tokens\"][i], task.source_dictionary.pad()), \n",
    "            task.source_dictionary,\n",
    "        ))\n",
    "        hyps.append(decode(\n",
    "            gen_out[i][0][\"tokens\"], # 0 indicates using the top hypothesis in beam\n",
    "            task.target_dictionary,\n",
    "        ))\n",
    "        refs.append(decode(\n",
    "            utils.strip_pad(sample[\"target\"][i], task.target_dictionary.pad()), \n",
    "            task.target_dictionary,\n",
    "        ))\n",
    "    return srcs, hyps, refs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "y1o7LeDkPDsd"
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "import sacrebleu\n",
    "\n",
    "def validate(model, task, criterion, log_to_wandb=True):\n",
    "    logger.info('begin validation')\n",
    "    itr = load_data_iterator(task, \"valid\", 1, config.max_tokens, config.num_workers).next_epoch_itr(shuffle=False)\n",
    "    \n",
    "    stats = {\"loss\":[], \"bleu\": 0, \"srcs\":[], \"hyps\":[], \"refs\":[]}\n",
    "    srcs = []\n",
    "    hyps = []\n",
    "    refs = []\n",
    "    \n",
    "    model.eval()\n",
    "    progress = tqdm.tqdm(itr, desc=f\"validation\", leave=False)\n",
    "    with torch.no_grad():\n",
    "        for i, sample in enumerate(progress):\n",
    "            # validation loss\n",
    "            sample = utils.move_to_cuda(sample, device=device)\n",
    "            net_output = model.forward(**sample[\"net_input\"])\n",
    "\n",
    "            lprobs = F.log_softmax(net_output[0], -1)\n",
    "            target = sample[\"target\"]\n",
    "            sample_size = sample[\"ntokens\"]\n",
    "            loss = criterion(lprobs.view(-1, lprobs.size(-1)), target.view(-1)) / sample_size\n",
    "            progress.set_postfix(valid_loss=loss.item())\n",
    "            stats[\"loss\"].append(loss)\n",
    "            \n",
    "            # do inference\n",
    "            s, h, r = inference_step(sample, model)\n",
    "            srcs.extend(s)\n",
    "            hyps.extend(h)\n",
    "            refs.extend(r)\n",
    "            \n",
    "    tok = 'zh' if task.cfg.target_lang == 'zh' else '13a'\n",
    "    stats[\"loss\"] = torch.stack(stats[\"loss\"]).mean().item()\n",
    "    stats[\"bleu\"] = sacrebleu.corpus_bleu(hyps, [refs], tokenize=tok) # 計算BLEU score\n",
    "    stats[\"srcs\"] = srcs\n",
    "    stats[\"hyps\"] = hyps\n",
    "    stats[\"refs\"] = refs\n",
    "    \n",
    "    if config.use_wandb and log_to_wandb:\n",
    "        wandb.log({\n",
    "            \"valid/loss\": stats[\"loss\"],\n",
    "            \"valid/bleu\": stats[\"bleu\"].score,\n",
    "        }, commit=False)\n",
    "    \n",
    "    showid = np.random.randint(len(hyps))\n",
    "    logger.info(\"example source: \" + srcs[showid])\n",
    "    logger.info(\"example hypothesis: \" + hyps[showid])\n",
    "    logger.info(\"example reference: \" + refs[showid])\n",
    "    \n",
    "    # show bleu results\n",
    "    logger.info(f\"validation loss:\\t{stats['loss']:.4f}\")\n",
    "    logger.info(stats[\"bleu\"].format())\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1sRF6nd4PGEE"
   },
   "source": [
    "# Save and Load Model Weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "edBuLlkuPGr9"
   },
   "outputs": [],
   "source": [
    "def validate_and_save(model, task, criterion, optimizer, epoch, save=True):   \n",
    "    stats = validate(model, task, criterion)\n",
    "    bleu = stats['bleu']\n",
    "    loss = stats['loss']\n",
    "    if save:\n",
    "        # save epoch checkpoints\n",
    "        savedir = Path(config.savedir).absolute()\n",
    "        savedir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        check = {\n",
    "            \"model\": model.state_dict(),\n",
    "            \"stats\": {\"bleu\": bleu.score, \"loss\": loss},\n",
    "            \"optim\": {\"step\": optimizer._step}\n",
    "        }\n",
    "        torch.save(check, savedir/f\"checkpoint{epoch}.pt\")\n",
    "        shutil.copy(savedir/f\"checkpoint{epoch}.pt\", savedir/f\"checkpoint_last.pt\")\n",
    "        logger.info(f\"saved epoch checkpoint: {savedir}/checkpoint{epoch}.pt\")\n",
    "    \n",
    "        # save epoch samples\n",
    "        with open(savedir/f\"samples{epoch}.{config.source_lang}-{config.target_lang}.txt\", \"w\") as f:\n",
    "            for s, h in zip(stats[\"srcs\"], stats[\"hyps\"]):\n",
    "                f.write(f\"{s}\\t{h}\\n\")\n",
    "\n",
    "        # get best valid bleu    \n",
    "        if getattr(validate_and_save, \"best_bleu\", 0) < bleu.score:\n",
    "            validate_and_save.best_bleu = bleu.score\n",
    "            torch.save(check, savedir/f\"checkpoint_best.pt\")\n",
    "            \n",
    "        del_file = savedir / f\"checkpoint{epoch - config.keep_last_epochs}.pt\"\n",
    "        if del_file.exists():\n",
    "            del_file.unlink()\n",
    "    \n",
    "    return stats\n",
    "\n",
    "def try_load_checkpoint(model, optimizer=None, name=None):\n",
    "    name = name if name else \"checkpoint_last.pt\"\n",
    "    checkpath = Path(config.savedir)/name\n",
    "    if checkpath.exists():\n",
    "        check = torch.load(checkpath)\n",
    "        model.load_state_dict(check[\"model\"])\n",
    "        stats = check[\"stats\"]\n",
    "        step = \"unknown\"\n",
    "        if optimizer != None:\n",
    "            optimizer._step = step = check[\"optim\"][\"step\"]\n",
    "        logger.info(f\"loaded checkpoint {checkpath}: step={step} loss={stats['loss']} bleu={stats['bleu']}\")\n",
    "    else:\n",
    "        logger.info(f\"no checkpoints found at {checkpath}!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KyIFpibfPJ5u"
   },
   "source": [
    "# Main\n",
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "hu7RZbCUPKQr"
   },
   "outputs": [],
   "source": [
    "model = model.to(device=device)\n",
    "criterion = criterion.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "5xxlJxU2PeAo"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-02 14:23:44 | INFO | ml-hw5 | task: TranslationTask\n",
      "2022-04-02 14:23:44 | INFO | ml-hw5 | encoder: TransformerEncoder\n",
      "2022-04-02 14:23:44 | INFO | ml-hw5 | decoder: TransformerDecoder\n",
      "2022-04-02 14:23:44 | INFO | ml-hw5 | criterion: LabelSmoothedCrossEntropyCriterion\n",
      "2022-04-02 14:23:44 | INFO | ml-hw5 | optimizer: NoamOpt\n",
      "2022-04-02 14:23:44 | INFO | ml-hw5 | num. model params: 29,222,912 (num. trained: 29,222,912)\n",
      "2022-04-02 14:23:44 | INFO | ml-hw5 | max tokens per batch = 8192, accumulate steps = 2\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"task: {}\".format(task.__class__.__name__))\n",
    "logger.info(\"encoder: {}\".format(model.encoder.__class__.__name__))\n",
    "logger.info(\"decoder: {}\".format(model.decoder.__class__.__name__))\n",
    "logger.info(\"criterion: {}\".format(criterion.__class__.__name__))\n",
    "logger.info(\"optimizer: {}\".format(optimizer.__class__.__name__))\n",
    "logger.info(\n",
    "    \"num. model params: {:,} (num. trained: {:,})\".format(\n",
    "        sum(p.numel() for p in model.parameters()),\n",
    "        sum(p.numel() for p in model.parameters() if p.requires_grad),\n",
    "    )\n",
    ")\n",
    "logger.info(f\"max tokens per batch = {config.max_tokens}, accumulate steps = {config.accum_steps}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "MSPRqpQUPfaX"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-02 14:23:44 | WARNING | fairseq.tasks.fairseq_task | 1 samples have invalid sizes and will be skipped, max_positions=(1024, 1024), first few sample ids=[326674]\n",
      "2022-04-02 14:23:44 | INFO | ml-hw5 | loaded checkpoint checkpoints/transformer_zh-en/checkpoint_last.pt: step=7882 loss=2.87406587600708 bleu=16.03945005837511\n",
      "2022-04-02 14:23:45 | INFO | fairseq.data.iterators | grouped total_num_itrs = 800\n",
      "2022-04-02 14:26:37 | INFO | ml-hw5 | training loss: 2.9035                \n",
      "2022-04-02 14:26:37 | INFO | ml-hw5 | begin validation\n",
      "2022-04-02 14:26:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2022-04-02 14:26:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2022-04-02 14:26:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
      "2022-04-02 14:26:55 | INFO | ml-hw5 | example source: 它是個美麗的國家 , 位在西非 。\n",
      "2022-04-02 14:26:55 | INFO | ml-hw5 | example hypothesis: it's a beautiful country , in west africa .\n",
      "2022-04-02 14:26:55 | INFO | ml-hw5 | example reference: it is a beautiful country located in west africa .\n",
      "2022-04-02 14:26:55 | INFO | ml-hw5 | validation loss:\t2.8426\n",
      "2022-04-02 14:26:55 | INFO | ml-hw5 | BLEU = 16.76 56.0/26.1/13.9/7.6 (BP = 0.844 ratio = 0.855 hyp_len = 65856 ref_len = 77050)\n",
      "2022-04-02 14:26:55 | INFO | ml-hw5 | saved epoch checkpoint: /home/user/homework/ML/hw5/checkpoints/transformer_zh-en/checkpoint1.pt\n",
      "2022-04-02 14:26:56 | INFO | ml-hw5 | end of epoch 1\n",
      "2022-04-02 14:26:56 | INFO | fairseq.data.iterators | grouped total_num_itrs = 800\n",
      "2022-04-02 14:29:49 | INFO | ml-hw5 | training loss: 2.8669                \n",
      "2022-04-02 14:29:49 | INFO | ml-hw5 | begin validation\n",
      "2022-04-02 14:30:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2022-04-02 14:30:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2022-04-02 14:30:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
      "2022-04-02 14:30:07 | INFO | ml-hw5 | example source: 他懂得策略 。\n",
      "2022-04-02 14:30:07 | INFO | ml-hw5 | example hypothesis: he knew strategy .\n",
      "2022-04-02 14:30:07 | INFO | ml-hw5 | example reference: arthur samuel knew strategy .\n",
      "2022-04-02 14:30:07 | INFO | ml-hw5 | validation loss:\t2.8082\n",
      "2022-04-02 14:30:07 | INFO | ml-hw5 | BLEU = 16.74 56.4/26.4/14.1/7.8 (BP = 0.834 ratio = 0.846 hyp_len = 65202 ref_len = 77050)\n",
      "2022-04-02 14:30:07 | INFO | ml-hw5 | saved epoch checkpoint: /home/user/homework/ML/hw5/checkpoints/transformer_zh-en/checkpoint2.pt\n",
      "2022-04-02 14:30:07 | INFO | ml-hw5 | end of epoch 2\n",
      "2022-04-02 14:30:08 | INFO | fairseq.data.iterators | grouped total_num_itrs = 800\n",
      "2022-04-02 14:33:01 | INFO | ml-hw5 | training loss: 2.8377                \n",
      "2022-04-02 14:33:01 | INFO | ml-hw5 | begin validation\n",
      "2022-04-02 14:33:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2022-04-02 14:33:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2022-04-02 14:33:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
      "2022-04-02 14:33:19 | INFO | ml-hw5 | example source: 你可以成為傑出的一代 。 」\n",
      "2022-04-02 14:33:19 | INFO | ml-hw5 | example hypothesis: you can be a brilliant generation . \"\n",
      "2022-04-02 14:33:19 | INFO | ml-hw5 | example reference: you can be that great generation . \"\n",
      "2022-04-02 14:33:19 | INFO | ml-hw5 | validation loss:\t2.7913\n",
      "2022-04-02 14:33:19 | INFO | ml-hw5 | BLEU = 17.18 56.5/26.7/14.4/8.0 (BP = 0.841 ratio = 0.852 hyp_len = 65658 ref_len = 77050)\n",
      "2022-04-02 14:33:19 | INFO | ml-hw5 | saved epoch checkpoint: /home/user/homework/ML/hw5/checkpoints/transformer_zh-en/checkpoint3.pt\n",
      "2022-04-02 14:33:20 | INFO | ml-hw5 | end of epoch 3\n",
      "2022-04-02 14:33:20 | INFO | fairseq.data.iterators | grouped total_num_itrs = 800\n",
      "2022-04-02 14:36:13 | INFO | ml-hw5 | training loss: 2.7961                \n",
      "2022-04-02 14:36:13 | INFO | ml-hw5 | begin validation\n",
      "2022-04-02 14:36:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2022-04-02 14:36:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2022-04-02 14:36:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
      "2022-04-02 14:36:32 | INFO | ml-hw5 | example source: 它驅使人們離開大腦聰明的那部份那個潛意識的黑暗深井本能和經驗所在的地方以及所有其他創意的元素還有良好判斷力所在之處它迫使我們去到單薄又呆板有意識的邏輯 。\n",
      "2022-04-02 14:36:32 | INFO | ml-hw5 | example hypothesis: it drives people to leave the smart part of the brain that unconscious dark wells instincts and experiences and all the other elements of creativity and good judgments that force us to go to a thin plate of conscious logic .\n",
      "2022-04-02 14:36:32 | INFO | ml-hw5 | example reference: it drives people from the smart part of the brain that dark , deep well of the subconscious , where instincts and experience , and all the other factors of creativity and good judgment are it drives us to the thin veneer of conscious logic .\n",
      "2022-04-02 14:36:32 | INFO | ml-hw5 | validation loss:\t2.7479\n",
      "2022-04-02 14:36:32 | INFO | ml-hw5 | BLEU = 18.25 55.4/26.3/14.3/8.1 (BP = 0.902 ratio = 0.906 hyp_len = 69831 ref_len = 77050)\n",
      "2022-04-02 14:36:32 | INFO | ml-hw5 | saved epoch checkpoint: /home/user/homework/ML/hw5/checkpoints/transformer_zh-en/checkpoint4.pt\n",
      "2022-04-02 14:36:32 | INFO | ml-hw5 | end of epoch 4\n",
      "2022-04-02 14:36:33 | INFO | fairseq.data.iterators | grouped total_num_itrs = 800\n",
      "2022-04-02 14:39:26 | INFO | ml-hw5 | training loss: 2.7578                \n",
      "2022-04-02 14:39:26 | INFO | ml-hw5 | begin validation\n",
      "2022-04-02 14:39:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2022-04-02 14:39:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2022-04-02 14:39:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
      "2022-04-02 14:39:44 | INFO | ml-hw5 | example source: 「 事情並無好壞/是我們的思維使之如此 」\n",
      "2022-04-02 14:39:44 | INFO | ml-hw5 | example hypothesis: \" it's not bad , it's our minds . \"\n",
      "2022-04-02 14:39:44 | INFO | ml-hw5 | example reference: that seems like a onequestion iq test .\n",
      "2022-04-02 14:39:44 | INFO | ml-hw5 | validation loss:\t2.7287\n",
      "2022-04-02 14:39:44 | INFO | ml-hw5 | BLEU = 18.59 55.7/26.8/14.7/8.2 (BP = 0.902 ratio = 0.906 hyp_len = 69841 ref_len = 77050)\n",
      "2022-04-02 14:39:44 | INFO | ml-hw5 | saved epoch checkpoint: /home/user/homework/ML/hw5/checkpoints/transformer_zh-en/checkpoint5.pt\n",
      "2022-04-02 14:39:45 | INFO | ml-hw5 | end of epoch 5\n",
      "2022-04-02 14:39:45 | INFO | fairseq.data.iterators | grouped total_num_itrs = 800\n",
      "2022-04-02 14:42:38 | INFO | ml-hw5 | training loss: 2.7202                \n",
      "2022-04-02 14:42:38 | INFO | ml-hw5 | begin validation\n",
      "2022-04-02 14:42:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2022-04-02 14:42:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2022-04-02 14:42:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
      "2022-04-02 14:42:57 | INFO | ml-hw5 | example source: 謝謝 。\n",
      "2022-04-02 14:42:57 | INFO | ml-hw5 | example hypothesis: thank you very much .\n",
      "2022-04-02 14:42:57 | INFO | ml-hw5 | example reference: thank you .\n",
      "2022-04-02 14:42:57 | INFO | ml-hw5 | validation loss:\t2.7093\n",
      "2022-04-02 14:42:57 | INFO | ml-hw5 | BLEU = 18.76 56.4/27.3/15.0/8.5 (BP = 0.892 ratio = 0.898 hyp_len = 69182 ref_len = 77050)\n",
      "2022-04-02 14:42:57 | INFO | ml-hw5 | saved epoch checkpoint: /home/user/homework/ML/hw5/checkpoints/transformer_zh-en/checkpoint6.pt\n",
      "2022-04-02 14:42:58 | INFO | ml-hw5 | end of epoch 6\n",
      "2022-04-02 14:42:58 | INFO | fairseq.data.iterators | grouped total_num_itrs = 800\n",
      "2022-04-02 14:45:51 | INFO | ml-hw5 | training loss: 2.6885                \n",
      "2022-04-02 14:45:51 | INFO | ml-hw5 | begin validation\n",
      "2022-04-02 14:46:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2022-04-02 14:46:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2022-04-02 14:46:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
      "2022-04-02 14:46:09 | INFO | ml-hw5 | example source: 不 。\n",
      "2022-04-02 14:46:09 | INFO | ml-hw5 | example hypothesis: no .\n",
      "2022-04-02 14:46:09 | INFO | ml-hw5 | example reference: no .\n",
      "2022-04-02 14:46:09 | INFO | ml-hw5 | validation loss:\t2.7051\n",
      "2022-04-02 14:46:09 | INFO | ml-hw5 | BLEU = 18.89 57.6/28.2/15.6/9.0 (BP = 0.865 ratio = 0.873 hyp_len = 67288 ref_len = 77050)\n",
      "2022-04-02 14:46:10 | INFO | ml-hw5 | saved epoch checkpoint: /home/user/homework/ML/hw5/checkpoints/transformer_zh-en/checkpoint7.pt\n",
      "2022-04-02 14:46:11 | INFO | ml-hw5 | end of epoch 7\n",
      "2022-04-02 14:46:11 | INFO | fairseq.data.iterators | grouped total_num_itrs = 800\n",
      "2022-04-02 14:49:04 | INFO | ml-hw5 | training loss: 2.6612                \n",
      "2022-04-02 14:49:04 | INFO | ml-hw5 | begin validation\n",
      "2022-04-02 14:49:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2022-04-02 14:49:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2022-04-02 14:49:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
      "2022-04-02 14:49:21 | INFO | ml-hw5 | example source: 自行車是只在美國南部一些城市正在進行的革命\n",
      "2022-04-02 14:49:21 | INFO | ml-hw5 | example hypothesis: bicycles are revolutions in the southern united states .\n",
      "2022-04-02 14:49:21 | INFO | ml-hw5 | example reference: bicycles and bicycling are the current revolution underway in only some american cities .\n",
      "2022-04-02 14:49:21 | INFO | ml-hw5 | validation loss:\t2.6849\n",
      "2022-04-02 14:49:21 | INFO | ml-hw5 | BLEU = 19.13 57.4/28.1/15.6/8.9 (BP = 0.878 ratio = 0.885 hyp_len = 68186 ref_len = 77050)\n",
      "2022-04-02 14:49:23 | INFO | ml-hw5 | saved epoch checkpoint: /home/user/homework/ML/hw5/checkpoints/transformer_zh-en/checkpoint8.pt\n",
      "2022-04-02 14:49:23 | INFO | ml-hw5 | end of epoch 8\n",
      "2022-04-02 14:49:24 | INFO | fairseq.data.iterators | grouped total_num_itrs = 800\n",
      "2022-04-02 14:52:16 | INFO | ml-hw5 | training loss: 2.6355                \n",
      "2022-04-02 14:52:16 | INFO | ml-hw5 | begin validation\n",
      "2022-04-02 14:52:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2022-04-02 14:52:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2022-04-02 14:52:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
      "2022-04-02 14:52:34 | INFO | ml-hw5 | example source: jc:我覺得很有意思 。\n",
      "2022-04-02 14:52:34 | INFO | ml-hw5 | example hypothesis: jc: i think it's interesting .\n",
      "2022-04-02 14:52:34 | INFO | ml-hw5 | example reference: jc: it makes perfect sense to me .\n",
      "2022-04-02 14:52:34 | INFO | ml-hw5 | validation loss:\t2.6780\n",
      "2022-04-02 14:52:34 | INFO | ml-hw5 | BLEU = 19.04 57.8/28.4/15.9/9.1 (BP = 0.862 ratio = 0.870 hyp_len = 67069 ref_len = 77050)\n",
      "2022-04-02 14:52:35 | INFO | ml-hw5 | saved epoch checkpoint: /home/user/homework/ML/hw5/checkpoints/transformer_zh-en/checkpoint9.pt\n",
      "2022-04-02 14:52:35 | INFO | ml-hw5 | end of epoch 9\n",
      "2022-04-02 14:52:35 | INFO | fairseq.data.iterators | grouped total_num_itrs = 800\n",
      "2022-04-02 14:55:29 | INFO | ml-hw5 | training loss: 2.6137                 \n",
      "2022-04-02 14:55:29 | INFO | ml-hw5 | begin validation\n",
      "2022-04-02 14:55:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2022-04-02 14:55:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2022-04-02 14:55:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
      "2022-04-02 14:55:47 | INFO | ml-hw5 | example source: 這就是問題所在彼得‧德森指出了這點他用的例子是某種鴨嘴恐龍當時被稱為亞冠龍\n",
      "2022-04-02 14:55:47 | INFO | ml-hw5 | example hypothesis: that's the problem with peter dson points out to be an example of some kind of duck dinosaur that was called the asyron .\n",
      "2022-04-02 14:55:47 | INFO | ml-hw5 | example reference: so this was a problem , and peter dodson pointed this out using some duckbilled dinosaurs then called hypacrosaurus .\n",
      "2022-04-02 14:55:47 | INFO | ml-hw5 | validation loss:\t2.6726\n",
      "2022-04-02 14:55:47 | INFO | ml-hw5 | BLEU = 18.88 57.8/28.4/15.9/9.1 (BP = 0.854 ratio = 0.864 hyp_len = 66557 ref_len = 77050)\n",
      "2022-04-02 14:55:48 | INFO | ml-hw5 | saved epoch checkpoint: /home/user/homework/ML/hw5/checkpoints/transformer_zh-en/checkpoint10.pt\n",
      "2022-04-02 14:55:48 | INFO | ml-hw5 | end of epoch 10\n",
      "2022-04-02 14:55:48 | INFO | fairseq.data.iterators | grouped total_num_itrs = 800\n",
      "2022-04-02 14:58:41 | INFO | ml-hw5 | training loss: 2.6060                 \n",
      "2022-04-02 14:58:41 | INFO | ml-hw5 | begin validation\n",
      "2022-04-02 14:59:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2022-04-02 14:59:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2022-04-02 14:59:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
      "2022-04-02 14:59:00 | INFO | ml-hw5 | example source: 她說: 「 放下你的身段 , 錢是『綠色』的 。 」\n",
      "2022-04-02 14:59:00 | INFO | ml-hw5 | example hypothesis: and she said , \" let's put down your phrase , and the money is green . \"\n",
      "2022-04-02 14:59:00 | INFO | ml-hw5 | example reference: she said , \" get off your throne . money is green . \"\n",
      "2022-04-02 14:59:00 | INFO | ml-hw5 | validation loss:\t2.6557\n",
      "2022-04-02 14:59:00 | INFO | ml-hw5 | BLEU = 19.70 56.2/27.6/15.4/8.8 (BP = 0.921 ratio = 0.924 hyp_len = 71164 ref_len = 77050)\n",
      "2022-04-02 14:59:00 | INFO | ml-hw5 | saved epoch checkpoint: /home/user/homework/ML/hw5/checkpoints/transformer_zh-en/checkpoint11.pt\n",
      "2022-04-02 14:59:01 | INFO | ml-hw5 | end of epoch 11\n",
      "2022-04-02 14:59:01 | INFO | fairseq.data.iterators | grouped total_num_itrs = 800\n",
      "2022-04-02 15:01:54 | INFO | ml-hw5 | training loss: 2.5885                 \n",
      "2022-04-02 15:01:54 | INFO | ml-hw5 | begin validation\n",
      "2022-04-02 15:02:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2022-04-02 15:02:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2022-04-02 15:02:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
      "2022-04-02 15:02:13 | INFO | ml-hw5 | example source: 成為領導者是我的抱負 , 我想問 , 在沒有影響力時 , 你要如何領導 ?\n",
      "2022-04-02 15:02:13 | INFO | ml-hw5 | example hypothesis: becoming a leader is my aspiration , and i want to ask , how do you lead when there is no impact ?\n",
      "2022-04-02 15:02:13 | INFO | ml-hw5 | example reference: i'm an aspiring leader , and i have a question about how you lead when you have no influence .\n",
      "2022-04-02 15:02:13 | INFO | ml-hw5 | validation loss:\t2.6428\n",
      "2022-04-02 15:02:13 | INFO | ml-hw5 | BLEU = 19.92 56.5/28.0/15.6/9.0 (BP = 0.918 ratio = 0.921 hyp_len = 71000 ref_len = 77050)\n",
      "2022-04-02 15:02:13 | INFO | ml-hw5 | saved epoch checkpoint: /home/user/homework/ML/hw5/checkpoints/transformer_zh-en/checkpoint12.pt\n",
      "2022-04-02 15:02:14 | INFO | ml-hw5 | end of epoch 12\n",
      "2022-04-02 15:02:14 | INFO | fairseq.data.iterators | grouped total_num_itrs = 800\n",
      "2022-04-02 15:05:08 | INFO | ml-hw5 | training loss: 2.5724                 \n",
      "2022-04-02 15:05:08 | INFO | ml-hw5 | begin validation\n",
      "2022-04-02 15:05:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2022-04-02 15:05:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2022-04-02 15:05:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
      "2022-04-02 15:05:26 | INFO | ml-hw5 | example source: 這樣 , 英國國教的牧師就可以教訓無神論者 , 說他們的言論有多麼冒犯人 ;\n",
      "2022-04-02 15:05:26 | INFO | ml-hw5 | example hypothesis: that way , the british priest can teach atheists how offensive they are .\n",
      "2022-04-02 15:05:26 | INFO | ml-hw5 | example reference: so anglican ministers could lecture atheists on the offensiveness of their discourse .\n",
      "2022-04-02 15:05:26 | INFO | ml-hw5 | validation loss:\t2.6487\n",
      "2022-04-02 15:05:26 | INFO | ml-hw5 | BLEU = 19.66 58.5/29.1/16.4/9.5 (BP = 0.867 ratio = 0.875 hyp_len = 67423 ref_len = 77050)\n",
      "2022-04-02 15:05:26 | INFO | ml-hw5 | saved epoch checkpoint: /home/user/homework/ML/hw5/checkpoints/transformer_zh-en/checkpoint13.pt\n",
      "2022-04-02 15:05:26 | INFO | ml-hw5 | end of epoch 13\n",
      "2022-04-02 15:05:27 | INFO | fairseq.data.iterators | grouped total_num_itrs = 800\n",
      "2022-04-02 15:08:18 | INFO | ml-hw5 | training loss: 2.5571                 \n",
      "2022-04-02 15:08:18 | INFO | ml-hw5 | begin validation\n",
      "2022-04-02 15:08:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2022-04-02 15:08:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2022-04-02 15:08:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
      "2022-04-02 15:08:36 | INFO | ml-hw5 | example source: 所以 , 我們說 , 好 , 咱們來研究看看這是如何發生的 , 先看科學 。\n",
      "2022-04-02 15:08:36 | INFO | ml-hw5 | example hypothesis: so we said , okay , let's look at what's going to happen first at science .\n",
      "2022-04-02 15:08:36 | INFO | ml-hw5 | example reference: so we said , ok , let's figure out how does this really happen , first in science .\n",
      "2022-04-02 15:08:36 | INFO | ml-hw5 | validation loss:\t2.6382\n",
      "2022-04-02 15:08:36 | INFO | ml-hw5 | BLEU = 19.89 57.8/28.7/16.1/9.3 (BP = 0.891 ratio = 0.897 hyp_len = 69081 ref_len = 77050)\n",
      "2022-04-02 15:08:37 | INFO | ml-hw5 | saved epoch checkpoint: /home/user/homework/ML/hw5/checkpoints/transformer_zh-en/checkpoint14.pt\n",
      "2022-04-02 15:08:37 | INFO | ml-hw5 | end of epoch 14\n",
      "2022-04-02 15:08:37 | INFO | fairseq.data.iterators | grouped total_num_itrs = 800\n",
      "2022-04-02 15:11:30 | INFO | ml-hw5 | training loss: 2.5443                 \n",
      "2022-04-02 15:11:30 | INFO | ml-hw5 | begin validation\n",
      "2022-04-02 15:11:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2022-04-02 15:11:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2022-04-02 15:11:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
      "2022-04-02 15:11:48 | INFO | ml-hw5 | example source: 然而此時此刻我們滅絕這些病症的能力也已經達到了超乎想像的高峰\n",
      "2022-04-02 15:11:48 | INFO | ml-hw5 | example hypothesis: but at this point , our ability to extinct these symptoms is now achieved incredible peaks .\n",
      "2022-04-02 15:11:48 | INFO | ml-hw5 | example reference: and yet we also live at the moment when our ability to eliminate those conditions has reached a height we never imagined before .\n",
      "2022-04-02 15:11:48 | INFO | ml-hw5 | validation loss:\t2.6220\n",
      "2022-04-02 15:11:48 | INFO | ml-hw5 | BLEU = 20.54 56.3/28.0/15.8/9.2 (BP = 0.939 ratio = 0.941 hyp_len = 72508 ref_len = 77050)\n",
      "2022-04-02 15:11:49 | INFO | ml-hw5 | saved epoch checkpoint: /home/user/homework/ML/hw5/checkpoints/transformer_zh-en/checkpoint15.pt\n",
      "2022-04-02 15:11:49 | INFO | ml-hw5 | end of epoch 15\n",
      "2022-04-02 15:11:50 | INFO | fairseq.data.iterators | grouped total_num_itrs = 800\n",
      "2022-04-02 15:14:43 | INFO | ml-hw5 | training loss: 2.5335                 \n",
      "2022-04-02 15:14:43 | INFO | ml-hw5 | begin validation\n",
      "2022-04-02 15:15:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2022-04-02 15:15:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2022-04-02 15:15:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
      "2022-04-02 15:15:01 | INFO | ml-hw5 | example source: 是因為勤奮的工作 。 是因為我們發現了有關恐怖活動的情報並且以不同的方式禁止 , 通過執法 , 通過和其他國家的合作 , 而且有時候通過軍事活動 。\n",
      "2022-04-02 15:15:01 | INFO | ml-hw5 | example hypothesis: it's because of hard work , because we discovered intelligence about terror activities and banned it in a different way , through law enforcement , through collaboration with other countries , and sometimes through military activity .\n",
      "2022-04-02 15:15:01 | INFO | ml-hw5 | example reference: that's hard work . that's us finding intelligence on terrorist activities and interdicting them through one way or another , through law enforcement , through cooperative activities with other countries and sometimes through military action .\n",
      "2022-04-02 15:15:01 | INFO | ml-hw5 | validation loss:\t2.6227\n",
      "2022-04-02 15:15:01 | INFO | ml-hw5 | BLEU = 20.25 57.7/28.8/16.3/9.6 (BP = 0.896 ratio = 0.901 hyp_len = 69454 ref_len = 77050)\n",
      "2022-04-02 15:15:02 | INFO | ml-hw5 | saved epoch checkpoint: /home/user/homework/ML/hw5/checkpoints/transformer_zh-en/checkpoint16.pt\n",
      "2022-04-02 15:15:02 | INFO | ml-hw5 | end of epoch 16\n",
      "2022-04-02 15:15:02 | INFO | fairseq.data.iterators | grouped total_num_itrs = 800\n",
      "2022-04-02 15:17:56 | INFO | ml-hw5 | training loss: 2.5204                 \n",
      "2022-04-02 15:17:56 | INFO | ml-hw5 | begin validation\n",
      "2022-04-02 15:18:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2022-04-02 15:18:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2022-04-02 15:18:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
      "2022-04-02 15:18:14 | INFO | ml-hw5 | example source: 這是過去40年來女性不斷倡導的結果\n",
      "2022-04-02 15:18:14 | INFO | ml-hw5 | example hypothesis: this is what women have advocated for the last 40 years .\n",
      "2022-04-02 15:18:14 | INFO | ml-hw5 | example reference: and that is the 40 years that women have advocated .\n",
      "2022-04-02 15:18:14 | INFO | ml-hw5 | validation loss:\t2.6205\n",
      "2022-04-02 15:18:14 | INFO | ml-hw5 | BLEU = 20.08 57.9/28.9/16.4/9.6 (BP = 0.887 ratio = 0.893 hyp_len = 68774 ref_len = 77050)\n",
      "2022-04-02 15:18:15 | INFO | ml-hw5 | saved epoch checkpoint: /home/user/homework/ML/hw5/checkpoints/transformer_zh-en/checkpoint17.pt\n",
      "2022-04-02 15:18:15 | INFO | ml-hw5 | end of epoch 17\n",
      "2022-04-02 15:18:15 | INFO | fairseq.data.iterators | grouped total_num_itrs = 800\n",
      "2022-04-02 15:21:07 | INFO | ml-hw5 | training loss: 2.5107                 \n",
      "2022-04-02 15:21:07 | INFO | ml-hw5 | begin validation\n",
      "2022-04-02 15:21:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2022-04-02 15:21:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2022-04-02 15:21:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
      "2022-04-02 15:21:26 | INFO | ml-hw5 | example source: 所有人都安全了 。\n",
      "2022-04-02 15:21:26 | INFO | ml-hw5 | example hypothesis: everyone's safe .\n",
      "2022-04-02 15:21:26 | INFO | ml-hw5 | example reference: and no one got killed .\n",
      "2022-04-02 15:21:26 | INFO | ml-hw5 | validation loss:\t2.6204\n",
      "2022-04-02 15:21:26 | INFO | ml-hw5 | BLEU = 20.19 58.0/29.0/16.4/9.6 (BP = 0.891 ratio = 0.897 hyp_len = 69091 ref_len = 77050)\n",
      "2022-04-02 15:21:26 | INFO | ml-hw5 | saved epoch checkpoint: /home/user/homework/ML/hw5/checkpoints/transformer_zh-en/checkpoint18.pt\n",
      "2022-04-02 15:21:26 | INFO | ml-hw5 | end of epoch 18\n",
      "2022-04-02 15:21:26 | INFO | fairseq.data.iterators | grouped total_num_itrs = 800\n",
      "2022-04-02 15:24:19 | INFO | ml-hw5 | training loss: 2.4995                 \n",
      "2022-04-02 15:24:19 | INFO | ml-hw5 | begin validation\n",
      "2022-04-02 15:24:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2022-04-02 15:24:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2022-04-02 15:24:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
      "2022-04-02 15:24:37 | INFO | ml-hw5 | example source: 其他人則是靠著很不適合的獨木舟 , 孤注一擲試圖前往西班牙 。\n",
      "2022-04-02 15:24:37 | INFO | ml-hw5 | example hypothesis: others rely on uncomfortable canoes , flip a throw to spain .\n",
      "2022-04-02 15:24:37 | INFO | ml-hw5 | example reference: others end up on inadequate wooden canoes in desperate attempts to reach spain .\n",
      "2022-04-02 15:24:37 | INFO | ml-hw5 | validation loss:\t2.6172\n",
      "2022-04-02 15:24:37 | INFO | ml-hw5 | BLEU = 20.30 58.2/29.3/16.7/9.7 (BP = 0.885 ratio = 0.891 hyp_len = 68665 ref_len = 77050)\n",
      "2022-04-02 15:24:38 | INFO | ml-hw5 | saved epoch checkpoint: /home/user/homework/ML/hw5/checkpoints/transformer_zh-en/checkpoint19.pt\n",
      "2022-04-02 15:24:38 | INFO | ml-hw5 | end of epoch 19\n",
      "2022-04-02 15:24:38 | INFO | fairseq.data.iterators | grouped total_num_itrs = 800\n",
      "2022-04-02 15:27:32 | INFO | ml-hw5 | training loss: 2.4900                 \n",
      "2022-04-02 15:27:32 | INFO | ml-hw5 | begin validation\n",
      "2022-04-02 15:27:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2022-04-02 15:27:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2022-04-02 15:27:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
      "2022-04-02 15:27:50 | INFO | ml-hw5 | example source: 對了 , 如果你還沒有注意到 , 我是黑人 , 謝謝 。 如果你像我一樣 , 生長在種族隔離的城市 , 例如芝加哥 , 你自然而然就相信膚色和種族永遠是分不開的 。\n",
      "2022-04-02 15:27:50 | INFO | ml-hw5 | example hypothesis: by the way , if you haven't noticed , i'm black , thank you . if you grow in apartheid cities like chicago , you naturally believe that skin color and race are never separated .\n",
      "2022-04-02 15:27:50 | INFO | ml-hw5 | example reference: now , if you haven't noticed , i am black , thank you and when you grow up in a segregated city as i have , like chicago , you're conditioned to believe that color and race can never be separate .\n",
      "2022-04-02 15:27:50 | INFO | ml-hw5 | validation loss:\t2.6163\n",
      "2022-04-02 15:27:50 | INFO | ml-hw5 | BLEU = 20.53 57.6/28.9/16.4/9.6 (BP = 0.908 ratio = 0.912 hyp_len = 70289 ref_len = 77050)\n",
      "2022-04-02 15:27:51 | INFO | ml-hw5 | saved epoch checkpoint: /home/user/homework/ML/hw5/checkpoints/transformer_zh-en/checkpoint20.pt\n",
      "2022-04-02 15:27:51 | INFO | ml-hw5 | end of epoch 20\n",
      "2022-04-02 15:27:51 | INFO | fairseq.data.iterators | grouped total_num_itrs = 800\n",
      "2022-04-02 15:30:44 | INFO | ml-hw5 | training loss: 2.4807                 \n",
      "2022-04-02 15:30:44 | INFO | ml-hw5 | begin validation\n",
      "2022-04-02 15:31:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2022-04-02 15:31:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2022-04-02 15:31:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
      "2022-04-02 15:31:03 | INFO | ml-hw5 | example source: 如果你是使用蘋果的keynote , 就有更好的版本能用\n",
      "2022-04-02 15:31:03 | INFO | ml-hw5 | example hypothesis: if you're using an apple's note , there's a better version of it .\n",
      "2022-04-02 15:31:03 | INFO | ml-hw5 | example reference: if you use apple's keynote , it's got an even better version .\n",
      "2022-04-02 15:31:03 | INFO | ml-hw5 | validation loss:\t2.6117\n",
      "2022-04-02 15:31:03 | INFO | ml-hw5 | BLEU = 20.59 57.4/28.8/16.3/9.5 (BP = 0.915 ratio = 0.919 hyp_len = 70776 ref_len = 77050)\n",
      "2022-04-02 15:31:03 | INFO | ml-hw5 | saved epoch checkpoint: /home/user/homework/ML/hw5/checkpoints/transformer_zh-en/checkpoint21.pt\n",
      "2022-04-02 15:31:03 | INFO | ml-hw5 | end of epoch 21\n",
      "2022-04-02 15:31:04 | INFO | fairseq.data.iterators | grouped total_num_itrs = 800\n",
      "2022-04-02 15:33:56 | INFO | ml-hw5 | training loss: 2.4723                 \n",
      "2022-04-02 15:33:56 | INFO | ml-hw5 | begin validation\n",
      "2022-04-02 15:34:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2022-04-02 15:34:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2022-04-02 15:34:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
      "2022-04-02 15:34:14 | INFO | ml-hw5 | example source: 這是1970年中國的收入分配\n",
      "2022-04-02 15:34:14 | INFO | ml-hw5 | example hypothesis: this is china's income distribution in 1970 .\n",
      "2022-04-02 15:34:14 | INFO | ml-hw5 | example reference: this is the income distribution of china , 1970 .\n",
      "2022-04-02 15:34:14 | INFO | ml-hw5 | validation loss:\t2.6112\n",
      "2022-04-02 15:34:14 | INFO | ml-hw5 | BLEU = 20.27 58.5/29.4/16.6/9.7 (BP = 0.882 ratio = 0.888 hyp_len = 68451 ref_len = 77050)\n",
      "2022-04-02 15:34:15 | INFO | ml-hw5 | saved epoch checkpoint: /home/user/homework/ML/hw5/checkpoints/transformer_zh-en/checkpoint22.pt\n",
      "2022-04-02 15:34:15 | INFO | ml-hw5 | end of epoch 22\n",
      "2022-04-02 15:34:15 | INFO | fairseq.data.iterators | grouped total_num_itrs = 800\n",
      "2022-04-02 15:37:08 | INFO | ml-hw5 | training loss: 2.4646                 \n",
      "2022-04-02 15:37:08 | INFO | ml-hw5 | begin validation\n",
      "2022-04-02 15:37:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2022-04-02 15:37:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2022-04-02 15:37:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
      "2022-04-02 15:37:26 | INFO | ml-hw5 | example source: 他是律師兼作家 , 笑的時候眼睛閃閃發光 , 我親他的時候 , 他緊緊閉上雙眼 , 在那晚的某一刻 , 我們的第零次約會\n",
      "2022-04-02 15:37:26 | INFO | ml-hw5 | example hypothesis: he's a lawyer and author , and he's a smile , and he's tightly closing his eyes , and at some point at that time , our zero dates .\n",
      "2022-04-02 15:37:26 | INFO | ml-hw5 | example reference: he was a lawyer and a writer , and his eyes twinkled when he laughed and they squeezed tight when i kissed him and at some point in the evening , our zero date became a first date .\n",
      "2022-04-02 15:37:26 | INFO | ml-hw5 | validation loss:\t2.6053\n",
      "2022-04-02 15:37:26 | INFO | ml-hw5 | BLEU = 20.53 57.6/28.9/16.4/9.6 (BP = 0.907 ratio = 0.911 hyp_len = 70190 ref_len = 77050)\n",
      "2022-04-02 15:37:26 | INFO | ml-hw5 | saved epoch checkpoint: /home/user/homework/ML/hw5/checkpoints/transformer_zh-en/checkpoint23.pt\n",
      "2022-04-02 15:37:26 | INFO | ml-hw5 | end of epoch 23\n",
      "2022-04-02 15:37:27 | INFO | fairseq.data.iterators | grouped total_num_itrs = 800\n",
      "2022-04-02 15:40:20 | INFO | ml-hw5 | training loss: 2.4571                 \n",
      "2022-04-02 15:40:20 | INFO | ml-hw5 | begin validation\n",
      "2022-04-02 15:40:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2022-04-02 15:40:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2022-04-02 15:40:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
      "2022-04-02 15:40:39 | INFO | ml-hw5 | example source: 用特斯拉 , 因你要有永續能源 , 所以造出這麽勁爆的車子來實現你的目標 。\n",
      "2022-04-02 15:40:39 | INFO | ml-hw5 | example hypothesis: using tesla , because you have to have sustainable energy , you have to make this sorry burning car to achieve your goal .\n",
      "2022-04-02 15:40:39 | INFO | ml-hw5 | example reference: with tesla , you want to have sustainable energy , so you made these super sexy , exciting cars to do it .\n",
      "2022-04-02 15:40:39 | INFO | ml-hw5 | validation loss:\t2.6082\n",
      "2022-04-02 15:40:39 | INFO | ml-hw5 | BLEU = 20.51 57.4/28.8/16.3/9.4 (BP = 0.914 ratio = 0.917 hyp_len = 70661 ref_len = 77050)\n",
      "2022-04-02 15:40:39 | INFO | ml-hw5 | saved epoch checkpoint: /home/user/homework/ML/hw5/checkpoints/transformer_zh-en/checkpoint24.pt\n",
      "2022-04-02 15:40:39 | INFO | ml-hw5 | end of epoch 24\n",
      "2022-04-02 15:40:40 | INFO | fairseq.data.iterators | grouped total_num_itrs = 800\n",
      "2022-04-02 15:43:33 | INFO | ml-hw5 | training loss: 2.4506                 \n",
      "2022-04-02 15:43:33 | INFO | ml-hw5 | begin validation\n",
      "2022-04-02 15:43:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2022-04-02 15:43:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2022-04-02 15:43:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
      "2022-04-02 15:43:51 | INFO | ml-hw5 | example source: 你要做的 , 就是把你的問題和以前別人所遇到的問題做比對 , 再利用他們已經想出的辦法來解決 。\n",
      "2022-04-02 15:43:51 | INFO | ml-hw5 | example hypothesis: what you have to do is compare your problems to the problems that people have faced before , and then use the solutions that they've come up with .\n",
      "2022-04-02 15:43:51 | INFO | ml-hw5 | example reference: because what you can do is take your problem , and turn it into a problem that someone else has solved , and use their solutions .\n",
      "2022-04-02 15:43:51 | INFO | ml-hw5 | validation loss:\t2.6048\n",
      "2022-04-02 15:43:51 | INFO | ml-hw5 | BLEU = 20.71 57.5/28.8/16.4/9.6 (BP = 0.917 ratio = 0.921 hyp_len = 70937 ref_len = 77050)\n",
      "2022-04-02 15:43:52 | INFO | ml-hw5 | saved epoch checkpoint: /home/user/homework/ML/hw5/checkpoints/transformer_zh-en/checkpoint25.pt\n",
      "2022-04-02 15:43:52 | INFO | ml-hw5 | end of epoch 25\n",
      "2022-04-02 15:43:53 | INFO | fairseq.data.iterators | grouped total_num_itrs = 800\n",
      "2022-04-02 15:46:45 | INFO | ml-hw5 | training loss: 2.4441                 \n",
      "2022-04-02 15:46:45 | INFO | ml-hw5 | begin validation\n",
      "2022-04-02 15:47:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2022-04-02 15:47:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2022-04-02 15:47:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
      "2022-04-02 15:47:04 | INFO | ml-hw5 | example source: 在同樣的狀況下他們該怎麼做 ?\n",
      "2022-04-02 15:47:04 | INFO | ml-hw5 | example hypothesis: how do they do it in the same situation ?\n",
      "2022-04-02 15:47:04 | INFO | ml-hw5 | example reference: what would they do under the same conditions ?\n",
      "2022-04-02 15:47:04 | INFO | ml-hw5 | validation loss:\t2.6076\n",
      "2022-04-02 15:47:04 | INFO | ml-hw5 | BLEU = 20.56 58.3/29.3/16.6/9.7 (BP = 0.898 ratio = 0.903 hyp_len = 69569 ref_len = 77050)\n",
      "2022-04-02 15:47:04 | INFO | ml-hw5 | saved epoch checkpoint: /home/user/homework/ML/hw5/checkpoints/transformer_zh-en/checkpoint26.pt\n",
      "2022-04-02 15:47:05 | INFO | ml-hw5 | end of epoch 26\n",
      "2022-04-02 15:47:05 | INFO | fairseq.data.iterators | grouped total_num_itrs = 800\n",
      "2022-04-02 15:49:58 | INFO | ml-hw5 | training loss: 2.4365                 \n",
      "2022-04-02 15:49:58 | INFO | ml-hw5 | begin validation\n",
      "2022-04-02 15:50:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2022-04-02 15:50:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2022-04-02 15:50:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
      "2022-04-02 15:50:16 | INFO | ml-hw5 | example source: 這帶給我想到第三個假設而這也許是問題最大的假設: \" 永遠不要對選擇說不 \" 。\n",
      "2022-04-02 15:50:16 | INFO | ml-hw5 | example hypothesis: and this brings me to my third assumption , which perhaps the biggest hypothesis is , \" never say no to choosing . \"\n",
      "2022-04-02 15:50:16 | INFO | ml-hw5 | example reference: this brings me to the third , and perhaps most problematic , assumption: \" you must never say no to choice . \"\n",
      "2022-04-02 15:50:16 | INFO | ml-hw5 | validation loss:\t2.6020\n",
      "2022-04-02 15:50:17 | INFO | ml-hw5 | BLEU = 20.63 58.1/29.3/16.6/9.7 (BP = 0.901 ratio = 0.906 hyp_len = 69777 ref_len = 77050)\n",
      "2022-04-02 15:50:17 | INFO | ml-hw5 | saved epoch checkpoint: /home/user/homework/ML/hw5/checkpoints/transformer_zh-en/checkpoint27.pt\n",
      "2022-04-02 15:50:17 | INFO | ml-hw5 | end of epoch 27\n",
      "2022-04-02 15:50:17 | INFO | fairseq.data.iterators | grouped total_num_itrs = 800\n",
      "2022-04-02 15:53:09 | INFO | ml-hw5 | training loss: 2.4303                 \n",
      "2022-04-02 15:53:09 | INFO | ml-hw5 | begin validation\n",
      "2022-04-02 15:53:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2022-04-02 15:53:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2022-04-02 15:53:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
      "2022-04-02 15:53:27 | INFO | ml-hw5 | example source: 沒有錢乘車 , 他們通常都會坐在卡車頂上 , 在這裡則是坐在橫越南蘇丹的火車頂上 。\n",
      "2022-04-02 15:53:27 | INFO | ml-hw5 | example hypothesis: no money rides , they're usually sitting on top of trucks , and here on the top of a train across vietnam .\n",
      "2022-04-02 15:53:27 | INFO | ml-hw5 | example reference: with no money for rides , they often made the mzungu ride on the roof of the trucks , or in this case , on the top of the train going across south sudan .\n",
      "2022-04-02 15:53:27 | INFO | ml-hw5 | validation loss:\t2.6003\n",
      "2022-04-02 15:53:27 | INFO | ml-hw5 | BLEU = 20.47 58.1/29.1/16.5/9.7 (BP = 0.897 ratio = 0.902 hyp_len = 69495 ref_len = 77050)\n",
      "2022-04-02 15:53:28 | INFO | ml-hw5 | saved epoch checkpoint: /home/user/homework/ML/hw5/checkpoints/transformer_zh-en/checkpoint28.pt\n",
      "2022-04-02 15:53:28 | INFO | ml-hw5 | end of epoch 28\n",
      "2022-04-02 15:53:28 | INFO | fairseq.data.iterators | grouped total_num_itrs = 800\n",
      "2022-04-02 15:56:22 | INFO | ml-hw5 | training loss: 2.4243                 \n",
      "2022-04-02 15:56:22 | INFO | ml-hw5 | begin validation\n",
      "2022-04-02 15:56:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2022-04-02 15:56:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2022-04-02 15:56:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
      "2022-04-02 15:56:40 | INFO | ml-hw5 | example source: 我可以把鏡頭向右旋轉一點 , 你就會失焦 , 而背景的人會凸顯出來 。\n",
      "2022-04-02 15:56:40 | INFO | ml-hw5 | example hypothesis: i can rotate the camera a little bit to the right , and you'll lose the focus , and the people in the background reveal it .\n",
      "2022-04-02 15:56:40 | INFO | ml-hw5 | example reference: i could move the lens a little to the right , and you would go back and the folks in the background would come out .\n",
      "2022-04-02 15:56:40 | INFO | ml-hw5 | validation loss:\t2.5979\n",
      "2022-04-02 15:56:40 | INFO | ml-hw5 | BLEU = 20.49 58.5/29.6/16.8/9.9 (BP = 0.884 ratio = 0.890 hyp_len = 68610 ref_len = 77050)\n",
      "2022-04-02 15:56:41 | INFO | ml-hw5 | saved epoch checkpoint: /home/user/homework/ML/hw5/checkpoints/transformer_zh-en/checkpoint29.pt\n",
      "2022-04-02 15:56:41 | INFO | ml-hw5 | end of epoch 29\n",
      "2022-04-02 15:56:41 | INFO | fairseq.data.iterators | grouped total_num_itrs = 800\n",
      "2022-04-02 15:59:34 | INFO | ml-hw5 | training loss: 2.4173                 \n",
      "2022-04-02 15:59:34 | INFO | ml-hw5 | begin validation\n",
      "2022-04-02 15:59:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2022-04-02 15:59:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2022-04-02 15:59:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
      "2022-04-02 15:59:52 | INFO | ml-hw5 | example source: 身為白人女性 , 我們得要做更多 , 因為種族主義、性別主義 , 和恐同性戀症 , 是影響我們所有人的議題 。\n",
      "2022-04-02 15:59:52 | INFO | ml-hw5 | example hypothesis: as white women , we need to do more , because racism , genderism and terrorism are the issues that affect all of us .\n",
      "2022-04-02 15:59:52 | INFO | ml-hw5 | example reference: and as white women , we have to do more , because racism and sexism and homophobia , these are issues that affect all of us .\n",
      "2022-04-02 15:59:52 | INFO | ml-hw5 | validation loss:\t2.5978\n",
      "2022-04-02 15:59:52 | INFO | ml-hw5 | BLEU = 20.83 57.4/28.9/16.5/9.7 (BP = 0.918 ratio = 0.921 hyp_len = 70978 ref_len = 77050)\n",
      "2022-04-02 15:59:53 | INFO | ml-hw5 | saved epoch checkpoint: /home/user/homework/ML/hw5/checkpoints/transformer_zh-en/checkpoint30.pt\n",
      "2022-04-02 15:59:54 | INFO | ml-hw5 | end of epoch 30\n",
      "2022-04-02 15:59:54 | INFO | fairseq.data.iterators | grouped total_num_itrs = 800\n",
      "2022-04-02 16:02:47 | INFO | ml-hw5 | training loss: 2.4126                 \n",
      "2022-04-02 16:02:47 | INFO | ml-hw5 | begin validation\n",
      "2022-04-02 16:03:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2022-04-02 16:03:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2022-04-02 16:03:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
      "2022-04-02 16:03:06 | INFO | ml-hw5 | example source: 他們見到一些神奇的事物 ,\n",
      "2022-04-02 16:03:06 | INFO | ml-hw5 | example hypothesis: they saw some magical things .\n",
      "2022-04-02 16:03:06 | INFO | ml-hw5 | example reference: they were seeing something magical .\n",
      "2022-04-02 16:03:06 | INFO | ml-hw5 | validation loss:\t2.5983\n",
      "2022-04-02 16:03:06 | INFO | ml-hw5 | BLEU = 20.62 57.9/29.1/16.5/9.8 (BP = 0.902 ratio = 0.907 hyp_len = 69851 ref_len = 77050)\n",
      "2022-04-02 16:03:06 | INFO | ml-hw5 | saved epoch checkpoint: /home/user/homework/ML/hw5/checkpoints/transformer_zh-en/checkpoint31.pt\n",
      "2022-04-02 16:03:06 | INFO | ml-hw5 | end of epoch 31\n",
      "2022-04-02 16:03:07 | INFO | fairseq.data.iterators | grouped total_num_itrs = 800\n",
      "2022-04-02 16:06:00 | INFO | ml-hw5 | training loss: 2.4079                 \n",
      "2022-04-02 16:06:00 | INFO | ml-hw5 | begin validation\n",
      "2022-04-02 16:06:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2022-04-02 16:06:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2022-04-02 16:06:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
      "2022-04-02 16:06:18 | INFO | ml-hw5 | example source: 我覺得沒人在乎我 , 鋃鐺入獄讓我滿腹怨恨 。\n",
      "2022-04-02 16:06:18 | INFO | ml-hw5 | example hypothesis: i felt like nobody cared me , nigeria went to jail and resented me .\n",
      "2022-04-02 16:06:18 | INFO | ml-hw5 | example reference: i felt like nobody cared , and i reacted with hostility to my confinement .\n",
      "2022-04-02 16:06:18 | INFO | ml-hw5 | validation loss:\t2.5936\n",
      "2022-04-02 16:06:18 | INFO | ml-hw5 | BLEU = 20.68 57.9/29.1/16.5/9.6 (BP = 0.908 ratio = 0.912 hyp_len = 70299 ref_len = 77050)\n",
      "2022-04-02 16:06:18 | INFO | ml-hw5 | saved epoch checkpoint: /home/user/homework/ML/hw5/checkpoints/transformer_zh-en/checkpoint32.pt\n",
      "2022-04-02 16:06:18 | INFO | ml-hw5 | end of epoch 32\n",
      "2022-04-02 16:06:19 | INFO | fairseq.data.iterators | grouped total_num_itrs = 800\n",
      "2022-04-02 16:09:12 | INFO | ml-hw5 | training loss: 2.4024                 \n",
      "2022-04-02 16:09:12 | INFO | ml-hw5 | begin validation\n",
      "2022-04-02 16:09:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2022-04-02 16:09:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2022-04-02 16:09:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
      "2022-04-02 16:09:30 | INFO | ml-hw5 | example source: 根據世界銀行的估計 , 每年賄賂的總額約為一兆美元 , 這讓原本就很糟的情況雪上加霜 。\n",
      "2022-04-02 16:09:30 | INFO | ml-hw5 | example hypothesis: according to the estimates of the world bank , the total bribery is about a trillion dollars a year , and it adds frost .\n",
      "2022-04-02 16:09:30 | INFO | ml-hw5 | example reference: according to world bank estimate , one trillion dollars is paid in bribes every year , worsening the condition of the already worse off .\n",
      "2022-04-02 16:09:30 | INFO | ml-hw5 | validation loss:\t2.6001\n",
      "2022-04-02 16:09:30 | INFO | ml-hw5 | BLEU = 20.87 58.0/29.3/16.7/9.8 (BP = 0.910 ratio = 0.914 hyp_len = 70397 ref_len = 77050)\n",
      "2022-04-02 16:09:30 | INFO | ml-hw5 | saved epoch checkpoint: /home/user/homework/ML/hw5/checkpoints/transformer_zh-en/checkpoint33.pt\n",
      "2022-04-02 16:09:31 | INFO | ml-hw5 | end of epoch 33\n",
      "2022-04-02 16:09:31 | INFO | fairseq.data.iterators | grouped total_num_itrs = 800\n",
      "2022-04-02 16:12:24 | INFO | ml-hw5 | training loss: 2.3984                 \n",
      "2022-04-02 16:12:24 | INFO | ml-hw5 | begin validation\n",
      "2022-04-02 16:12:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2022-04-02 16:12:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2022-04-02 16:12:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
      "2022-04-02 16:12:43 | INFO | ml-hw5 | example source: 好 。 我是日本移民的第三代 , 我的祖父母來到美國 , 勇敢地踏進一個新奇的世界 , 尋找新的機會 。\n",
      "2022-04-02 16:12:43 | INFO | ml-hw5 | example hypothesis: ok . i'm the third generation of japanese immigrants , and my grandparents come to the united states to courageously step into a novelty world and find new opportunities .\n",
      "2022-04-02 16:12:43 | INFO | ml-hw5 | example reference: well — — i am the grandson of immigrants from japan who went to america , boldly going to a strange new world , seeking new opportunities .\n",
      "2022-04-02 16:12:43 | INFO | ml-hw5 | validation loss:\t2.5975\n",
      "2022-04-02 16:12:43 | INFO | ml-hw5 | BLEU = 20.65 58.1/29.3/16.7/9.8 (BP = 0.899 ratio = 0.904 hyp_len = 69661 ref_len = 77050)\n",
      "2022-04-02 16:12:43 | INFO | ml-hw5 | saved epoch checkpoint: /home/user/homework/ML/hw5/checkpoints/transformer_zh-en/checkpoint34.pt\n",
      "2022-04-02 16:12:43 | INFO | ml-hw5 | end of epoch 34\n",
      "2022-04-02 16:12:44 | INFO | fairseq.data.iterators | grouped total_num_itrs = 800\n",
      "2022-04-02 16:15:37 | INFO | ml-hw5 | training loss: 2.3932                 \n",
      "2022-04-02 16:15:37 | INFO | ml-hw5 | begin validation\n",
      "2022-04-02 16:15:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2022-04-02 16:15:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2022-04-02 16:15:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
      "2022-04-02 16:15:55 | INFO | ml-hw5 | example source: 這有點像是獨白 , 在很多我做的錄音訪談裡都有獨白 。\n",
      "2022-04-02 16:15:55 | INFO | ml-hw5 | example hypothesis: it's kind of like monologues , and it's got monologues in many of the recording interviews i've done .\n",
      "2022-04-02 16:15:55 | INFO | ml-hw5 | example reference: it's a kind of an aria , i would say , and in many tapes that i have .\n",
      "2022-04-02 16:15:55 | INFO | ml-hw5 | validation loss:\t2.5933\n",
      "2022-04-02 16:15:55 | INFO | ml-hw5 | BLEU = 20.98 57.8/29.2/16.6/9.8 (BP = 0.916 ratio = 0.920 hyp_len = 70867 ref_len = 77050)\n",
      "2022-04-02 16:15:56 | INFO | ml-hw5 | saved epoch checkpoint: /home/user/homework/ML/hw5/checkpoints/transformer_zh-en/checkpoint35.pt\n",
      "2022-04-02 16:15:56 | INFO | ml-hw5 | end of epoch 35\n",
      "2022-04-02 16:15:57 | INFO | fairseq.data.iterators | grouped total_num_itrs = 800\n",
      "2022-04-02 16:18:49 | INFO | ml-hw5 | training loss: 2.3877                 \n",
      "2022-04-02 16:18:49 | INFO | ml-hw5 | begin validation\n",
      "2022-04-02 16:19:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2022-04-02 16:19:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2022-04-02 16:19:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
      "2022-04-02 16:19:08 | INFO | ml-hw5 | example source: 人們知道我很熱心 , 我是個快樂的人 。 」\n",
      "2022-04-02 16:19:08 | INFO | ml-hw5 | example hypothesis: people know i'm happy . i'm happy . \"\n",
      "2022-04-02 16:19:08 | INFO | ml-hw5 | example reference: people know now that i'm enthusiastic , that i'm a happy person . \"\n",
      "2022-04-02 16:19:08 | INFO | ml-hw5 | validation loss:\t2.5984\n",
      "2022-04-02 16:19:08 | INFO | ml-hw5 | BLEU = 20.72 58.5/29.6/16.9/9.9 (BP = 0.893 ratio = 0.898 hyp_len = 69202 ref_len = 77050)\n",
      "2022-04-02 16:19:08 | INFO | ml-hw5 | saved epoch checkpoint: /home/user/homework/ML/hw5/checkpoints/transformer_zh-en/checkpoint36.pt\n",
      "2022-04-02 16:19:08 | INFO | ml-hw5 | end of epoch 36\n",
      "2022-04-02 16:19:09 | INFO | fairseq.data.iterators | grouped total_num_itrs = 800\n",
      "2022-04-02 16:22:02 | INFO | ml-hw5 | training loss: 2.3835                 \n",
      "2022-04-02 16:22:02 | INFO | ml-hw5 | begin validation\n",
      "2022-04-02 16:22:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2022-04-02 16:22:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2022-04-02 16:22:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
      "2022-04-02 16:22:20 | INFO | ml-hw5 | example source: 所以我並沒有辦法解決 。\n",
      "2022-04-02 16:22:20 | INFO | ml-hw5 | example hypothesis: so i couldn't fix it .\n",
      "2022-04-02 16:22:20 | INFO | ml-hw5 | example reference: so i couldn't handle it .\n",
      "2022-04-02 16:22:20 | INFO | ml-hw5 | validation loss:\t2.5963\n",
      "2022-04-02 16:22:20 | INFO | ml-hw5 | BLEU = 21.03 57.9/29.3/16.8/9.9 (BP = 0.912 ratio = 0.916 hyp_len = 70561 ref_len = 77050)\n",
      "2022-04-02 16:22:21 | INFO | ml-hw5 | saved epoch checkpoint: /home/user/homework/ML/hw5/checkpoints/transformer_zh-en/checkpoint37.pt\n",
      "2022-04-02 16:22:21 | INFO | ml-hw5 | end of epoch 37\n",
      "2022-04-02 16:22:22 | INFO | fairseq.data.iterators | grouped total_num_itrs = 800\n",
      "2022-04-02 16:25:14 | INFO | ml-hw5 | training loss: 2.3793                 \n",
      "2022-04-02 16:25:14 | INFO | ml-hw5 | begin validation\n",
      "2022-04-02 16:25:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2022-04-02 16:25:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2022-04-02 16:25:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
      "2022-04-02 16:25:33 | INFO | ml-hw5 | example source: 但如果人人都是報導人的話真相便難以追蹤我們難以核實不同的線索不僅無法獲知真實意見更難以查明事實真相\n",
      "2022-04-02 16:25:33 | INFO | ml-hw5 | example hypothesis: but it's hard for us to track our truth if we're all covering people , and it's not only incapable of having a real opinion , it's incredibly difficult to see the truth .\n",
      "2022-04-02 16:25:33 | INFO | ml-hw5 | example reference: but if everyone is a reporter , nobody is , and different sources may disagree , not only opinions , but on the facts themselves .\n",
      "2022-04-02 16:25:33 | INFO | ml-hw5 | validation loss:\t2.5931\n",
      "2022-04-02 16:25:33 | INFO | ml-hw5 | BLEU = 21.03 58.3/29.6/16.9/9.9 (BP = 0.908 ratio = 0.912 hyp_len = 70243 ref_len = 77050)\n",
      "2022-04-02 16:25:33 | INFO | ml-hw5 | saved epoch checkpoint: /home/user/homework/ML/hw5/checkpoints/transformer_zh-en/checkpoint38.pt\n",
      "2022-04-02 16:25:33 | INFO | ml-hw5 | end of epoch 38\n",
      "2022-04-02 16:25:34 | INFO | fairseq.data.iterators | grouped total_num_itrs = 800\n",
      "2022-04-02 16:28:27 | INFO | ml-hw5 | training loss: 2.3763                 \n",
      "2022-04-02 16:28:27 | INFO | ml-hw5 | begin validation\n",
      "2022-04-02 16:28:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2022-04-02 16:28:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2022-04-02 16:28:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
      "2022-04-02 16:28:46 | INFO | ml-hw5 | example source: 因此從二月開始 , 我們開始一項基本收入的演示 , 在未來18個月 , 實驗隨機挑選130個家庭 , 選自市內收入低於中位數的地區 , 每個月給他們五百美金 。\n",
      "2022-04-02 16:28:46 | INFO | ml-hw5 | example hypothesis: so we started a basic income demonstration in february , and in the next 18 months , we took 130 randomly selected families and selected revenues below the middle income , 500 dollars a month .\n",
      "2022-04-02 16:28:46 | INFO | ml-hw5 | example reference: so starting in february , we launched a basic income demonstration , where for the next 18 months , as a pilot , 130 families , randomly selected , who live in zip codes at or below the median income of the city , are given 500 dollars a month .\n",
      "2022-04-02 16:28:46 | INFO | ml-hw5 | validation loss:\t2.5946\n",
      "2022-04-02 16:28:46 | INFO | ml-hw5 | BLEU = 21.10 57.9/29.4/16.8/9.8 (BP = 0.916 ratio = 0.920 hyp_len = 70848 ref_len = 77050)\n",
      "2022-04-02 16:28:46 | INFO | ml-hw5 | saved epoch checkpoint: /home/user/homework/ML/hw5/checkpoints/transformer_zh-en/checkpoint39.pt\n",
      "2022-04-02 16:28:47 | INFO | ml-hw5 | end of epoch 39\n",
      "2022-04-02 16:28:47 | INFO | fairseq.data.iterators | grouped total_num_itrs = 800\n",
      "2022-04-02 16:31:41 | INFO | ml-hw5 | training loss: 2.3723                 \n",
      "2022-04-02 16:31:41 | INFO | ml-hw5 | begin validation\n",
      "2022-04-02 16:31:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2022-04-02 16:31:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2022-04-02 16:31:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
      "2022-04-02 16:31:59 | INFO | ml-hw5 | example source: 另外一件事 。\n",
      "2022-04-02 16:31:59 | INFO | ml-hw5 | example hypothesis: here's another thing .\n",
      "2022-04-02 16:31:59 | INFO | ml-hw5 | example reference: then another thing .\n",
      "2022-04-02 16:31:59 | INFO | ml-hw5 | validation loss:\t2.6009\n",
      "2022-04-02 16:31:59 | INFO | ml-hw5 | BLEU = 20.75 58.4/29.6/16.8/9.8 (BP = 0.899 ratio = 0.904 hyp_len = 69645 ref_len = 77050)\n",
      "2022-04-02 16:32:00 | INFO | ml-hw5 | saved epoch checkpoint: /home/user/homework/ML/hw5/checkpoints/transformer_zh-en/checkpoint40.pt\n",
      "2022-04-02 16:32:00 | INFO | ml-hw5 | end of epoch 40\n"
     ]
    }
   ],
   "source": [
    "epoch_itr = load_data_iterator(task, \"train\", config.start_epoch, config.max_tokens, config.num_workers)\n",
    "try_load_checkpoint(model, optimizer, name=config.resume)\n",
    "while epoch_itr.next_epoch_idx <= config.max_epoch:\n",
    "    # train for one epoch\n",
    "    train_one_epoch(epoch_itr, model, task, criterion, optimizer, config.accum_steps)\n",
    "    stats = validate_and_save(model, task, criterion, optimizer, epoch=epoch_itr.epoch)\n",
    "    logger.info(\"end of epoch {}\".format(epoch_itr.epoch))    \n",
    "    epoch_itr = load_data_iterator(task, \"train\", epoch_itr.next_epoch_idx, config.max_tokens, config.num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KyjRwllxPjtf"
   },
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "N70Gc6smPi1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-02 16:32:01 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
      "Namespace(checkpoint_upper_bound=None, inputs=['./checkpoints/transformer_zh-en'], num_epoch_checkpoints=5, num_update_checkpoints=None, output='./checkpoints/transformer_zh-en/avg_last_5_checkpoint.pt')\n",
      "averaging checkpoints:  ['./checkpoints/transformer_zh-en/checkpoint40.pt', './checkpoints/transformer_zh-en/checkpoint39.pt', './checkpoints/transformer_zh-en/checkpoint38.pt', './checkpoints/transformer_zh-en/checkpoint37.pt', './checkpoints/transformer_zh-en/checkpoint36.pt']\n",
      "Finished writing averaged checkpoint to ./checkpoints/transformer_zh-en/avg_last_5_checkpoint.pt\n"
     ]
    }
   ],
   "source": [
    "# averaging a few checkpoints can have a similar effect to ensemble\n",
    "checkdir=config.savedir\n",
    "!python ./fairseq/scripts/average_checkpoints.py \\\n",
    "--inputs {checkdir} \\\n",
    "--num-epoch-checkpoints 5 \\\n",
    "--output {checkdir}/avg_last_5_checkpoint.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BAGMiun8PnZy"
   },
   "source": [
    "## Confirm model weights used to generate submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "tvRdivVUPnsU"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-02 16:32:02 | INFO | ml-hw5 | loaded checkpoint checkpoints/transformer_zh-en/avg_last_5_checkpoint.pt: step=unknown loss=2.600874662399292 bleu=20.751491776227514\n"
     ]
    }
   ],
   "source": [
    "# checkpoint_last.pt : latest epoch\n",
    "# checkpoint_best.pt : highest validation bleu\n",
    "# avg_last_5_checkpoint.pt:　the average of last 5 epochs\n",
    "try_load_checkpoint(model, name=\"avg_last_5_checkpoint.pt\")\n",
    "validate(model, task, criterion, log_to_wandb=False)\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ioAIflXpPsxt"
   },
   "source": [
    "## Generate Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "oYMxA8FlPtIq"
   },
   "outputs": [],
   "source": [
    "def generate_prediction(model, task, split=\"test\", outfile=\"./prediction.txt\"):    \n",
    "    task.load_dataset(split=split, epoch=1)\n",
    "    itr = load_data_iterator(task, split, 1, config.max_tokens, config.num_workers).next_epoch_itr(shuffle=False)\n",
    "    \n",
    "    idxs = []\n",
    "    hyps = []\n",
    "\n",
    "    model.eval()\n",
    "    progress = tqdm.tqdm(itr, desc=f\"prediction\")\n",
    "    with torch.no_grad():\n",
    "        for i, sample in enumerate(progress):\n",
    "            # validation loss\n",
    "            sample = utils.move_to_cuda(sample, device=device)\n",
    "\n",
    "            # do inference\n",
    "            s, h, r = inference_step(sample, model)\n",
    "            \n",
    "            hyps.extend(h)\n",
    "            idxs.extend(list(sample['id']))\n",
    "            \n",
    "    # sort based on the order before preprocess\n",
    "    hyps = [x for _,x in sorted(zip(idxs,hyps))]\n",
    "    \n",
    "    with open(outfile, \"w\") as f:\n",
    "        for h in hyps:\n",
    "            f.write(h+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "Le4RFWXxjmm0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-02 16:32:02 | INFO | fairseq.data.data_utils | loaded 4,000 examples from: ./DATA/data-bin/ted2020/test.en-zh.zh\n",
      "2022-04-02 16:32:02 | INFO | fairseq.data.data_utils | loaded 4,000 examples from: ./DATA/data-bin/ted2020/test.en-zh.en\n",
      "2022-04-02 16:32:02 | INFO | fairseq.tasks.translation | ./DATA/data-bin/ted2020 test zh-en 4000 examples\n",
      "prediction: 100%|██████████| 17/17 [00:03<00:00,  4.37it/s]\n"
     ]
    }
   ],
   "source": [
    "# generate_prediction(model, task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1z0cJE-wPzaU"
   },
   "source": [
    "# Back-translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5-7uPJ2CP0sm"
   },
   "source": [
    "## Train a backward translation model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ppGHjg2ZP3sV"
   },
   "source": [
    "1. Switch the source_lang and target_lang in **config** \n",
    "2. Change the savedir in **config** (eg. \"./checkpoints/transformer-back\")\n",
    "3. Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "waTGz29UP6WI"
   },
   "source": [
    "## Generate synthetic data with backward model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sIeTsPexP8FL"
   },
   "source": [
    "### Download monolingual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "i7N4QlsbP8fh"
   },
   "outputs": [],
   "source": [
    "mono_dataset_name = 'mono'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "396saD9-QBPY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-04-02 16:58:04--  https://github.com/yuhsinchan/ML2022-HW5Dataset/releases/download/v1.0.2/ted_zh_corpus.deduped.gz\n",
      "Resolving github.com (github.com)... 13.114.40.48\n",
      "Connecting to github.com (github.com)|13.114.40.48|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/465173291/e0bb1e99-3b10-4346-b4b7-e1aa83404760?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220402%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220402T085804Z&X-Amz-Expires=300&X-Amz-Signature=68cbfede90336eba2d0a6819f4918821d1cb035c10825cea2611babbac78f042&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=465173291&response-content-disposition=attachment%3B%20filename%3Dted_zh_corpus.deduped.gz&response-content-type=application%2Foctet-stream [following]\n",
      "--2022-04-02 16:58:04--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/465173291/e0bb1e99-3b10-4346-b4b7-e1aa83404760?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220402%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220402T085804Z&X-Amz-Expires=300&X-Amz-Signature=68cbfede90336eba2d0a6819f4918821d1cb035c10825cea2611babbac78f042&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=465173291&response-content-disposition=attachment%3B%20filename%3Dted_zh_corpus.deduped.gz&response-content-type=application%2Foctet-stream\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 21709855 (21M) [application/octet-stream]\n",
      "Saving to: ‘/home/user/homework/ML/hw5/DATA/rawdata/mono/ted_zh_corpus.deduped.gz’\n",
      "\n",
      "/home/user/homework 100%[===================>]  20.70M  9.21MB/s    in 2.2s    \n",
      "\n",
      "2022-04-02 16:58:07 (9.21 MB/s) - ‘/home/user/homework/ML/hw5/DATA/rawdata/mono/ted_zh_corpus.deduped.gz’ saved [21709855/21709855]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mono_prefix = Path(data_dir).absolute() / mono_dataset_name\n",
    "mono_prefix.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "urls = (\n",
    "    \"https://github.com/yuhsinchan/ML2022-HW5Dataset/releases/download/v1.0.2/ted_zh_corpus.deduped.gz\",\n",
    ")\n",
    "file_names = (\n",
    "    'ted_zh_corpus.deduped.gz',\n",
    ")\n",
    "\n",
    "for u, f in zip(urls, file_names):\n",
    "    path = mono_prefix/f\n",
    "    if not path.exists():\n",
    "        !wget {u} -O {path}\n",
    "    else:\n",
    "        print(f'{f} is exist, skip downloading')\n",
    "    if path.suffix == \".tgz\":\n",
    "        !tar -xvf {path} -C {prefix}\n",
    "    elif path.suffix == \".zip\":\n",
    "        !unzip -o {path} -d {prefix}\n",
    "    elif path.suffix == \".gz\":\n",
    "        !gzip -fkd {path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JOVQRHzGQU4-"
   },
   "source": [
    "### TODO: clean corpus\n",
    "\n",
    "1. remove sentences that are too long or too short\n",
    "2. unify punctuation\n",
    "\n",
    "hint: you can use clean_s() defined above to do this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "eIYmxfUOQSov"
   },
   "outputs": [],
   "source": [
    "def clean_mono(mono_prefix, max_len=512, min_len=3):\n",
    "    l1 = 'zh'\n",
    "    l2 =  'en'\n",
    "    if Path(f'{mono_prefix}/ted_zh_corpus.deduped.clean.{l1}').exists() and Path(f'{mono_prefix}/ted_zh_corpus.deduped.clean.{l2}').exists():\n",
    "        print(f'{mono_prefix}/ted_zh_corpus.deduped.clean.{l1} & {l2} exists. skipping clean.')\n",
    "        return\n",
    "    with open(f'{mono_prefix}/ted_zh_corpus.deduped', 'r') as l1_in_f:\n",
    "        with open(f'{mono_prefix}/ted_zh_corpus.deduped.clean.{l1}', 'w') as l1_out_f:\n",
    "            with open(f'{mono_prefix}/ted_zh_corpus.deduped.clean.{l2}', 'w') as l2_out_f:\n",
    "                for s1 in tqdm.tqdm(l1_in_f):\n",
    "                    s1 = s1.strip()\n",
    "                    s1 = clean_s(s1, l1)\n",
    "                    s1_len = len_s(s1, l1)\n",
    "                    if min_len > 0: # remove short sentence\n",
    "                        if s1_len < min_len:\n",
    "                            continue\n",
    "                    if max_len > 0: # remove long sentence\n",
    "                        if s1_len > max_len:\n",
    "                            continue\n",
    "                    print(s1, file=l1_out_f)\n",
    "                    print('.', file=l2_out_f)\n",
    "\n",
    "clean_mono(mono_prefix=mono_prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jegH0bvMQVmR"
   },
   "source": [
    "### TODO: Subword Units\n",
    "\n",
    "Use the spm model of the backward model to tokenize the data into subword units\n",
    "\n",
    "hint: spm model is located at DATA/raw-data/\\[dataset\\]/spm\\[vocab_num\\].model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "vqgR4uUMQZGY"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "782527it [00:09, 84028.48it/s] \n",
      "782527it [00:09, 83551.14it/s] \n"
     ]
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "vocab_size = 8000\n",
    "# if (mono_prefix/f'spm{vocab_size}.model').exists():\n",
    "#     print(f'{mono_prefix}/spm{vocab_size}.model exists. skipping spm_train.')\n",
    "# else:\n",
    "#     spm.SentencePieceTrainer.train(\n",
    "#         input=mono_prefix / 'mono.train.zh',\n",
    "#         model_prefix=mono_prefix/f'spm{vocab_size}',\n",
    "#         vocab_size=vocab_size,\n",
    "#         character_coverage=1,\n",
    "#         model_type='unigram', # 'bpe' works as well\n",
    "#         input_sentence_size=1e6,\n",
    "#         shuffle_input_sentence=True,\n",
    "#         normalization_rule_name='nmt_nfkc_cf',\n",
    "#     )\n",
    "spm_model = spm.SentencePieceProcessor(model_file=f'{prefix}/spm8000.model')\n",
    "for lang in ['zh', 'en']:\n",
    "    out_path = mono_prefix / f'mono.tok.{lang}'\n",
    "    with open(out_path, 'w') as out_f:\n",
    "        with open(mono_prefix / 'ted_zh_corpus.cleaned', 'r') as in_f:\n",
    "            for line in tqdm.tqdm(in_f):\n",
    "                line = line.strip()\n",
    "                tok = spm_model.encode(line, out_type=str)\n",
    "                print(' '.join(tok), file=out_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a65glBVXQZiE"
   },
   "source": [
    "### Binarize\n",
    "\n",
    "use fairseq to binarize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "b803qA5aQaEu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-02 17:42:05 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
      "2022-04-02 17:42:05 | INFO | fairseq_cli.preprocess | Namespace(aim_repo=None, aim_run_hash=None, align_suffix=None, alignfile=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, azureml_logging=False, bf16=False, bpe=None, cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='DATA/data-bin/mono', dict_only=False, empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_file=None, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, on_cpu_convert_precision=False, only_source=False, optimizer=None, padding_factor=8, plasma_path='/tmp/plasma', profile=False, quantization_config_path=None, reset_logging=False, scoring='bleu', seed=1, simul_type=None, source_lang='zh', srcdict='./DATA/data-bin/ted2020/dict.en.txt', suppress_crashes=False, target_lang='en', task='translation', tensorboard_logdir=None, testpref=None, tgtdict='./DATA/data-bin/ted2020/dict.en.txt', threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref='/home/user/homework/ML/hw5/DATA/rawdata/mono/mono.tok', use_plasma_view=False, user_dir=None, validpref=None, wandb_project=None, workers=10)\n",
      "2022-04-02 17:42:05 | INFO | fairseq_cli.preprocess | [zh] Dictionary: 8000 types\n",
      "2022-04-02 17:42:27 | INFO | fairseq_cli.preprocess | [zh] /home/user/homework/ML/hw5/DATA/rawdata/mono/mono.tok.zh: 782527 sents, 14004837 tokens, 0.0023% replaced (by <unk>)\n",
      "2022-04-02 17:42:27 | INFO | fairseq_cli.preprocess | [en] Dictionary: 8000 types\n",
      "2022-04-02 17:42:49 | INFO | fairseq_cli.preprocess | [en] /home/user/homework/ML/hw5/DATA/rawdata/mono/mono.tok.en: 782527 sents, 14004837 tokens, 0.0023% replaced (by <unk>)\n",
      "2022-04-02 17:42:49 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to DATA/data-bin/mono\n"
     ]
    }
   ],
   "source": [
    "binpath = Path('./DATA/data-bin', mono_dataset_name)\n",
    "src_dict_file = './DATA/data-bin/ted2020/dict.en.txt'\n",
    "tgt_dict_file = src_dict_file\n",
    "monopref = str(mono_prefix / 'mono.tok') # whatever filepath you get after applying subword tokenization\n",
    "if binpath.exists():\n",
    "    print(binpath, \"exists, will not overwrite!\")\n",
    "else:\n",
    "    !python -m fairseq_cli.preprocess\\\n",
    "        --source-lang 'zh'\\\n",
    "        --target-lang 'en'\\\n",
    "        --trainpref {monopref}\\\n",
    "        --destdir {binpath}\\\n",
    "        --srcdict {src_dict_file}\\\n",
    "        --tgtdict {tgt_dict_file}\\\n",
    "        --workers 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "smA0JraEQdxz"
   },
   "source": [
    "### TODO: Generate synthetic data with backward model\n",
    "\n",
    "Add binarized monolingual data to the original data directory, and name it with \"split_name\"\n",
    "\n",
    "ex. ./DATA/data-bin/ted2020/\\[split_name\\].zh-en.\\[\"en\", \"zh\"\\].\\[\"bin\", \"idx\"\\]\n",
    "\n",
    "then you can use 'generate_prediction(model, task, split=\"split_name\")' to generate translation prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "jvaOVHeoQfkB"
   },
   "outputs": [],
   "source": [
    "# Add binarized monolingual data to the original data directory, and name it with \"split_name\"\n",
    "# ex. ./DATA/data-bin/ted2020/\\[split_name\\].zh-en.\\[\"en\", \"zh\"\\].\\[\"bin\", \"idx\"\\]\n",
    "!cp ./DATA/data-bin/mono/train.zh-en.zh.bin ./DATA/data-bin/ted2020/mono.zh-en.zh.bin\n",
    "!cp ./DATA/data-bin/mono/train.zh-en.zh.idx ./DATA/data-bin/ted2020/mono.zh-en.zh.idx\n",
    "!cp ./DATA/data-bin/mono/train.zh-en.en.bin ./DATA/data-bin/ted2020/mono.zh-en.en.bin\n",
    "!cp ./DATA/data-bin/mono/train.zh-en.en.idx ./DATA/data-bin/ted2020/mono.zh-en.en.idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "id": "fFEkxPu-Qhlc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-02 17:46:10 | INFO | fairseq.data.data_utils | loaded 782,527 examples from: ./DATA/data-bin/ted2020/mono.zh-en.zh\n",
      "2022-04-02 17:46:10 | INFO | fairseq.data.data_utils | loaded 782,527 examples from: ./DATA/data-bin/ted2020/mono.zh-en.en\n",
      "2022-04-02 17:46:10 | INFO | fairseq.tasks.translation | ./DATA/data-bin/ted2020 mono zh-en 782527 examples\n",
      "prediction: 100%|██████████| 1715/1715 [33:34<00:00,  1.17s/it]\n"
     ]
    }
   ],
   "source": [
    "# hint: do prediction on split='mono' to create prediction_file\n",
    "generate_prediction(model, task ,split='mono' ,outfile=mono_prefix / 'mono_pred.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in the mid16th century , italians were fascinated by a kind of male singer whose singers were vast , including highpitched pitch previously impossible for adul\n",
      "but there's a very high price for this talent .\n",
      "to prevent them from transforming their voices , these singers were castrated before puberty to stop the hormone changes so that they wouldn't have gone down .\n",
      "called castrati , their light , angellike voices were famous throughout europe until this brutal procedure was banned in the 19th century .\n",
      "while preventing the growth of the vocal folds can produce an extraordinary range of sounds , naturally developing sounds have a lot of possibilities .\n"
     ]
    }
   ],
   "source": [
    "!head {'./DATA/rawdata/mono/mono_pred.txt'} -n 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jn4XeawpQjLk"
   },
   "source": [
    "### TODO: Create new dataset\n",
    "\n",
    "1. Combine the prediction data with monolingual data\n",
    "2. Use the original spm model to tokenize data into Subword Units\n",
    "3. Binarize data with fairseq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "3R35JTaTQjkm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-02 18:27:03 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
      "2022-04-02 18:27:04 | INFO | fairseq_cli.preprocess | Namespace(aim_repo=None, aim_run_hash=None, align_suffix=None, alignfile=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, azureml_logging=False, bf16=False, bpe=None, cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='DATA/data-bin/synthetic', dict_only=False, empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_file=None, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, on_cpu_convert_precision=False, only_source=False, optimizer=None, padding_factor=8, plasma_path='/tmp/plasma', profile=False, quantization_config_path=None, reset_logging=False, scoring='bleu', seed=1, simul_type=None, source_lang='zh', srcdict='./DATA/data-bin/ted2020/dict.en.txt', suppress_crashes=False, target_lang='en', task='translation', tensorboard_logdir=None, testpref=None, tgtdict='./DATA/data-bin/ted2020/dict.en.txt', threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref='./DATA/rawdata/mono/mono.tok', use_plasma_view=False, user_dir=None, validpref=None, wandb_project=None, workers=10)\n",
      "2022-04-02 18:27:04 | INFO | fairseq_cli.preprocess | [zh] Dictionary: 8000 types\n",
      "2022-04-02 18:27:26 | INFO | fairseq_cli.preprocess | [zh] ./DATA/rawdata/mono/mono.tok.zh: 782527 sents, 14004837 tokens, 0.0023% replaced (by <unk>)\n",
      "2022-04-02 18:27:26 | INFO | fairseq_cli.preprocess | [en] Dictionary: 8000 types\n",
      "2022-04-02 18:27:48 | INFO | fairseq_cli.preprocess | [en] ./DATA/rawdata/mono/mono.tok.en: 782527 sents, 17196445 tokens, 0.0% replaced (by <unk>)\n",
      "2022-04-02 18:27:48 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to DATA/data-bin/synthetic\n"
     ]
    }
   ],
   "source": [
    "# Combine prediction_file (.en) and mono.zh (.zh) into a new dataset.\n",
    "# \n",
    "# hint: tokenize prediction_file with the spm model\n",
    "# spm_model.encode(line, out_type=str)\n",
    "# output: ./DATA/rawdata/mono/mono.tok.en & mono.tok.zh\n",
    "\n",
    "with open(mono_prefix/f'mono.tok.en', 'w') as out_f:\n",
    "    with open(mono_prefix / 'mono_pred.txt', 'r') as in_f:\n",
    "        for line in in_f:\n",
    "            line = line.strip()\n",
    "            tok = spm_model.encode(line, out_type=str)\n",
    "            print(' '.join(tok), file=out_f)\n",
    "\n",
    "# hint: use fairseq to binarize these two files again\n",
    "binpath = Path('./DATA/data-bin/synthetic')\n",
    "src_dict_file = './DATA/data-bin/ted2020/dict.en.txt'\n",
    "tgt_dict_file = src_dict_file\n",
    "monopref = './DATA/rawdata/mono/mono.tok' # or whatever path after applying subword tokenization, w/o the suffix (.zh/.en)\n",
    "if binpath.exists():\n",
    "    print(binpath, \"exists, will not overwrite!\")\n",
    "else:\n",
    "    !python -m fairseq_cli.preprocess\\\n",
    "        --source-lang 'zh'\\\n",
    "        --target-lang 'en'\\\n",
    "        --trainpref {monopref}\\\n",
    "        --destdir {binpath}\\\n",
    "        --srcdict {src_dict_file}\\\n",
    "        --tgtdict {tgt_dict_file}\\\n",
    "        --workers 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "id": "MSkse1tyQnsR"
   },
   "outputs": [],
   "source": [
    "# create a new dataset from all the files prepared above\n",
    "!cp -r ./DATA/data-bin/ted2020/ ./DATA/data-bin/ted2020_with_mono/\n",
    "\n",
    "!cp ./DATA/data-bin/synthetic/train.zh-en.zh.bin ./DATA/data-bin/ted2020_with_mono/train1.en-zh.zh.bin\n",
    "!cp ./DATA/data-bin/synthetic/train.zh-en.zh.idx ./DATA/data-bin/ted2020_with_mono/train1.en-zh.zh.idx\n",
    "!cp ./DATA/data-bin/synthetic/train.zh-en.en.bin ./DATA/data-bin/ted2020_with_mono/train1.en-zh.en.bin\n",
    "!cp ./DATA/data-bin/synthetic/train.zh-en.en.idx ./DATA/data-bin/ted2020_with_mono/train1.en-zh.en.idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YVdxVGO3QrSs"
   },
   "source": [
    "Created new dataset \"ted2020_with_mono\"\n",
    "\n",
    "1. Change the datadir in **config** (\"./DATA/data-bin/ted2020_with_mono\")\n",
    "2. Switch back the source_lang and target_lang in **config** (\"en\", \"zh\")\n",
    "2. Change the savedir in **config** (eg. \"./checkpoints/transformer-bt\")\n",
    "3. Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_CZU2beUQtl3"
   },
   "source": [
    "1. <a name=ott2019fairseq></a>Ott, M., Edunov, S., Baevski, A., Fan, A., Gross, S., Ng, N., ... & Auli, M. (2019, June). fairseq: A Fast, Extensible Toolkit for Sequence Modeling. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics (Demonstrations) (pp. 48-53).\n",
    "2. <a name=vaswani2017></a>Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., ... & Polosukhin, I. (2017, December). Attention is all you need. In Proceedings of the 31st International Conference on Neural Information Processing Systems (pp. 6000-6010).\n",
    "3. <a name=reimers-2020-multilingual-sentence-bert></a>Reimers, N., & Gurevych, I. (2020, November). Making Monolingual Sentence Embeddings Multilingual Using Knowledge Distillation. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP) (pp. 4512-4525).\n",
    "4. <a name=tiedemann2012parallel></a>Tiedemann, J. (2012, May). Parallel Data, Tools and Interfaces in OPUS. In Lrec (Vol. 2012, pp. 2214-2218).\n",
    "5. <a name=kudo-richardson-2018-sentencepiece></a>Kudo, T., & Richardson, J. (2018, November). SentencePiece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing: System Demonstrations (pp. 66-71).\n",
    "6. <a name=sennrich-etal-2016-improving></a>Sennrich, R., Haddow, B., & Birch, A. (2016, August). Improving Neural Machine Translation Models with Monolingual Data. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) (pp. 86-96).\n",
    "7. <a name=edunov-etal-2018-understanding></a>Edunov, S., Ott, M., Auli, M., & Grangier, D. (2018). Understanding Back-Translation at Scale. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing (pp. 489-500).\n",
    "8. https://github.com/ajinkyakulkarni14/TED-Multilingual-Parallel-Corpus\n",
    "9. https://ithelp.ithome.com.tw/articles/10233122\n",
    "10. https://nlp.seas.harvard.edu/2018/04/03/attention.html\n",
    "11. https://colab.research.google.com/github/ga642381/ML2021-Spring/blob/main/HW05/HW05.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rrfm6iLJQ0tS"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "nKb4u67-sT_Z",
    "n1rwQysTsdJq",
    "59si_C0Wsms7",
    "oOpG4EBRLwe_",
    "6ZlE_1JnMv56",
    "UDAPmxjRNEEL",
    "ce5n4eS7NQNy",
    "rUB9f1WCNgMH",
    "VFJlkOMONsc6",
    "Gt1lX3DRO_yU",
    "BAGMiun8PnZy",
    "JOVQRHzGQU4-",
    "jegH0bvMQVmR",
    "a65glBVXQZiE",
    "smA0JraEQdxz",
    "Jn4XeawpQjLk"
   ],
   "name": "HW05.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
