{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AFEKWoh3p1Mv"
   },
   "source": [
    "# Homework Description\n",
    "- English to Chinese (Traditional) Translation\n",
    "  - Input: an English sentence         (e.g.\t\ttom is a student .)\n",
    "  - Output: the Chinese translation  (e.g. \t\t湯姆 是 個 學生 。)\n",
    "\n",
    "- TODO\n",
    "    - Train a simple RNN seq2seq to acheive translation\n",
    "    - Switch to transformer model to boost performance\n",
    "    - Apply Back-translation to furthur boost performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "3Vf1Q79XPQ3D"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Apr  3 12:18:26 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.103.01   Driver Version: 470.103.01   CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0 Off |                  N/A |\n",
      "| 27%   27C    P8    21W / 250W |    166MiB / 11016MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A       955      G   /usr/lib/xorg/Xorg                142MiB |\n",
      "|    0   N/A  N/A      1317      G   cinnamon                           22MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "59neB_Sxp5Ub"
   },
   "source": [
    "# Download and import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "rRlFbfFRpZYT"
   },
   "outputs": [],
   "source": [
    "# !pip install 'torch>=1.6.0' editdistance matplotlib sacrebleu sacremoses sentencepiece tqdm wandb\n",
    "# !pip install --upgrade jupyter ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "fSksMTdmp-Wt"
   },
   "outputs": [],
   "source": [
    "# !git clone https://github.com/pytorch/fairseq.git\n",
    "# !cd fairseq && git checkout 9a1c497\n",
    "# !pip install --upgrade ./fairseq/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "uRLTiuIuqGNc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-03 12:18:27 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pdb\n",
    "import pprint\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "import numpy as np\n",
    "import tqdm as tqdm\n",
    "from pathlib import Path\n",
    "from argparse import Namespace\n",
    "from fairseq import utils\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0n07Za1XqJzA"
   },
   "source": [
    "# Fix random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "xllxxyWxqI7s"
   },
   "outputs": [],
   "source": [
    "seed = 73\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  \n",
    "np.random.seed(seed)  \n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N5ORDJ-2qdYw"
   },
   "source": [
    "# Dataset\n",
    "\n",
    "## En-Zh Bilingual Parallel Corpus\n",
    "* [TED2020](#reimers-2020-multilingual-sentence-bert)\n",
    "    - Raw: 398,066 (sentences)   \n",
    "    - Processed: 393,980 (sentences)\n",
    "    \n",
    "\n",
    "## Testdata\n",
    "- Size: 4,000 (sentences)\n",
    "- **Chinese translation is undisclosed. The provided (.zh) file is psuedo translation, each line is a '。'**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GQw2mY4Dqkzd"
   },
   "source": [
    "## Dataset Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "SXT42xQtqijD"
   },
   "outputs": [],
   "source": [
    "data_dir = './DATA/rawdata'\n",
    "dataset_name = 'ted2020'\n",
    "urls = (\n",
    "    \"https://github.com/yuhsinchan/ML2022-HW5Dataset/releases/download/v1.0.2/ted2020.tgz\",\n",
    "    \"https://github.com/yuhsinchan/ML2022-HW5Dataset/releases/download/v1.0.2/test.tgz\",\n",
    ")\n",
    "file_names = (\n",
    "    'ted2020.tgz', # train & dev\n",
    "    'test.tgz', # test\n",
    ")\n",
    "prefix = Path(data_dir).absolute() / dataset_name\n",
    "\n",
    "# prefix.mkdir(parents=True, exist_ok=True)\n",
    "# for u, f in zip(urls, file_names):\n",
    "#     path = prefix/f\n",
    "#     if not path.exists():\n",
    "#         !wget {u} -O {path}\n",
    "#     if path.suffix == \".tgz\":\n",
    "#         !tar -xvf {path} -C {prefix}\n",
    "#     elif path.suffix == \".zip\":\n",
    "#         !unzip -o {path} -d {prefix}\n",
    "# !mv {prefix/'raw.en'} {prefix/'train_dev.raw.en'}\n",
    "# !mv {prefix/'raw.zh'} {prefix/'train_dev.raw.zh'}\n",
    "# !mv {prefix/'test/test.en'} {prefix/'test.raw.en'}\n",
    "# !mv {prefix/'test/test.zh'} {prefix/'test.raw.zh'}\n",
    "# !rm -rf {prefix/'test'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YLkJwNiFrIwZ"
   },
   "source": [
    "## Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "_uJYkCncrKJb"
   },
   "outputs": [],
   "source": [
    "src_lang = 'zh'\n",
    "tgt_lang = 'en'\n",
    "\n",
    "data_prefix = f'{prefix}/train_dev.raw'\n",
    "test_prefix = f'{prefix}/test.raw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "0t2CPt1brOT3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "非常謝謝你，克里斯。能有這個機會第二度踏上這個演講台\n",
      "真是一大榮幸。我非常感激。\n",
      "這個研討會給我留下了極為深刻的印象，我想感謝大家 對我之前演講的好評。\n",
      "我是由衷的想這麼說，有部份原因是因為 —— 我真的有需要!\n",
      "請你們設身處地為我想一想！\n",
      "Thank you so much, Chris.\n",
      "And it's truly a great honor to have the opportunity to come to this stage twice; I'm extremely grateful.\n",
      "I have been blown away by this conference, and I want to thank all of you for the many nice comments about what I had to say the other night.\n",
      "And I say that sincerely, partly because  I need that.\n",
      "Put yourselves in my position.\n"
     ]
    }
   ],
   "source": [
    "!head {data_prefix+'.'+src_lang} -n 5\n",
    "!head {data_prefix+'.'+tgt_lang} -n 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pRoE9UK7r1gY"
   },
   "source": [
    "## Preprocess files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "3tzFwtnFrle3"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def strQ2B(ustring):\n",
    "    \"\"\"Full width -> half width\"\"\"\n",
    "    # reference:https://ithelp.ithome.com.tw/articles/10233122\n",
    "    ss = []\n",
    "    for s in ustring:\n",
    "        rstring = \"\"\n",
    "        for uchar in s:\n",
    "            inside_code = ord(uchar)\n",
    "            if inside_code == 12288:  # Full width space: direct conversion\n",
    "                inside_code = 32\n",
    "            elif (inside_code >= 65281 and inside_code <= 65374):  # Full width chars (except space) conversion\n",
    "                inside_code -= 65248\n",
    "            rstring += chr(inside_code)\n",
    "        ss.append(rstring)\n",
    "    return ''.join(ss)\n",
    "                \n",
    "def clean_s(s, lang):\n",
    "    if lang == 'en':\n",
    "        s = re.sub(r\"\\([^()]*\\)\", \"\", s) # remove ([text])\n",
    "        s = s.replace('-', '') # remove '-'\n",
    "        s = re.sub('([.,;!?()\\\"])', r' \\1 ', s) # keep punctuation\n",
    "    elif lang == 'zh':\n",
    "        s = strQ2B(s) # Q2B\n",
    "        s = re.sub(r\"\\([^()]*\\)\", \"\", s) # remove ([text])\n",
    "        s = s.replace(' ', '')\n",
    "        s = s.replace('—', '')\n",
    "        s = s.replace('“', '\"')\n",
    "        s = s.replace('”', '\"')\n",
    "        s = s.replace('_', '')\n",
    "        s = re.sub('([。,;!?()\\\"~「」])', r' \\1 ', s) # keep punctuation\n",
    "    s = ' '.join(s.strip().split())\n",
    "    return s\n",
    "\n",
    "def len_s(s, lang):\n",
    "    if lang == 'zh':\n",
    "        return len(s)\n",
    "    return len(s.split())\n",
    "\n",
    "def clean_corpus(prefix, l1, l2, ratio=9, max_len=1000, min_len=1):\n",
    "    if Path(f'{prefix}.clean.{l1}').exists() and Path(f'{prefix}.clean.{l2}').exists():\n",
    "        print(f'{prefix}.clean.{l1} & {l2} exists. skipping clean.')\n",
    "        return\n",
    "    with open(f'{prefix}.{l1}', 'r') as l1_in_f:\n",
    "        with open(f'{prefix}.{l2}', 'r') as l2_in_f:\n",
    "            with open(f'{prefix}.clean.{l1}', 'w') as l1_out_f:\n",
    "                with open(f'{prefix}.clean.{l2}', 'w') as l2_out_f:\n",
    "                    for s1 in l1_in_f:\n",
    "                        s1 = s1.strip()\n",
    "                        s2 = l2_in_f.readline().strip()\n",
    "                        s1 = clean_s(s1, l1)\n",
    "                        s2 = clean_s(s2, l2)\n",
    "                        s1_len = len_s(s1, l1)\n",
    "                        s2_len = len_s(s2, l2)\n",
    "                        if min_len > 0: # remove short sentence\n",
    "                            if s1_len < min_len or s2_len < min_len:\n",
    "                                continue\n",
    "                        if max_len > 0: # remove long sentence\n",
    "                            if s1_len > max_len or s2_len > max_len:\n",
    "                                continue\n",
    "                        if ratio > 0: # remove by ratio of length\n",
    "                            if s1_len/s2_len > ratio or s2_len/s1_len > ratio:\n",
    "                                continue\n",
    "                        print(s1, file=l1_out_f)\n",
    "                        print(s2, file=l2_out_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "h_i8b1PRr9Nf"
   },
   "outputs": [],
   "source": [
    "# clean_corpus(data_prefix, src_lang, tgt_lang)\n",
    "# clean_corpus(test_prefix, src_lang, tgt_lang, ratio=-1, min_len=-1, max_len=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "gjT3XCy9r_rj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "非常謝謝你 , 克里斯 。 能有這個機會第二度踏上這個演講台\n",
      "真是一大榮幸 。 我非常感激 。\n",
      "這個研討會給我留下了極為深刻的印象 , 我想感謝大家對我之前演講的好評 。\n",
      "我是由衷的想這麼說 , 有部份原因是因為我真的有需要 !\n",
      "請你們設身處地為我想一想 !\n",
      "Thank you so much , Chris .\n",
      "And it's truly a great honor to have the opportunity to come to this stage twice ; I'm extremely grateful .\n",
      "I have been blown away by this conference , and I want to thank all of you for the many nice comments about what I had to say the other night .\n",
      "And I say that sincerely , partly because I need that .\n",
      "Put yourselves in my position .\n"
     ]
    }
   ],
   "source": [
    "!head {data_prefix+'.clean.'+src_lang} -n 5\n",
    "!head {data_prefix+'.clean.'+tgt_lang} -n 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nKb4u67-sT_Z"
   },
   "source": [
    "## Split into train/valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "AuFKeDz3sGHL"
   },
   "outputs": [],
   "source": [
    "valid_ratio = 0.01 # 3000~4000 would suffice\n",
    "train_ratio = 1 - valid_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "QR2NVldqsXyY"
   },
   "outputs": [],
   "source": [
    "# if (prefix/f'train.clean.{src_lang}').exists() \\\n",
    "# and (prefix/f'train.clean.{tgt_lang}').exists() \\\n",
    "# and (prefix/f'valid.clean.{src_lang}').exists() \\\n",
    "# and (prefix/f'valid.clean.{tgt_lang}').exists():\n",
    "#     print(f'train/valid splits exists. skipping split.')\n",
    "# else:\n",
    "#     line_num = sum(1 for line in open(f'{data_prefix}.clean.{src_lang}'))\n",
    "#     labels = list(range(line_num))\n",
    "#     random.shuffle(labels)\n",
    "#     for lang in [src_lang, tgt_lang]:\n",
    "#         train_f = open(os.path.join(data_dir, dataset_name, f'train.clean.{lang}'), 'w')\n",
    "#         valid_f = open(os.path.join(data_dir, dataset_name, f'valid.clean.{lang}'), 'w')\n",
    "#         count = 0\n",
    "#         for line in open(f'{data_prefix}.clean.{lang}', 'r'):\n",
    "#             if labels[count]/line_num < train_ratio:\n",
    "#                 train_f.write(line)\n",
    "#             else:\n",
    "#                 valid_f.write(line)\n",
    "#             count += 1\n",
    "#         train_f.close()\n",
    "#         valid_f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n1rwQysTsdJq"
   },
   "source": [
    "## Subword Units \n",
    "Out of vocabulary (OOV) has been a major problem in machine translation. This can be alleviated by using subword units.\n",
    "- We will use the [sentencepiece](#kudo-richardson-2018-sentencepiece) package\n",
    "- select 'unigram' or 'byte-pair encoding (BPE)' algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Ecwllsa7sZRA"
   },
   "outputs": [],
   "source": [
    "# import sentencepiece as spm\n",
    "# vocab_size = 8000\n",
    "# if (prefix/f'spm{vocab_size}.model').exists():\n",
    "#     print(f'{prefix}/spm{vocab_size}.model exists. skipping spm_train.')\n",
    "# else:\n",
    "#     spm.SentencePieceTrainer.train(\n",
    "#         input=','.join([f'{prefix}/train.clean.{src_lang}',\n",
    "#                         f'{prefix}/valid.clean.{src_lang}',\n",
    "#                         f'{prefix}/train.clean.{tgt_lang}',\n",
    "#                         f'{prefix}/valid.clean.{tgt_lang}']),\n",
    "#         model_prefix=prefix/f'spm{vocab_size}',\n",
    "#         vocab_size=vocab_size,\n",
    "#         character_coverage=1,\n",
    "#         model_type='unigram', # 'bpe' works as well\n",
    "#         input_sentence_size=1e6,\n",
    "#         shuffle_input_sentence=True,\n",
    "#         normalization_rule_name='nmt_nfkc_cf',\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "lQPRNldqse_V"
   },
   "outputs": [],
   "source": [
    "# spm_model = spm.SentencePieceProcessor(model_file=str(prefix/f'spm{vocab_size}.model'))\n",
    "# in_tag = {\n",
    "#     'train': 'train.clean',\n",
    "#     'valid': 'valid.clean',\n",
    "#     'test': 'test.raw.clean',\n",
    "# }\n",
    "# for split in ['train', 'valid', 'test']:\n",
    "#     for lang in [src_lang, tgt_lang]:\n",
    "#         out_path = prefix/f'{split}.{lang}'\n",
    "#         if out_path.exists():\n",
    "#             print(f\"{out_path} exists. skipping spm_encode.\")\n",
    "#         else:\n",
    "#             with open(prefix/f'{split}.{lang}', 'w') as out_f:\n",
    "#                 with open(prefix/f'{in_tag[split]}.{lang}', 'r') as in_f:\n",
    "#                     for line in in_f:\n",
    "#                         line = line.strip()\n",
    "#                         tok = spm_model.encode(line, out_type=str)\n",
    "#                         print(' '.join(tok), file=out_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "4j6lXHjAsjXa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▁ 非常 謝 謝 你 ▁, ▁ 克 里 斯 ▁。 ▁ 能 有 這個 機會 第二 度 踏 上 這個 演講 台\n",
      "▁ 真 是 一 大 榮 幸 ▁。 ▁我 非常 感 激 ▁。\n",
      "▁這個 研 討 會 給我 留 下 了 極 為 深 刻 的 印 象 ▁, ▁我想 感 謝 大家 對我 之前 演講 的 好 評 ▁。\n",
      "▁我 是由 衷 的 想 這麼 說 ▁, ▁有 部份 原因 是因為 我 真的 有 需要 ▁!\n",
      "▁ 請 你們 設 身 處 地 為 我想 一 想 ▁!\n",
      "▁thank ▁you ▁so ▁much ▁, ▁chris ▁.\n",
      "▁and ▁it ' s ▁ t ru ly ▁a ▁great ▁ho n or ▁to ▁have ▁the ▁ op port un ity ▁to ▁come ▁to ▁this ▁st age ▁ t wi ce ▁; ▁i ' m ▁ex t re me ly ▁gr ate ful ▁.\n",
      "▁i ▁have ▁been ▁ bl ow n ▁away ▁by ▁this ▁con fer ence ▁, ▁and ▁i ▁want ▁to ▁thank ▁all ▁of ▁you ▁for ▁the ▁many ▁ ni ce ▁ com ment s ▁about ▁what ▁i ▁had ▁to ▁say ▁the ▁other ▁night ▁.\n",
      "▁and ▁i ▁say ▁that ▁since re ly ▁, ▁part ly ▁because ▁i ▁need ▁that ▁.\n",
      "▁put ▁your s el ve s ▁in ▁my ▁po s ition ▁.\n"
     ]
    }
   ],
   "source": [
    "!head {data_dir+'/'+dataset_name+'/train.'+src_lang} -n 5\n",
    "!head {data_dir+'/'+dataset_name+'/train.'+tgt_lang} -n 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "59si_C0Wsms7"
   },
   "source": [
    "## Binarize the data with fairseq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "w-cHVLSpsknh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA/data-bin/ted2020 exists, will not overwrite!\n"
     ]
    }
   ],
   "source": [
    "binpath = Path('./DATA/data-bin', dataset_name)\n",
    "if binpath.exists():\n",
    "    print(binpath, \"exists, will not overwrite!\")\n",
    "else:\n",
    "    !python -m fairseq_cli.preprocess \\\n",
    "        --source-lang {src_lang}\\\n",
    "        --target-lang {tgt_lang}\\\n",
    "        --trainpref {prefix/'train'}\\\n",
    "        --validpref {prefix/'valid'}\\\n",
    "        --testpref {prefix/'test'}\\\n",
    "        --destdir {binpath}\\\n",
    "        --joined-dictionary\\\n",
    "        --workers 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "szMuH1SWLPWA"
   },
   "source": [
    "# Configuration for experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "5Luz3_tVLUxs"
   },
   "outputs": [],
   "source": [
    "#! config\n",
    "config = Namespace(\n",
    "    datadir = \"./DATA/data-bin/ted2020\",\n",
    "    savedir = \"./checkpoints/transformer_zh-en1\",\n",
    "    source_lang = \"zh\",\n",
    "    target_lang = \"en\",\n",
    "    \n",
    "    # cpu threads when fetching & processing data.\n",
    "    num_workers=10,  \n",
    "    # batch size in terms of tokens. gradient accumulation increases the effective batchsize.\n",
    "    max_tokens=8192,\n",
    "    accum_steps=2,\n",
    "    \n",
    "    # the lr calculated from Noam lr scheduler. you can tune the maximum lr by this factor.\n",
    "    lr_factor=2,\n",
    "    lr_warmup=8000,\n",
    "    \n",
    "    # clipping gradient norm helps alleviate gradient exploding\n",
    "    clip_norm=1.0,\n",
    "    \n",
    "    # maximum epochs for training\n",
    "    max_epoch=40,\n",
    "    start_epoch=1,\n",
    "    \n",
    "    # beam size for beam search\n",
    "    beam=5, \n",
    "    # generate sequences of maximum length ax + b, where x is the source length\n",
    "    max_len_a=1.5, \n",
    "    max_len_b=10, \n",
    "    # when decoding, post process sentence by removing sentencepiece symbols and jieba tokenization.\n",
    "    post_process = \"sentencepiece\",\n",
    "    \n",
    "    # checkpoints\n",
    "    keep_last_epochs=5,\n",
    "    resume=None, # if resume from checkpoint name (under config.savedir)\n",
    "    \n",
    "    # logging\n",
    "    use_wandb=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cjrJFvyQLg86"
   },
   "source": [
    "# Logging\n",
    "- logging package logs ordinary messages\n",
    "- wandb logs the loss, bleu, etc. in the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "-ZiMyDWALbDk"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-03 12:18:30 | ERROR | wandb.jupyter | Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtedli\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/user/homework/ML/hw5/wandb/run-20220403_121831-2w0hslk2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/tedli/ml-hw5/runs/2w0hslk2\" target=\"_blank\">transformer_zh-en1</a></strong> to <a href=\"https://wandb.ai/tedli/ml-hw5\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s | %(levelname)s | %(name)s | %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    "    level=\"INFO\", # \"DEBUG\" \"WARNING\" \"ERROR\"\n",
    "    stream=sys.stdout,\n",
    ")\n",
    "proj = \"ml-hw5\"\n",
    "logger = logging.getLogger(proj)\n",
    "if config.use_wandb:\n",
    "    import wandb\n",
    "    wandb.init(project=proj, name=Path(config.savedir).stem, config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BNoSkK45Lmqc"
   },
   "source": [
    "# CUDA Environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "oqrsbmcoLqMl"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-03 12:18:34 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
      "2022-04-03 12:18:34 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 10.758 GB ; name = NVIDIA GeForce RTX 2080 Ti              \n",
      "2022-04-03 12:18:34 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n"
     ]
    }
   ],
   "source": [
    "cuda_env = utils.CudaEnvironment()\n",
    "utils.CudaEnvironment.pretty_print_cuda_env_list([cuda_env])\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TbJuBIHLLt2D"
   },
   "source": [
    "# Dataloading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oOpG4EBRLwe_"
   },
   "source": [
    "## We borrow the TranslationTask from fairseq\n",
    "* used to load the binarized data created above\n",
    "* well-implemented data iterator (dataloader)\n",
    "* built-in task.source_dictionary and task.target_dictionary are also handy\n",
    "* well-implemented beach search decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "3gSEy1uFLvVs"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-03 12:18:34 | INFO | fairseq.tasks.translation | [zh] dictionary: 8000 types\n",
      "2022-04-03 12:18:34 | INFO | fairseq.tasks.translation | [en] dictionary: 8000 types\n"
     ]
    }
   ],
   "source": [
    "from fairseq.tasks.translation import TranslationConfig, TranslationTask\n",
    "# from fairseq.tasks import translation\n",
    "## setup task\n",
    "task_cfg = TranslationConfig(\n",
    "    data=config.datadir,\n",
    "    source_lang=config.source_lang,\n",
    "    target_lang=config.target_lang,\n",
    "    train_subset=\"train\",\n",
    "    required_seq_len_multiple=8,\n",
    "    dataset_impl=\"mmap\",\n",
    "    upsample_primary=1,\n",
    ")\n",
    "task = TranslationTask.setup_task(task_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "mR7Bhov7L4IU"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-03 12:18:34 | INFO | ml-hw5 | loading data for epoch 1\n",
      "2022-04-03 12:18:34 | INFO | fairseq.data.data_utils | loaded 390,041 examples from: ./DATA/data-bin/ted2020/train.en-zh.zh\n",
      "2022-04-03 12:18:34 | INFO | fairseq.data.data_utils | loaded 390,041 examples from: ./DATA/data-bin/ted2020/train.en-zh.en\n",
      "2022-04-03 12:18:34 | INFO | fairseq.tasks.translation | ./DATA/data-bin/ted2020 train zh-en 390041 examples\n",
      "2022-04-03 12:18:34 | INFO | fairseq.data.data_utils | loaded 3,939 examples from: ./DATA/data-bin/ted2020/valid.en-zh.zh\n",
      "2022-04-03 12:18:34 | INFO | fairseq.data.data_utils | loaded 3,939 examples from: ./DATA/data-bin/ted2020/valid.en-zh.en\n",
      "2022-04-03 12:18:34 | INFO | fairseq.tasks.translation | ./DATA/data-bin/ted2020 valid zh-en 3939 examples\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"loading data for epoch 1\")\n",
    "task.load_dataset(split=\"train\", epoch=1, combine=True) # combine if you have back-translation data.\n",
    "task.load_dataset(split=\"valid\", epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "P0BCEm_9L6ig"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 1,\n",
      " 'source': tensor([ 140,  690,   28,  270,   45,  151, 1142,  660,  606,  369, 3114, 2434,\n",
      "        1434,  192,    2]),\n",
      " 'target': tensor([  18,   14,    6, 2234,   60,   19,   80,    5,  256,   16,  405, 1407,\n",
      "        1706,    7,    2])}\n",
      "'Source: 這實在就是我所做的--光學操控思想'\n",
      "\"Target: that's exactly what i do optical mind control .\"\n"
     ]
    }
   ],
   "source": [
    "sample = task.dataset(\"valid\")[1]\n",
    "pprint.pprint(sample)\n",
    "pprint.pprint(\n",
    "    \"Source: \" + \\\n",
    "    task.source_dictionary.string(\n",
    "        sample['source'],\n",
    "        config.post_process,\n",
    "    )\n",
    ")\n",
    "pprint.pprint(\n",
    "    \"Target: \" + \\\n",
    "    task.target_dictionary.string(\n",
    "        sample['target'],\n",
    "        config.post_process,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UcfCVa2FMBSE"
   },
   "source": [
    "# Dataset iterator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yBvc-B_6MKZM"
   },
   "source": [
    "* Controls every batch to contain no more than N tokens, which optimizes GPU memory efficiency\n",
    "* Shuffles the training set for every epoch\n",
    "* Ignore sentences exceeding maximum length\n",
    "* Pad all sentences in a batch to the same length, which enables parallel computing by GPU\n",
    "* Add eos and shift one token\n",
    "    - teacher forcing: to train the model to predict the next token based on prefix, we feed the right shifted target sequence as the decoder input.\n",
    "    - generally, prepending bos to the target would do the job (as shown below)\n",
    "![seq2seq](https://i.imgur.com/0zeDyuI.png)\n",
    "    - in fairseq however, this is done by moving the eos token to the begining. Empirically, this has the same effect. For instance:\n",
    "    ```\n",
    "    # output target (target) and Decoder input (prev_output_tokens): \n",
    "                   eos = 2\n",
    "                target = 419,  711,  238,  888,  792,   60,  968,    8,    2\n",
    "    prev_output_tokens = 2,  419,  711,  238,  888,  792,   60,  968,    8\n",
    "    ```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "OWFJFmCnMDXW"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-03 12:18:34 | WARNING | fairseq.tasks.fairseq_task | 2,532 samples have invalid sizes and will be skipped, max_positions=(20, 20), first few sample ids=[3525, 527, 1633, 76, 2861, 2415, 2890, 210, 880, 636]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': tensor([963]),\n",
       " 'nsentences': 1,\n",
       " 'ntokens': 18,\n",
       " 'net_input': {'src_tokens': tensor([[   1,    1,    1,    1,    1,    1,    1,    5,  971, 1132,  373,  160,\n",
       "            516,  315,  433,   33,    5, 3673, 2044,  339,  230,  102,  976,    2]]),\n",
       "  'src_lengths': tensor([17]),\n",
       "  'prev_output_tokens': tensor([[   2,  554,   36,   38,    7,   55,   24,  155,    4,  278,  407, 1362,\n",
       "             26, 1011,   25,  153, 2055,    7,    1,    1,    1,    1,    1,    1]])},\n",
       " 'target': tensor([[ 554,   36,   38,    7,   55,   24,  155,    4,  278,  407, 1362,   26,\n",
       "          1011,   25,  153, 2055,    7,    2,    1,    1,    1,    1,    1,    1]])}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_data_iterator(task, split, epoch=1, max_tokens=4000, num_workers=10, cached=True):\n",
    "    batch_iterator = task.get_batch_iterator(\n",
    "        dataset=task.dataset(split),\n",
    "        max_tokens=max_tokens,\n",
    "        max_sentences=None,\n",
    "        max_positions=utils.resolve_max_positions(\n",
    "            task.max_positions(),\n",
    "            max_tokens,\n",
    "        ),\n",
    "        ignore_invalid_inputs=True,\n",
    "        seed=seed,\n",
    "        num_workers=num_workers,\n",
    "        epoch=epoch,\n",
    "        disable_iterator_cache=not cached,\n",
    "        # Set this to False to speed up. However, if set to False, changing max_tokens beyond \n",
    "        # first call of this method has no effect. \n",
    "    )\n",
    "    return batch_iterator\n",
    "\n",
    "demo_epoch_obj = load_data_iterator(task, \"valid\", epoch=1, max_tokens=20, num_workers=1, cached=False)\n",
    "demo_iter = demo_epoch_obj.next_epoch_itr(shuffle=True)\n",
    "sample = next(demo_iter)\n",
    "sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p86K-0g7Me4M"
   },
   "source": [
    "* each batch is a python dict, with string key and Tensor value. Contents are described below:\n",
    "```python\n",
    "batch = {\n",
    "    \"id\": id, # id for each example \n",
    "    \"nsentences\": len(samples), # batch size (sentences)\n",
    "    \"ntokens\": ntokens, # batch size (tokens)\n",
    "    \"net_input\": {\n",
    "        \"src_tokens\": src_tokens, # sequence in source language\n",
    "        \"src_lengths\": src_lengths, # sequence length of each example before padding\n",
    "        \"prev_output_tokens\": prev_output_tokens, # right shifted target, as mentioned above.\n",
    "    },\n",
    "    \"target\": target, # target sequence\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9EyDBE5ZMkFZ"
   },
   "source": [
    "# Model Architecture\n",
    "* We again inherit fairseq's encoder, decoder and model, so that in the testing phase we can directly leverage fairseq's beam search decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "Hzh74qLIMfW_"
   },
   "outputs": [],
   "source": [
    "from fairseq.models import (\n",
    "    FairseqEncoder, \n",
    "    FairseqIncrementalDecoder,\n",
    "    FairseqEncoderDecoderModel\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OI46v1z7MotH"
   },
   "source": [
    "# Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wn0wSeLLMrbc"
   },
   "source": [
    "- The Encoder is a RNN or Transformer Encoder. The following description is for RNN. For every input token, Encoder will generate a output vector and a hidden states vector, and the hidden states vector is passed on to the next step. In other words, the Encoder sequentially reads in the input sequence, and outputs a single vector at each timestep, then finally outputs the final hidden states, or content vector, at the last timestep.\n",
    "- Parameters:\n",
    "  - *args*\n",
    "      - encoder_embed_dim: the dimension of embeddings, this compresses the one-hot vector into fixed dimensions, which achieves dimension reduction\n",
    "      - encoder_ffn_embed_dim is the dimension of hidden states and output vectors\n",
    "      - encoder_layers is the number of layers for Encoder RNN\n",
    "      - dropout determines the probability of a neuron's activation being set to 0, in order to prevent overfitting. Generally this is applied in training, and removed in testing.\n",
    "  - *dictionary*: the dictionary provided by fairseq. it's used to obtain the padding index, and in turn the encoder padding mask. \n",
    "  - *embed_tokens*: an instance of token embeddings (nn.Embedding)\n",
    "\n",
    "- Inputs: \n",
    "    - *src_tokens*: integer sequence representing english e.g. 1, 28, 29, 205, 2 \n",
    "- Outputs: \n",
    "    - *outputs*: the output of RNN at each timestep, can be furthur processed by Attention\n",
    "    - *final_hiddens*: the hidden states of each timestep, will be passed to decoder for decoding\n",
    "    - *encoder_padding_mask*: this tells the decoder which position to ignore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "WcX3W4iGMq-S"
   },
   "outputs": [],
   "source": [
    "class RNNEncoder(FairseqEncoder):\n",
    "    def __init__(self, args, dictionary, embed_tokens):\n",
    "        super().__init__(dictionary)\n",
    "        self.embed_tokens = embed_tokens\n",
    "        \n",
    "        self.embed_dim = args.encoder_embed_dim\n",
    "        self.hidden_dim = args.encoder_ffn_embed_dim\n",
    "        self.num_layers = args.encoder_layers\n",
    "        \n",
    "        self.dropout_in_module = nn.Dropout(args.dropout)\n",
    "        self.rnn = nn.GRU(\n",
    "            self.embed_dim, \n",
    "            self.hidden_dim, \n",
    "            self.num_layers, \n",
    "            dropout=args.dropout, \n",
    "            batch_first=False, \n",
    "            bidirectional=True\n",
    "        )\n",
    "        self.dropout_out_module = nn.Dropout(args.dropout)\n",
    "        \n",
    "        self.padding_idx = dictionary.pad()\n",
    "        \n",
    "    def combine_bidir(self, outs, bsz: int):\n",
    "        out = outs.view(self.num_layers, 2, bsz, -1).transpose(1, 2).contiguous()\n",
    "        return out.view(self.num_layers, bsz, -1)\n",
    "\n",
    "    def forward(self, src_tokens, **unused):\n",
    "        bsz, seqlen = src_tokens.size()\n",
    "        \n",
    "        # get embeddings\n",
    "        x = self.embed_tokens(src_tokens)\n",
    "        x = self.dropout_in_module(x)\n",
    "\n",
    "        # B x T x C -> T x B x C\n",
    "        x = x.transpose(0, 1)\n",
    "        \n",
    "        # pass thru bidirectional RNN\n",
    "        h0 = x.new_zeros(2 * self.num_layers, bsz, self.hidden_dim)\n",
    "        x, final_hiddens = self.rnn(x, h0)\n",
    "        outputs = self.dropout_out_module(x)\n",
    "        # outputs = [sequence len, batch size, hid dim * directions]\n",
    "        # hidden =  [num_layers * directions, batch size  , hid dim]\n",
    "        \n",
    "        # Since Encoder is bidirectional, we need to concatenate the hidden states of two directions\n",
    "        final_hiddens = self.combine_bidir(final_hiddens, bsz)\n",
    "        # hidden =  [num_layers x batch x num_directions*hidden]\n",
    "        \n",
    "        encoder_padding_mask = src_tokens.eq(self.padding_idx).t()\n",
    "        return tuple(\n",
    "            (\n",
    "                outputs,  # seq_len x batch x hidden\n",
    "                final_hiddens,  # num_layers x batch x num_directions*hidden\n",
    "                encoder_padding_mask,  # seq_len x batch\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    def reorder_encoder_out(self, encoder_out, new_order):\n",
    "        # This is used by fairseq's beam search. How and why is not particularly important here.\n",
    "        return tuple(\n",
    "            (\n",
    "                encoder_out[0].index_select(1, new_order),\n",
    "                encoder_out[1].index_select(1, new_order),\n",
    "                encoder_out[2].index_select(1, new_order),\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ZlE_1JnMv56"
   },
   "source": [
    "## Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZSFSKt_ZMzgh"
   },
   "source": [
    "- When the input sequence is long, \"content vector\" alone cannot accurately represent the whole sequence, attention mechanism can provide the Decoder more information.\n",
    "- According to the **Decoder embeddings** of the current timestep, match the **Encoder outputs** with decoder embeddings to determine correlation, and then sum the Encoder outputs weighted by the correlation as the input to **Decoder** RNN.\n",
    "- Common attention implementations use neural network / dot product as the correlation between **query** (decoder embeddings) and **key** (Encoder outputs), followed by **softmax**  to obtain a distribution, and finally **values** (Encoder outputs) is **weighted sum**-ed by said distribution.\n",
    "\n",
    "- Parameters:\n",
    "  - *input_embed_dim*: dimensionality of key, should be that of the vector in decoder to attend others\n",
    "  - *source_embed_dim*: dimensionality of query, should be that of the vector to be attended to (encoder outputs)\n",
    "  - *output_embed_dim*: dimensionality of value, should be that of the vector after attention, expected by the next layer\n",
    "\n",
    "- Inputs: \n",
    "    - *inputs*: is the key, the vector to attend to others\n",
    "    - *encoder_outputs*:  is the query/value, the vector to be attended to\n",
    "    - *encoder_padding_mask*: this tells the decoder which position to ignore\n",
    "- Outputs: \n",
    "    - *output*: the context vector after attention\n",
    "    - *attention score*: the attention distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "1Atf_YuCMyyF"
   },
   "outputs": [],
   "source": [
    "class AttentionLayer(nn.Module):\n",
    "    def __init__(self, input_embed_dim, source_embed_dim, output_embed_dim, bias=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_proj = nn.Linear(input_embed_dim, source_embed_dim, bias=bias)\n",
    "        self.output_proj = nn.Linear(\n",
    "            input_embed_dim + source_embed_dim, output_embed_dim, bias=bias\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs, encoder_outputs, encoder_padding_mask):\n",
    "        # inputs: T, B, dim\n",
    "        # encoder_outputs: S x B x dim\n",
    "        # padding mask:  S x B\n",
    "        \n",
    "        # convert all to batch first\n",
    "        inputs = inputs.transpose(1,0) # B, T, dim\n",
    "        encoder_outputs = encoder_outputs.transpose(1,0) # B, S, dim\n",
    "        encoder_padding_mask = encoder_padding_mask.transpose(1,0) # B, S\n",
    "        \n",
    "        # project to the dimensionality of encoder_outputs\n",
    "        x = self.input_proj(inputs)\n",
    "\n",
    "        # compute attention\n",
    "        # (B, T, dim) x (B, dim, S) = (B, T, S)\n",
    "        attn_scores = torch.bmm(x, encoder_outputs.transpose(1,2))\n",
    "\n",
    "        # cancel the attention at positions corresponding to padding\n",
    "        if encoder_padding_mask is not None:\n",
    "            # leveraging broadcast  B, S -> (B, 1, S)\n",
    "            encoder_padding_mask = encoder_padding_mask.unsqueeze(1)\n",
    "            attn_scores = (\n",
    "                attn_scores.float()\n",
    "                .masked_fill_(encoder_padding_mask, float(\"-inf\"))\n",
    "                .type_as(attn_scores)\n",
    "            )  # FP16 support: cast to float and back\n",
    "\n",
    "        # softmax on the dimension corresponding to source sequence\n",
    "        attn_scores = F.softmax(attn_scores, dim=-1)\n",
    "\n",
    "        # shape (B, T, S) x (B, S, dim) = (B, T, dim) weighted sum\n",
    "        x = torch.bmm(attn_scores, encoder_outputs)\n",
    "\n",
    "        # (B, T, dim)\n",
    "        x = torch.cat((x, inputs), dim=-1)\n",
    "        x = torch.tanh(self.output_proj(x)) # concat + linear + tanh\n",
    "        \n",
    "        # restore shape (B, T, dim) -> (T, B, dim)\n",
    "        return x.transpose(1,0), attn_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "doSCOA2gM7fK"
   },
   "source": [
    "# Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2M8Vod2gNABR"
   },
   "source": [
    "* The hidden states of **Decoder** will be initialized by the final hidden states of **Encoder** (the content vector)\n",
    "* At the same time, **Decoder** will change its hidden states based on the input of the current timestep (the outputs of previous timesteps), and generates an output\n",
    "* Attention improves the performance\n",
    "* The seq2seq steps are implemented in decoder, so that later the Seq2Seq class can accept RNN and Transformer, without furthur modification.\n",
    "- Parameters:\n",
    "  - *args*\n",
    "      - decoder_embed_dim: is the dimensionality of the decoder embeddings, similar to encoder_embed_dim，\n",
    "      - decoder_ffn_embed_dim: is the dimensionality of the decoder RNN hidden states, similar to encoder_ffn_embed_dim\n",
    "      - decoder_layers: number of layers of RNN decoder\n",
    "      - share_decoder_input_output_embed: usually, the projection matrix of the decoder will share weights with the decoder input embeddings\n",
    "  - *dictionary*: the dictionary provided by fairseq\n",
    "  - *embed_tokens*: an instance of token embeddings (nn.Embedding)\n",
    "- Inputs: \n",
    "    - *prev_output_tokens*: integer sequence representing the right-shifted target e.g. 1, 28, 29, 205, 2 \n",
    "    - *encoder_out*: encoder's output.\n",
    "    - *incremental_state*: in order to speed up decoding during test time, we will save the hidden state of each timestep. see forward() for details.\n",
    "- Outputs: \n",
    "    - *outputs*: the logits (before softmax) output of decoder for each timesteps\n",
    "    - *extra*: unsused"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "QfvgqHYDM6Lp"
   },
   "outputs": [],
   "source": [
    "class RNNDecoder(FairseqIncrementalDecoder):\n",
    "    def __init__(self, args, dictionary, embed_tokens):\n",
    "        super().__init__(dictionary)\n",
    "        self.embed_tokens = embed_tokens\n",
    "        \n",
    "        assert args.decoder_layers == args.encoder_layers, f\"\"\"seq2seq rnn requires that encoder \n",
    "        and decoder have same layers of rnn. got: {args.encoder_layers, args.decoder_layers}\"\"\"\n",
    "        assert args.decoder_ffn_embed_dim == args.encoder_ffn_embed_dim*2, f\"\"\"seq2seq-rnn requires \n",
    "        that decoder hidden to be 2*encoder hidden dim. got: {args.decoder_ffn_embed_dim, args.encoder_ffn_embed_dim*2}\"\"\"\n",
    "        \n",
    "        self.embed_dim = args.decoder_embed_dim\n",
    "        self.hidden_dim = args.decoder_ffn_embed_dim\n",
    "        self.num_layers = args.decoder_layers\n",
    "        \n",
    "        \n",
    "        self.dropout_in_module = nn.Dropout(args.dropout)\n",
    "        self.rnn = nn.GRU(\n",
    "            self.embed_dim, \n",
    "            self.hidden_dim, \n",
    "            self.num_layers, \n",
    "            dropout=args.dropout, \n",
    "            batch_first=False, \n",
    "            bidirectional=False\n",
    "        )\n",
    "        self.attention = AttentionLayer(\n",
    "            self.embed_dim, self.hidden_dim, self.embed_dim, bias=False\n",
    "        ) \n",
    "        # self.attention = None\n",
    "        self.dropout_out_module = nn.Dropout(args.dropout)\n",
    "        \n",
    "        if self.hidden_dim != self.embed_dim:\n",
    "            self.project_out_dim = nn.Linear(self.hidden_dim, self.embed_dim)\n",
    "        else:\n",
    "            self.project_out_dim = None\n",
    "        \n",
    "        if args.share_decoder_input_output_embed:\n",
    "            self.output_projection = nn.Linear(\n",
    "                self.embed_tokens.weight.shape[1],\n",
    "                self.embed_tokens.weight.shape[0],\n",
    "                bias=False,\n",
    "            )\n",
    "            self.output_projection.weight = self.embed_tokens.weight\n",
    "        else:\n",
    "            self.output_projection = nn.Linear(\n",
    "                self.output_embed_dim, len(dictionary), bias=False\n",
    "            )\n",
    "            nn.init.normal_(\n",
    "                self.output_projection.weight, mean=0, std=self.output_embed_dim ** -0.5\n",
    "            )\n",
    "        \n",
    "    def forward(self, prev_output_tokens, encoder_out, incremental_state=None, **unused):\n",
    "        # extract the outputs from encoder\n",
    "        encoder_outputs, encoder_hiddens, encoder_padding_mask = encoder_out\n",
    "        # outputs:          seq_len x batch x num_directions*hidden\n",
    "        # encoder_hiddens:  num_layers x batch x num_directions*encoder_hidden\n",
    "        # padding_mask:     seq_len x batch\n",
    "        \n",
    "        if incremental_state is not None and len(incremental_state) > 0:\n",
    "            # if the information from last timestep is retained, we can continue from there instead of starting from bos\n",
    "            prev_output_tokens = prev_output_tokens[:, -1:]\n",
    "            cache_state = self.get_incremental_state(incremental_state, \"cached_state\")\n",
    "            prev_hiddens = cache_state[\"prev_hiddens\"]\n",
    "        else:\n",
    "            # incremental state does not exist, either this is training time, or the first timestep of test time\n",
    "            # prepare for seq2seq: pass the encoder_hidden to the decoder hidden states\n",
    "            prev_hiddens = encoder_hiddens\n",
    "        \n",
    "        bsz, seqlen = prev_output_tokens.size()\n",
    "        \n",
    "        # embed tokens\n",
    "        x = self.embed_tokens(prev_output_tokens)\n",
    "        x = self.dropout_in_module(x)\n",
    "\n",
    "        # B x T x C -> T x B x C\n",
    "        x = x.transpose(0, 1)\n",
    "                \n",
    "        # decoder-to-encoder attention\n",
    "        if self.attention is not None:\n",
    "            x, attn = self.attention(x, encoder_outputs, encoder_padding_mask)\n",
    "                        \n",
    "        # pass thru unidirectional RNN\n",
    "        x, final_hiddens = self.rnn(x, prev_hiddens)\n",
    "        # outputs = [sequence len, batch size, hid dim]\n",
    "        # hidden =  [num_layers * directions, batch size  , hid dim]\n",
    "        x = self.dropout_out_module(x)\n",
    "                \n",
    "        # project to embedding size (if hidden differs from embed size, and share_embedding is True, \n",
    "        # we need to do an extra projection)\n",
    "        if self.project_out_dim != None:\n",
    "            x = self.project_out_dim(x)\n",
    "        \n",
    "        # project to vocab size\n",
    "        x = self.output_projection(x)\n",
    "        \n",
    "        # T x B x C -> B x T x C\n",
    "        x = x.transpose(1, 0)\n",
    "        \n",
    "        # if incremental, record the hidden states of current timestep, which will be restored in the next timestep\n",
    "        cache_state = {\n",
    "            \"prev_hiddens\": final_hiddens,\n",
    "        }\n",
    "        self.set_incremental_state(incremental_state, \"cached_state\", cache_state)\n",
    "        \n",
    "        return x, None\n",
    "    \n",
    "    def reorder_incremental_state(\n",
    "        self,\n",
    "        incremental_state,\n",
    "        new_order,\n",
    "    ):\n",
    "        # This is used by fairseq's beam search. How and why is not particularly important here.\n",
    "        cache_state = self.get_incremental_state(incremental_state, \"cached_state\")\n",
    "        prev_hiddens = cache_state[\"prev_hiddens\"]\n",
    "        prev_hiddens = [p.index_select(0, new_order) for p in prev_hiddens]\n",
    "        cache_state = {\n",
    "            \"prev_hiddens\": torch.stack(prev_hiddens),\n",
    "        }\n",
    "        self.set_incremental_state(incremental_state, \"cached_state\", cache_state)\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UDAPmxjRNEEL"
   },
   "source": [
    "## Seq2Seq\n",
    "- Composed of **Encoder** and **Decoder**\n",
    "- Recieves inputs and pass to **Encoder** \n",
    "- Pass the outputs from **Encoder** to **Decoder**\n",
    "- **Decoder** will decode according to outputs of previous timesteps as well as **Encoder** outputs  \n",
    "- Once done decoding, return the **Decoder** outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "oRwKdLa0NEU6"
   },
   "outputs": [],
   "source": [
    "class Seq2Seq(FairseqEncoderDecoderModel):\n",
    "    def __init__(self, args, encoder, decoder):\n",
    "        super().__init__(encoder, decoder)\n",
    "        self.args = args\n",
    "    \n",
    "    def forward(\n",
    "        self,\n",
    "        src_tokens,\n",
    "        src_lengths,\n",
    "        prev_output_tokens,\n",
    "        return_all_hiddens: bool = True,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Run the forward pass for an encoder-decoder model.\n",
    "        \"\"\"\n",
    "        encoder_out = self.encoder(\n",
    "            src_tokens, src_lengths=src_lengths, return_all_hiddens=return_all_hiddens\n",
    "        )\n",
    "        logits, extra = self.decoder(\n",
    "            prev_output_tokens,\n",
    "            encoder_out=encoder_out,\n",
    "            src_lengths=src_lengths,\n",
    "            return_all_hiddens=return_all_hiddens,\n",
    "        )\n",
    "        return logits, extra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zu3C2JfqNHzk"
   },
   "source": [
    "# Model Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "nyI9FOx-NJ2m"
   },
   "outputs": [],
   "source": [
    "# # HINT: transformer architecture\n",
    "from fairseq.models.transformer import (\n",
    "    TransformerEncoder, \n",
    "    TransformerDecoder,\n",
    ")\n",
    "\n",
    "def build_model(args, task):\n",
    "    \"\"\" build a model instance based on hyperparameters \"\"\"\n",
    "    src_dict, tgt_dict = task.source_dictionary, task.target_dictionary\n",
    "\n",
    "    # token embeddings\n",
    "    encoder_embed_tokens = nn.Embedding(len(src_dict), args.encoder_embed_dim, src_dict.pad())\n",
    "    decoder_embed_tokens = nn.Embedding(len(tgt_dict), args.decoder_embed_dim, tgt_dict.pad())\n",
    "    \n",
    "    # encoder decoder\n",
    "    # encoder = RNNEncoder(args, src_dict, encoder_embed_tokens)\n",
    "    # decoder = RNNDecoder(args, tgt_dict, decoder_embed_tokens)\n",
    "    encoder = TransformerEncoder(args, src_dict, encoder_embed_tokens)\n",
    "    decoder = TransformerDecoder(args, tgt_dict, decoder_embed_tokens)\n",
    "\n",
    "    # sequence to sequence model\n",
    "    model = Seq2Seq(args, encoder, decoder)\n",
    "    \n",
    "    # initialization for seq2seq model is important, requires extra handling\n",
    "    def init_params(module):\n",
    "        from fairseq.modules import MultiheadAttention\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        if isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=0.02)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        if isinstance(module, MultiheadAttention):\n",
    "            module.q_proj.weight.data.normal_(mean=0.0, std=0.02)\n",
    "            module.k_proj.weight.data.normal_(mean=0.0, std=0.02)\n",
    "            module.v_proj.weight.data.normal_(mean=0.0, std=0.02)\n",
    "        if isinstance(module, nn.RNNBase):\n",
    "            for name, param in module.named_parameters():\n",
    "                if \"weight\" in name or \"bias\" in name:\n",
    "                    param.data.uniform_(-0.1, 0.1)\n",
    "            \n",
    "    # weight initialization\n",
    "    model.apply(init_params)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ce5n4eS7NQNy"
   },
   "source": [
    "## Architecture Related Configuration\n",
    "\n",
    "For strong baseline, please refer to the hyperparameters for *transformer-base* in Table 3 in [Attention is all you need](#vaswani2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "Cyn30VoGNT6N"
   },
   "outputs": [],
   "source": [
    "arch_args = Namespace(\n",
    "    encoder_embed_dim=512,\n",
    "    encoder_ffn_embed_dim=1024,\n",
    "    encoder_layers=6,\n",
    "    decoder_embed_dim=512,\n",
    "    decoder_ffn_embed_dim=1024,\n",
    "    decoder_layers=6,\n",
    "    share_decoder_input_output_embed=True,\n",
    "    dropout=0.2,\n",
    ")\n",
    "\n",
    "# HINT: these patches on parameters for Transformer\n",
    "def add_transformer_args(args):\n",
    "    args.encoder_attention_heads=8\n",
    "    args.encoder_normalize_before=True\n",
    "    \n",
    "    args.decoder_attention_heads=8\n",
    "    args.decoder_normalize_before=True\n",
    "    \n",
    "    args.activation_fn=\"gelu\"\n",
    "    args.max_source_positions=1024\n",
    "    args.max_target_positions=1024\n",
    "    \n",
    "    # patches on default parameters for Transformer (those not set above)\n",
    "    from fairseq.models.transformer import base_architecture\n",
    "    base_architecture(arch_args)\n",
    "\n",
    "add_transformer_args(arch_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cyn30VoGNT6N"
   },
   "outputs": [],
   "source": [
    "arch_args = Namespace(\n",
    "    encoder_embed_dim=512,\n",
    "    encoder_ffn_embed_dim=1024,\n",
    "    encoder_layers=6,\n",
    "    decoder_embed_dim=512,\n",
    "    decoder_ffn_embed_dim=1024,\n",
    "    decoder_layers=6,\n",
    "    share_decoder_input_output_embed=True,\n",
    "    dropout=0.2,\n",
    ")\n",
    "\n",
    "# HINT: these patches on parameters for Transformer\n",
    "def add_transformer_args(args):\n",
    "    args.encoder_attention_heads=8\n",
    "    args.encoder_normalize_before=True\n",
    "    \n",
    "    args.decoder_attention_heads=8\n",
    "    args.decoder_normalize_before=True\n",
    "    \n",
    "    args.activation_fn=\"gelu\"\n",
    "    args.max_source_positions=1024\n",
    "    args.max_target_positions=1024\n",
    "    \n",
    "    # patches on default parameters for Transformer (those not set above)\n",
    "    from fairseq.models.transformer import base_architecture\n",
    "    base_architecture(arch_args)\n",
    "\n",
    "add_transformer_args(arch_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "Nbb76QLCNZZZ"
   },
   "outputs": [],
   "source": [
    "if config.use_wandb:\n",
    "    wandb.config.update(vars(arch_args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "7ZWfxsCDNatH"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-03 12:18:37 | INFO | ml-hw5 | Seq2Seq(\n",
      "  (encoder): TransformerEncoder(\n",
      "    (dropout_module): FairseqDropout()\n",
      "    (embed_tokens): Embedding(8000, 512, padding_idx=1)\n",
      "    (embed_positions): SinusoidalPositionalEmbedding()\n",
      "    (layers): ModuleList(\n",
      "      (0): TransformerEncoderLayerBase(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n",
      "        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (1): TransformerEncoderLayerBase(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n",
      "        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (2): TransformerEncoderLayerBase(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n",
      "        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (3): TransformerEncoderLayerBase(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n",
      "        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (4): TransformerEncoderLayerBase(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n",
      "        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (5): TransformerEncoderLayerBase(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n",
      "        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (decoder): TransformerDecoder(\n",
      "    (dropout_module): FairseqDropout()\n",
      "    (embed_tokens): Embedding(8000, 512, padding_idx=1)\n",
      "    (embed_positions): SinusoidalPositionalEmbedding()\n",
      "    (layers): ModuleList(\n",
      "      (0): TransformerDecoderLayerBase(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n",
      "        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (1): TransformerDecoderLayerBase(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n",
      "        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (2): TransformerDecoderLayerBase(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n",
      "        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (3): TransformerDecoderLayerBase(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n",
      "        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (4): TransformerDecoderLayerBase(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n",
      "        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (5): TransformerDecoderLayerBase(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n",
      "        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    (output_projection): Linear(in_features=512, out_features=8000, bias=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = build_model(arch_args, task)\n",
    "logger.info(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aHll7GRNNdqc"
   },
   "source": [
    "# Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rUB9f1WCNgMH"
   },
   "source": [
    "## Loss: Label Smoothing Regularization\n",
    "* let the model learn to generate less concentrated distribution, and prevent over-confidence\n",
    "* sometimes the ground truth may not be the only answer. thus, when calculating loss, we reserve some probability for incorrect labels\n",
    "* avoids overfitting\n",
    "\n",
    "code [source](https://fairseq.readthedocs.io/en/latest/_modules/fairseq/criterions/label_smoothed_cross_entropy.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "IgspdJn0NdYF"
   },
   "outputs": [],
   "source": [
    "class LabelSmoothedCrossEntropyCriterion(nn.Module):\n",
    "    def __init__(self, smoothing, ignore_index=None, reduce=True):\n",
    "        super().__init__()\n",
    "        self.smoothing = smoothing\n",
    "        self.ignore_index = ignore_index\n",
    "        self.reduce = reduce\n",
    "    \n",
    "    def forward(self, lprobs, target):\n",
    "        if target.dim() == lprobs.dim() - 1:\n",
    "            target = target.unsqueeze(-1)\n",
    "        # nll: Negative log likelihood，the cross-entropy when target is one-hot. following line is same as F.nll_loss\n",
    "        nll_loss = -lprobs.gather(dim=-1, index=target)\n",
    "        #  reserve some probability for other labels. thus when calculating cross-entropy, \n",
    "        # equivalent to summing the log probs of all labels\n",
    "        smooth_loss = -lprobs.sum(dim=-1, keepdim=True)\n",
    "        if self.ignore_index is not None:\n",
    "            pad_mask = target.eq(self.ignore_index)\n",
    "            nll_loss.masked_fill_(pad_mask, 0.0)\n",
    "            smooth_loss.masked_fill_(pad_mask, 0.0)\n",
    "        else:\n",
    "            nll_loss = nll_loss.squeeze(-1)\n",
    "            smooth_loss = smooth_loss.squeeze(-1)\n",
    "        if self.reduce:\n",
    "            nll_loss = nll_loss.sum()\n",
    "            smooth_loss = smooth_loss.sum()\n",
    "        # when calculating cross-entropy, add the loss of other labels\n",
    "        eps_i = self.smoothing / lprobs.size(-1)\n",
    "        loss = (1.0 - self.smoothing) * nll_loss + eps_i * smooth_loss\n",
    "        return loss\n",
    "\n",
    "# generally, 0.1 is good enough\n",
    "criterion = LabelSmoothedCrossEntropyCriterion(\n",
    "    smoothing=0.1,\n",
    "    ignore_index=task.target_dictionary.pad(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aRalDto2NkJJ"
   },
   "source": [
    "## Optimizer: Adam + lr scheduling\n",
    "Inverse square root scheduling is important to the stability when training Transformer. It's later used on RNN as well.\n",
    "Update the learning rate according to the following equation. Linearly increase the first stage, then decay proportionally to the inverse square root of timestep.\n",
    "$$lrate = d_{\\text{model}}^{-0.5}\\cdot\\min({step\\_num}^{-0.5},{step\\_num}\\cdot{warmup\\_steps}^{-1.5})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "sS7tQj1ROBYm"
   },
   "outputs": [],
   "source": [
    "def get_rate(d_model, step_num, warmup_step):\n",
    "    lr = d_model **(-.5) * min(step_num ** (-.5), step_num * warmup_step ** (-1.5))\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "J8hoAjHPNkh3"
   },
   "outputs": [],
   "source": [
    "class NoamOpt:\n",
    "    \"Optim wrapper that implements rate.\"\n",
    "    def __init__(self, model_size, factor, warmup, optimizer):\n",
    "        self.optimizer = optimizer\n",
    "        self._step = 0\n",
    "        self.warmup = warmup\n",
    "        self.factor = factor\n",
    "        self.model_size = model_size\n",
    "        self._rate = 0\n",
    "    \n",
    "    @property\n",
    "    def param_groups(self):\n",
    "        return self.optimizer.param_groups\n",
    "        \n",
    "    def multiply_grads(self, c):\n",
    "        \"\"\"Multiplies grads by a constant *c*.\"\"\"                \n",
    "        for group in self.param_groups:\n",
    "            for p in group['params']:\n",
    "                if p.grad is not None:\n",
    "                    p.grad.data.mul_(c)\n",
    "        \n",
    "    def step(self):\n",
    "        \"Update parameters and rate\"\n",
    "        self._step += 1\n",
    "        rate = self.rate()\n",
    "        for p in self.param_groups:\n",
    "            p['lr'] = rate\n",
    "        self._rate = rate\n",
    "        self.optimizer.step()\n",
    "        \n",
    "    def rate(self, step = None):\n",
    "        \"Implement `lrate` above\"\n",
    "        if step is None:\n",
    "            step = self._step\n",
    "        return 0 if not step else self.factor * get_rate(self.model_size, step, self.warmup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VFJlkOMONsc6"
   },
   "source": [
    "## Scheduling Visualized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "A135fwPCNrQs"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f0fb7299850>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "optimizer = NoamOpt(\n",
    "    model_size=arch_args.encoder_embed_dim, \n",
    "    factor=config.lr_factor, \n",
    "    warmup=config.lr_warmup, \n",
    "    optimizer=torch.optim.AdamW(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9, weight_decay=0.0001))\n",
    "plt.plot(np.arange(1, 100000), [optimizer.rate(i) for i in range(1, 100000)])\n",
    "plt.legend([f\"{optimizer.model_size}:{optimizer.warmup}\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TOR0g-cVO5ZO"
   },
   "source": [
    "# Training Procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f-0ZjbK3O8Iv"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "foal3xM1O404"
   },
   "outputs": [],
   "source": [
    "from fairseq.data import iterators\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "def batch_cosine_similarity(a:torch.tensor, b: torch.tensor, eps=1e-6):\n",
    "    a_n, b_n = a.norm(dim=1)[:, None], b.norm(dim=1)[:, None]\n",
    "    a_norm = a / torch.clamp(a_n, min=eps)\n",
    "    b_norm = b / torch.clamp(b_n, min=eps)\n",
    "    sim_mt = torch.mm(a_norm, b_norm.transpose(0, 1))\n",
    "    return sim_mt\n",
    "\n",
    "\n",
    "def train_one_epoch(epoch_itr, model, task, criterion, optimizer, accum_steps=1):\n",
    "    itr = epoch_itr.next_epoch_itr(shuffle=True)\n",
    "    itr = iterators.GroupedIterator(itr, accum_steps) # gradient accumulation: update every accum_steps samples\n",
    "    \n",
    "    stats = {\"loss\": []}\n",
    "    scaler = GradScaler() # automatic mixed precision (amp) \n",
    "    \n",
    "    model.train()\n",
    "    progress = tqdm.tqdm(itr, desc=f\"train epoch {epoch_itr.epoch}\", leave=False)\n",
    "    for samples in progress:\n",
    "        model.zero_grad()\n",
    "        accum_loss = 0\n",
    "        sample_size = 0\n",
    "        # gradient accumulation: update every accum_steps samples\n",
    "        for i, sample in enumerate(samples):\n",
    "            if i == 1:\n",
    "                # emptying the CUDA cache after the first step can reduce the chance of OOM\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "            sample = utils.move_to_cuda(sample, device=device)\n",
    "            target = sample[\"target\"]\n",
    "            sample_size_i = sample[\"ntokens\"]\n",
    "            sample_size += sample_size_i\n",
    "            \n",
    "            # mixed precision training\n",
    "            with autocast():\n",
    "                net_output = model.forward(**sample[\"net_input\"])\n",
    "                lprobs = F.log_softmax(net_output[0], -1)            \n",
    "                loss = criterion(lprobs.view(-1, lprobs.size(-1)), target.view(-1))\n",
    "                \n",
    "                # logging\n",
    "                accum_loss += loss.item()\n",
    "                # back-prop\n",
    "                scaler.scale(loss).backward()                \n",
    "        \n",
    "        scaler.unscale_(optimizer)\n",
    "        optimizer.multiply_grads(1 / (sample_size or 1.0)) # (sample_size or 1.0) handles the case of a zero gradient\n",
    "        gnorm = nn.utils.clip_grad_norm_(model.parameters(), config.clip_norm) # grad norm clipping prevents gradient exploding\n",
    "        \n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        # logging\n",
    "        loss_print = accum_loss/sample_size\n",
    "        stats[\"loss\"].append(loss_print)\n",
    "        progress.set_postfix(loss=loss_print)\n",
    "        if config.use_wandb:\n",
    "            wandb.log({\n",
    "                \"train/loss\": loss_print,\n",
    "                \"train/grad_norm\": gnorm.item(),\n",
    "                \"train/lr\": optimizer.rate(),\n",
    "                \"train/sample_size\": sample_size,\n",
    "            })\n",
    "    pos_emb = model.decoder.embed_positions.weights.cpu().detach()\n",
    "    if config.use_wandb:\n",
    "        wandb.log({\"decoder_positional_embedding\": wandb.Image(batch_cosine_similarity(pos_emb, pos_emb))})\n",
    "\n",
    "    loss_print = np.mean(stats[\"loss\"])\n",
    "    logger.info(f\"training loss: {loss_print:.4f}\")\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gt1lX3DRO_yU"
   },
   "source": [
    "## Validation & Inference\n",
    "To prevent overfitting, validation is required every epoch to validate the performance on unseen data.\n",
    "- the procedure is essensially same as training, with the addition of inference step\n",
    "- after validation we can save the model weights\n",
    "\n",
    "Validation loss alone cannot describe the actual performance of the model\n",
    "- Directly produce translation hypotheses based on current model, then calculate BLEU with the reference translation\n",
    "- We can also manually examine the hypotheses' quality\n",
    "- We use fairseq's sequence generator for beam search to generate translation hypotheses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "2og80HYQPAKq"
   },
   "outputs": [],
   "source": [
    "# fairseq's beam search generator\n",
    "# given model and input seqeunce, produce translation hypotheses by beam search\n",
    "sequence_generator = task.build_generator([model], config)\n",
    "\n",
    "def decode(toks, dictionary):\n",
    "    # convert from Tensor to human readable sentence\n",
    "    s = dictionary.string(\n",
    "        toks.int().cpu(),\n",
    "        config.post_process,\n",
    "    )\n",
    "    return s if s else \"<unk>\"\n",
    "\n",
    "def inference_step(sample, model):\n",
    "    gen_out = sequence_generator.generate([model], sample)\n",
    "    srcs = []\n",
    "    hyps = []\n",
    "    refs = []\n",
    "    for i in range(len(gen_out)):\n",
    "        # for each sample, collect the input, hypothesis and reference, later be used to calculate BLEU\n",
    "        srcs.append(decode(\n",
    "            utils.strip_pad(sample[\"net_input\"][\"src_tokens\"][i], task.source_dictionary.pad()), \n",
    "            task.source_dictionary,\n",
    "        ))\n",
    "        hyps.append(decode(\n",
    "            gen_out[i][0][\"tokens\"], # 0 indicates using the top hypothesis in beam\n",
    "            task.target_dictionary,\n",
    "        ))\n",
    "        refs.append(decode(\n",
    "            utils.strip_pad(sample[\"target\"][i], task.target_dictionary.pad()), \n",
    "            task.target_dictionary,\n",
    "        ))\n",
    "    return srcs, hyps, refs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "y1o7LeDkPDsd"
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "import sacrebleu\n",
    "\n",
    "def validate(model, task, criterion, log_to_wandb=True):\n",
    "    logger.info('begin validation')\n",
    "    itr = load_data_iterator(task, \"valid\", 1, config.max_tokens, config.num_workers).next_epoch_itr(shuffle=False)\n",
    "    \n",
    "    stats = {\"loss\":[], \"bleu\": 0, \"srcs\":[], \"hyps\":[], \"refs\":[]}\n",
    "    srcs = []\n",
    "    hyps = []\n",
    "    refs = []\n",
    "    \n",
    "    model.eval()\n",
    "    progress = tqdm.tqdm(itr, desc=f\"validation\", leave=False)\n",
    "    with torch.no_grad():\n",
    "        for i, sample in enumerate(progress):\n",
    "            # validation loss\n",
    "            sample = utils.move_to_cuda(sample, device=device)\n",
    "            net_output = model.forward(**sample[\"net_input\"])\n",
    "\n",
    "            lprobs = F.log_softmax(net_output[0], -1)\n",
    "            target = sample[\"target\"]\n",
    "            sample_size = sample[\"ntokens\"]\n",
    "            loss = criterion(lprobs.view(-1, lprobs.size(-1)), target.view(-1)) / sample_size\n",
    "            progress.set_postfix(valid_loss=loss.item())\n",
    "            stats[\"loss\"].append(loss)\n",
    "            \n",
    "            # do inference\n",
    "            s, h, r = inference_step(sample, model)\n",
    "            srcs.extend(s)\n",
    "            hyps.extend(h)\n",
    "            refs.extend(r)\n",
    "            \n",
    "    tok = 'zh' if task.cfg.target_lang == 'zh' else '13a'\n",
    "    stats[\"loss\"] = torch.stack(stats[\"loss\"]).mean().item()\n",
    "    stats[\"bleu\"] = sacrebleu.corpus_bleu(hyps, [refs], tokenize=tok) # 計算BLEU score\n",
    "    stats[\"srcs\"] = srcs\n",
    "    stats[\"hyps\"] = hyps\n",
    "    stats[\"refs\"] = refs\n",
    "    \n",
    "    if config.use_wandb and log_to_wandb:\n",
    "        wandb.log({\n",
    "            \"valid/loss\": stats[\"loss\"],\n",
    "            \"valid/bleu\": stats[\"bleu\"].score,\n",
    "        }, commit=False)\n",
    "    \n",
    "    showid = np.random.randint(len(hyps))\n",
    "    logger.info(\"example source: \" + srcs[showid])\n",
    "    logger.info(\"example hypothesis: \" + hyps[showid])\n",
    "    logger.info(\"example reference: \" + refs[showid])\n",
    "    \n",
    "    # show bleu results\n",
    "    logger.info(f\"validation loss:\\t{stats['loss']:.4f}\")\n",
    "    logger.info(stats[\"bleu\"].format())\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1sRF6nd4PGEE"
   },
   "source": [
    "# Save and Load Model Weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "edBuLlkuPGr9"
   },
   "outputs": [],
   "source": [
    "def validate_and_save(model, task, criterion, optimizer, epoch, save=True):   \n",
    "    stats = validate(model, task, criterion)\n",
    "    bleu = stats['bleu']\n",
    "    loss = stats['loss']\n",
    "    if save:\n",
    "        # save epoch checkpoints\n",
    "        savedir = Path(config.savedir).absolute()\n",
    "        savedir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        check = {\n",
    "            \"model\": model.state_dict(),\n",
    "            \"stats\": {\"bleu\": bleu.score, \"loss\": loss},\n",
    "            \"optim\": {\"step\": optimizer._step}\n",
    "        }\n",
    "        torch.save(check, savedir/f\"checkpoint{epoch}.pt\")\n",
    "        shutil.copy(savedir/f\"checkpoint{epoch}.pt\", savedir/f\"checkpoint_last.pt\")\n",
    "        logger.info(f\"saved epoch checkpoint: {savedir}/checkpoint{epoch}.pt\")\n",
    "    \n",
    "        # save epoch samples\n",
    "        with open(savedir/f\"samples{epoch}.{config.source_lang}-{config.target_lang}.txt\", \"w\") as f:\n",
    "            for s, h in zip(stats[\"srcs\"], stats[\"hyps\"]):\n",
    "                f.write(f\"{s}\\t{h}\\n\")\n",
    "\n",
    "        # get best valid bleu    \n",
    "        if getattr(validate_and_save, \"best_bleu\", 0) < bleu.score:\n",
    "            validate_and_save.best_bleu = bleu.score\n",
    "            torch.save(check, savedir/f\"checkpoint_best.pt\")\n",
    "            \n",
    "        del_file = savedir / f\"checkpoint{epoch - config.keep_last_epochs}.pt\"\n",
    "        if del_file.exists():\n",
    "            del_file.unlink()\n",
    "    \n",
    "    return stats\n",
    "\n",
    "def try_load_checkpoint(model, optimizer=None, name=None):\n",
    "    name = name if name else \"checkpoint_last.pt\"\n",
    "    checkpath = Path(config.savedir)/name\n",
    "    if checkpath.exists():\n",
    "        check = torch.load(checkpath)\n",
    "        model.load_state_dict(check[\"model\"])\n",
    "        stats = check[\"stats\"]\n",
    "        step = \"unknown\"\n",
    "        if optimizer != None:\n",
    "            optimizer._step = step = check[\"optim\"][\"step\"]\n",
    "        logger.info(f\"loaded checkpoint {checkpath}: step={step} loss={stats['loss']} bleu={stats['bleu']}\")\n",
    "    else:\n",
    "        logger.info(f\"no checkpoints found at {checkpath}!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KyIFpibfPJ5u"
   },
   "source": [
    "# Main\n",
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "hu7RZbCUPKQr"
   },
   "outputs": [],
   "source": [
    "model = model.to(device=device)\n",
    "criterion = criterion.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "5xxlJxU2PeAo"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-03 12:18:38 | INFO | ml-hw5 | task: TranslationTask\n",
      "2022-04-03 12:18:38 | INFO | ml-hw5 | encoder: TransformerEncoder\n",
      "2022-04-03 12:18:38 | INFO | ml-hw5 | decoder: TransformerDecoder\n",
      "2022-04-03 12:18:38 | INFO | ml-hw5 | criterion: LabelSmoothedCrossEntropyCriterion\n",
      "2022-04-03 12:18:38 | INFO | ml-hw5 | optimizer: NoamOpt\n",
      "2022-04-03 12:18:38 | INFO | ml-hw5 | num. model params: 39,737,344 (num. trained: 39,737,344)\n",
      "2022-04-03 12:18:38 | INFO | ml-hw5 | max tokens per batch = 8192, accumulate steps = 2\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"task: {}\".format(task.__class__.__name__))\n",
    "logger.info(\"encoder: {}\".format(model.encoder.__class__.__name__))\n",
    "logger.info(\"decoder: {}\".format(model.decoder.__class__.__name__))\n",
    "logger.info(\"criterion: {}\".format(criterion.__class__.__name__))\n",
    "logger.info(\"optimizer: {}\".format(optimizer.__class__.__name__))\n",
    "logger.info(\n",
    "    \"num. model params: {:,} (num. trained: {:,})\".format(\n",
    "        sum(p.numel() for p in model.parameters()),\n",
    "        sum(p.numel() for p in model.parameters() if p.requires_grad),\n",
    "    )\n",
    ")\n",
    "logger.info(f\"max tokens per batch = {config.max_tokens}, accumulate steps = {config.accum_steps}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "MSPRqpQUPfaX"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-03 12:18:39 | WARNING | fairseq.tasks.fairseq_task | 1 samples have invalid sizes and will be skipped, max_positions=(1024, 1024), first few sample ids=[326674]\n",
      "2022-04-03 12:18:39 | INFO | ml-hw5 | no checkpoints found at checkpoints/transformer_zh-en1/checkpoint_last.pt!\n",
      "2022-04-03 12:18:39 | INFO | fairseq.data.iterators | grouped total_num_itrs = 800\n",
      "2022-04-03 12:23:03 | INFO | ml-hw5 | training loss: 6.3396                \n",
      "2022-04-03 12:23:03 | INFO | ml-hw5 | begin validation\n",
      "2022-04-03 12:23:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2022-04-03 12:23:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2022-04-03 12:23:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
      "2022-04-03 12:23:26 | INFO | ml-hw5 | example source: 它是個美麗的國家 , 位在西非 。\n",
      "2022-04-03 12:23:26 | INFO | ml-hw5 | example hypothesis: it's a lot of the world .\n",
      "2022-04-03 12:23:26 | INFO | ml-hw5 | example reference: it is a beautiful country located in west africa .\n",
      "2022-04-03 12:23:26 | INFO | ml-hw5 | validation loss:\t4.9830\n",
      "2022-04-03 12:23:26 | INFO | ml-hw5 | BLEU = 0.84 23.3/2.4/0.3/0.1 (BP = 0.838 ratio = 0.850 hyp_len = 65470 ref_len = 77050)\n",
      "2022-04-03 12:23:27 | INFO | ml-hw5 | saved epoch checkpoint: /home/user/homework/ML/hw5/checkpoints/transformer_zh-en1/checkpoint1.pt\n",
      "2022-04-03 12:23:27 | INFO | ml-hw5 | end of epoch 1\n",
      "2022-04-03 12:23:27 | INFO | fairseq.data.iterators | grouped total_num_itrs = 800\n",
      "2022-04-03 12:27:51 | INFO | ml-hw5 | training loss: 4.6205                \n",
      "2022-04-03 12:27:51 | INFO | ml-hw5 | begin validation\n",
      "2022-04-03 12:28:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2022-04-03 12:28:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2022-04-03 12:28:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
      "2022-04-03 12:28:14 | INFO | ml-hw5 | example source: 他懂得策略 。\n",
      "2022-04-03 12:28:14 | INFO | ml-hw5 | example hypothesis: he knows what he's going to do .\n",
      "2022-04-03 12:28:14 | INFO | ml-hw5 | example reference: arthur samuel knew strategy .\n",
      "2022-04-03 12:28:14 | INFO | ml-hw5 | validation loss:\t4.0684\n",
      "2022-04-03 12:28:14 | INFO | ml-hw5 | BLEU = 5.19 36.1/9.6/3.2/1.1 (BP = 0.880 ratio = 0.887 hyp_len = 68336 ref_len = 77050)\n",
      "2022-04-03 12:28:15 | INFO | ml-hw5 | saved epoch checkpoint: /home/user/homework/ML/hw5/checkpoints/transformer_zh-en1/checkpoint2.pt\n",
      "2022-04-03 12:28:16 | INFO | ml-hw5 | end of epoch 2\n",
      "2022-04-03 12:28:16 | INFO | fairseq.data.iterators | grouped total_num_itrs = 800\n",
      "2022-04-03 12:32:42 | INFO | ml-hw5 | training loss: 3.9302                \n",
      "2022-04-03 12:32:42 | INFO | ml-hw5 | begin validation\n",
      "2022-04-03 12:33:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2022-04-03 12:33:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2022-04-03 12:33:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
      "2022-04-03 12:33:05 | INFO | ml-hw5 | example source: 你可以成為傑出的一代 。 」\n",
      "2022-04-03 12:33:05 | INFO | ml-hw5 | example hypothesis: you can become a modern generation . \"\n",
      "2022-04-03 12:33:05 | INFO | ml-hw5 | example reference: you can be that great generation . \"\n",
      "2022-04-03 12:33:05 | INFO | ml-hw5 | validation loss:\t3.5250\n",
      "2022-04-03 12:33:05 | INFO | ml-hw5 | BLEU = 8.89 44.1/15.3/6.3/2.8 (BP = 0.855 ratio = 0.865 hyp_len = 66629 ref_len = 77050)\n",
      "2022-04-03 12:33:06 | INFO | ml-hw5 | saved epoch checkpoint: /home/user/homework/ML/hw5/checkpoints/transformer_zh-en1/checkpoint3.pt\n",
      "2022-04-03 12:33:06 | INFO | ml-hw5 | end of epoch 3\n",
      "2022-04-03 12:33:06 | INFO | fairseq.data.iterators | grouped total_num_itrs = 800\n",
      "2022-04-03 12:37:31 | INFO | ml-hw5 | training loss: 3.4900                \n",
      "2022-04-03 12:37:31 | INFO | ml-hw5 | begin validation\n",
      "2022-04-03 12:37:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2022-04-03 12:37:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2022-04-03 12:37:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
      "2022-04-03 12:37:54 | INFO | ml-hw5 | example source: 它驅使人們離開大腦聰明的那部份那個潛意識的黑暗深井本能和經驗所在的地方以及所有其他創意的元素還有良好判斷力所在之處它迫使我們去到單薄又呆板有意識的邏輯 。\n",
      "2022-04-03 12:37:54 | INFO | ml-hw5 | example hypothesis: it drives people to leave the smart darkness of the brain that's smart darkness , and the elements of all the creativity and all the other creativity , and it forces us to thin and logic .\n",
      "2022-04-03 12:37:54 | INFO | ml-hw5 | example reference: it drives people from the smart part of the brain that dark , deep well of the subconscious , where instincts and experience , and all the other factors of creativity and good judgment are it drives us to the thin veneer of conscious logic .\n",
      "2022-04-03 12:37:54 | INFO | ml-hw5 | validation loss:\t3.2030\n",
      "2022-04-03 12:37:54 | INFO | ml-hw5 | BLEU = 11.95 48.5/19.1/8.8/4.2 (BP = 0.878 ratio = 0.885 hyp_len = 68195 ref_len = 77050)\n",
      "2022-04-03 12:37:55 | INFO | ml-hw5 | saved epoch checkpoint: /home/user/homework/ML/hw5/checkpoints/transformer_zh-en1/checkpoint4.pt\n",
      "2022-04-03 12:37:55 | INFO | ml-hw5 | end of epoch 4\n",
      "2022-04-03 12:37:56 | INFO | fairseq.data.iterators | grouped total_num_itrs = 800\n",
      "2022-04-03 12:42:20 | INFO | ml-hw5 | training loss: 3.2393                \n",
      "2022-04-03 12:42:20 | INFO | ml-hw5 | begin validation\n",
      "2022-04-03 12:42:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2022-04-03 12:42:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2022-04-03 12:42:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
      "2022-04-03 12:42:41 | INFO | ml-hw5 | example source: 「 事情並無好壞/是我們的思維使之如此 」\n",
      "2022-04-03 12:42:41 | INFO | ml-hw5 | example hypothesis: \" things and bad things are our thoughts . \"\n",
      "2022-04-03 12:42:41 | INFO | ml-hw5 | example reference: that seems like a onequestion iq test .\n",
      "2022-04-03 12:42:41 | INFO | ml-hw5 | validation loss:\t3.0822\n",
      "2022-04-03 12:42:41 | INFO | ml-hw5 | BLEU = 13.18 52.4/22.0/10.8/5.6 (BP = 0.810 ratio = 0.826 hyp_len = 63660 ref_len = 77050)\n",
      "2022-04-03 12:42:41 | INFO | ml-hw5 | saved epoch checkpoint: /home/user/homework/ML/hw5/checkpoints/transformer_zh-en1/checkpoint5.pt\n",
      "2022-04-03 12:42:42 | INFO | ml-hw5 | end of epoch 5\n",
      "2022-04-03 12:42:42 | INFO | fairseq.data.iterators | grouped total_num_itrs = 800\n",
      "2022-04-03 12:47:06 | INFO | ml-hw5 | training loss: 3.0813                \n",
      "2022-04-03 12:47:06 | INFO | ml-hw5 | begin validation\n",
      "2022-04-03 12:47:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2022-04-03 12:47:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2022-04-03 12:47:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
      "2022-04-03 12:47:29 | INFO | ml-hw5 | example source: 謝謝 。\n",
      "2022-04-03 12:47:29 | INFO | ml-hw5 | example hypothesis: thank you .\n",
      "2022-04-03 12:47:29 | INFO | ml-hw5 | example reference: thank you .\n",
      "2022-04-03 12:47:29 | INFO | ml-hw5 | validation loss:\t2.9459\n",
      "2022-04-03 12:47:29 | INFO | ml-hw5 | BLEU = 14.47 52.6/22.8/11.4/6.0 (BP = 0.856 ratio = 0.865 hyp_len = 66671 ref_len = 77050)\n",
      "2022-04-03 12:47:30 | INFO | ml-hw5 | saved epoch checkpoint: /home/user/homework/ML/hw5/checkpoints/transformer_zh-en1/checkpoint6.pt\n",
      "2022-04-03 12:47:31 | INFO | ml-hw5 | end of epoch 6\n",
      "2022-04-03 12:47:31 | INFO | fairseq.data.iterators | grouped total_num_itrs = 800\n",
      "2022-04-03 12:51:56 | INFO | ml-hw5 | training loss: 2.9745                \n",
      "2022-04-03 12:51:56 | INFO | ml-hw5 | begin validation\n",
      "2022-04-03 12:52:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2022-04-03 12:52:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2022-04-03 12:52:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
      "2022-04-03 12:52:18 | INFO | ml-hw5 | example source: 不 。\n",
      "2022-04-03 12:52:18 | INFO | ml-hw5 | example hypothesis: no .\n",
      "2022-04-03 12:52:18 | INFO | ml-hw5 | example reference: no .\n",
      "2022-04-03 12:52:18 | INFO | ml-hw5 | validation loss:\t2.8876\n",
      "2022-04-03 12:52:18 | INFO | ml-hw5 | BLEU = 16.19 53.6/24.0/12.4/6.7 (BP = 0.895 ratio = 0.900 hyp_len = 69354 ref_len = 77050)\n",
      "2022-04-03 12:52:18 | INFO | ml-hw5 | saved epoch checkpoint: /home/user/homework/ML/hw5/checkpoints/transformer_zh-en1/checkpoint7.pt\n",
      "2022-04-03 12:52:19 | INFO | ml-hw5 | end of epoch 7\n",
      "2022-04-03 12:52:19 | INFO | fairseq.data.iterators | grouped total_num_itrs = 800\n",
      "2022-04-03 12:56:44 | INFO | ml-hw5 | training loss: 2.9003                \n",
      "2022-04-03 12:56:44 | INFO | ml-hw5 | begin validation\n",
      "2022-04-03 12:57:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2022-04-03 12:57:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2022-04-03 12:57:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
      "2022-04-03 12:57:07 | INFO | ml-hw5 | example source: 自行車是只在美國南部一些城市正在進行的革命\n",
      "2022-04-03 12:57:07 | INFO | ml-hw5 | example hypothesis: bicycles are the only revolution in the united states .\n",
      "2022-04-03 12:57:07 | INFO | ml-hw5 | example reference: bicycles and bicycling are the current revolution underway in only some american cities .\n",
      "2022-04-03 12:57:07 | INFO | ml-hw5 | validation loss:\t2.8115\n",
      "2022-04-03 12:57:07 | INFO | ml-hw5 | BLEU = 16.75 54.4/25.0/13.2/7.2 (BP = 0.885 ratio = 0.891 hyp_len = 68666 ref_len = 77050)\n",
      "2022-04-03 12:57:08 | INFO | ml-hw5 | saved epoch checkpoint: /home/user/homework/ML/hw5/checkpoints/transformer_zh-en1/checkpoint8.pt\n",
      "2022-04-03 12:57:08 | INFO | ml-hw5 | end of epoch 8\n",
      "2022-04-03 12:57:09 | INFO | fairseq.data.iterators | grouped total_num_itrs = 800\n",
      "2022-04-03 13:01:33 | INFO | ml-hw5 | training loss: 2.8440                \n",
      "2022-04-03 13:01:33 | INFO | ml-hw5 | begin validation\n",
      "2022-04-03 13:01:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2022-04-03 13:01:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2022-04-03 13:01:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
      "2022-04-03 13:01:55 | INFO | ml-hw5 | example source: jc:我覺得很有意思 。\n",
      "2022-04-03 13:01:55 | INFO | ml-hw5 | example hypothesis: jc: i think it's interesting .\n",
      "2022-04-03 13:01:55 | INFO | ml-hw5 | example reference: jc: it makes perfect sense to me .\n",
      "2022-04-03 13:01:55 | INFO | ml-hw5 | validation loss:\t2.8009\n",
      "2022-04-03 13:01:55 | INFO | ml-hw5 | BLEU = 16.79 55.8/25.9/13.8/7.7 (BP = 0.848 ratio = 0.858 hyp_len = 66114 ref_len = 77050)\n",
      "2022-04-03 13:01:56 | INFO | ml-hw5 | saved epoch checkpoint: /home/user/homework/ML/hw5/checkpoints/transformer_zh-en1/checkpoint9.pt\n",
      "2022-04-03 13:01:57 | INFO | ml-hw5 | end of epoch 9\n",
      "2022-04-03 13:01:57 | INFO | fairseq.data.iterators | grouped total_num_itrs = 800\n",
      "2022-04-03 13:06:23 | INFO | ml-hw5 | training loss: 2.7987                 \n",
      "2022-04-03 13:06:23 | INFO | ml-hw5 | begin validation\n",
      "2022-04-03 13:06:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2022-04-03 13:06:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2022-04-03 13:06:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
      "2022-04-03 13:06:46 | INFO | ml-hw5 | example source: 這就是問題所在彼得‧德森指出了這點他用的例子是某種鴨嘴恐龍當時被稱為亞冠龍\n",
      "2022-04-03 13:06:46 | INFO | ml-hw5 | example hypothesis: and that's the problem , peter dson pointed out that he used an example of a duck dinosaur that was called a coronary dinosaur .\n",
      "2022-04-03 13:06:46 | INFO | ml-hw5 | example reference: so this was a problem , and peter dodson pointed this out using some duckbilled dinosaurs then called hypacrosaurus .\n",
      "2022-04-03 13:06:46 | INFO | ml-hw5 | validation loss:\t2.7602\n",
      "2022-04-03 13:06:46 | INFO | ml-hw5 | BLEU = 17.09 56.5/26.6/14.3/8.0 (BP = 0.840 ratio = 0.852 hyp_len = 65636 ref_len = 77050)\n",
      "2022-04-03 13:06:46 | INFO | ml-hw5 | saved epoch checkpoint: /home/user/homework/ML/hw5/checkpoints/transformer_zh-en1/checkpoint10.pt\n",
      "2022-04-03 13:06:47 | INFO | ml-hw5 | end of epoch 10\n",
      "2022-04-03 13:06:47 | INFO | fairseq.data.iterators | grouped total_num_itrs = 800\n",
      "2022-04-03 13:11:12 | INFO | ml-hw5 | training loss: 2.7570                 \n",
      "2022-04-03 13:11:12 | INFO | ml-hw5 | begin validation\n",
      "2022-04-03 13:11:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2022-04-03 13:11:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2022-04-03 13:11:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
      "2022-04-03 13:11:35 | INFO | ml-hw5 | example source: 她說: 「 放下你的身段 , 錢是『綠色』的 。 」\n",
      "2022-04-03 13:11:35 | INFO | ml-hw5 | example hypothesis: she said , \" put your perspective , money is green . \"\n",
      "2022-04-03 13:11:35 | INFO | ml-hw5 | example reference: she said , \" get off your throne . money is green . \"\n",
      "2022-04-03 13:11:35 | INFO | ml-hw5 | validation loss:\t2.7129\n",
      "2022-04-03 13:11:35 | INFO | ml-hw5 | BLEU = 18.06 55.4/26.3/14.3/7.9 (BP = 0.895 ratio = 0.900 hyp_len = 69370 ref_len = 77050)\n",
      "2022-04-03 13:11:36 | INFO | ml-hw5 | saved epoch checkpoint: /home/user/homework/ML/hw5/checkpoints/transformer_zh-en1/checkpoint11.pt\n",
      "2022-04-03 13:11:37 | INFO | ml-hw5 | end of epoch 11\n",
      "2022-04-03 13:11:37 | INFO | fairseq.data.iterators | grouped total_num_itrs = 800\n",
      "2022-04-03 13:16:02 | INFO | ml-hw5 | training loss: 2.6981                 \n",
      "2022-04-03 13:16:02 | INFO | ml-hw5 | begin validation\n",
      "2022-04-03 13:16:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2022-04-03 13:16:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2022-04-03 13:16:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
      "2022-04-03 13:16:27 | INFO | ml-hw5 | example source: 成為領導者是我的抱負 , 我想問 , 在沒有影響力時 , 你要如何領導 ?\n",
      "2022-04-03 13:16:27 | INFO | ml-hw5 | example hypothesis: being a leader is my aspiration , and i want to ask , how do you lead when you're not influenced ?\n",
      "2022-04-03 13:16:27 | INFO | ml-hw5 | example reference: i'm an aspiring leader , and i have a question about how you lead when you have no influence .\n",
      "2022-04-03 13:16:27 | INFO | ml-hw5 | validation loss:\t2.6759\n",
      "2022-04-03 13:16:27 | INFO | ml-hw5 | BLEU = 19.18 54.0/25.8/14.2/8.1 (BP = 0.960 ratio = 0.960 hyp_len = 73992 ref_len = 77050)\n",
      "2022-04-03 13:16:28 | INFO | ml-hw5 | saved epoch checkpoint: /home/user/homework/ML/hw5/checkpoints/transformer_zh-en1/checkpoint12.pt\n",
      "2022-04-03 13:16:28 | INFO | ml-hw5 | end of epoch 12\n",
      "2022-04-03 13:16:29 | INFO | fairseq.data.iterators | grouped total_num_itrs = 800\n",
      "2022-04-03 13:20:53 | INFO | ml-hw5 | training loss: 2.6476                 \n",
      "2022-04-03 13:20:53 | INFO | ml-hw5 | begin validation\n",
      "2022-04-03 13:21:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2022-04-03 13:21:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2022-04-03 13:21:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
      "2022-04-03 13:21:16 | INFO | ml-hw5 | example source: 這樣 , 英國國教的牧師就可以教訓無神論者 , 說他們的言論有多麼冒犯人 ;\n",
      "2022-04-03 13:21:16 | INFO | ml-hw5 | example hypothesis: so the britain's priests can train atheists no matter how offensive they say .\n",
      "2022-04-03 13:21:16 | INFO | ml-hw5 | example reference: so anglican ministers could lecture atheists on the offensiveness of their discourse .\n",
      "2022-04-03 13:21:16 | INFO | ml-hw5 | validation loss:\t2.6539\n",
      "2022-04-03 13:21:16 | INFO | ml-hw5 | BLEU = 19.35 56.6/27.5/15.2/8.7 (BP = 0.907 ratio = 0.911 hyp_len = 70229 ref_len = 77050)\n",
      "2022-04-03 13:21:17 | INFO | ml-hw5 | saved epoch checkpoint: /home/user/homework/ML/hw5/checkpoints/transformer_zh-en1/checkpoint13.pt\n",
      "2022-04-03 13:21:17 | INFO | ml-hw5 | end of epoch 13\n",
      "2022-04-03 13:21:18 | INFO | fairseq.data.iterators | grouped total_num_itrs = 800\n",
      "2022-04-03 13:25:42 | INFO | ml-hw5 | training loss: 2.6038                 \n",
      "2022-04-03 13:25:42 | INFO | ml-hw5 | begin validation\n",
      "2022-04-03 13:26:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2022-04-03 13:26:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2022-04-03 13:26:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
      "2022-04-03 13:26:05 | INFO | ml-hw5 | example source: 所以 , 我們說 , 好 , 咱們來研究看看這是如何發生的 , 先看科學 。\n",
      "2022-04-03 13:26:05 | INFO | ml-hw5 | example hypothesis: so we said , okay , let's look at how this is happening , and look at science first .\n",
      "2022-04-03 13:26:05 | INFO | ml-hw5 | example reference: so we said , ok , let's figure out how does this really happen , first in science .\n",
      "2022-04-03 13:26:05 | INFO | ml-hw5 | validation loss:\t2.6347\n",
      "2022-04-03 13:26:05 | INFO | ml-hw5 | BLEU = 19.60 56.4/27.6/15.3/8.7 (BP = 0.919 ratio = 0.922 hyp_len = 71015 ref_len = 77050)\n",
      "2022-04-03 13:26:05 | INFO | ml-hw5 | saved epoch checkpoint: /home/user/homework/ML/hw5/checkpoints/transformer_zh-en1/checkpoint14.pt\n",
      "2022-04-03 13:26:06 | INFO | ml-hw5 | end of epoch 14\n",
      "2022-04-03 13:26:07 | INFO | fairseq.data.iterators | grouped total_num_itrs = 800\n",
      "2022-04-03 13:30:31 | INFO | ml-hw5 | training loss: 2.5682                 \n",
      "2022-04-03 13:30:31 | INFO | ml-hw5 | begin validation\n",
      "2022-04-03 13:30:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2022-04-03 13:30:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2022-04-03 13:30:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
      "2022-04-03 13:30:56 | INFO | ml-hw5 | example source: 然而此時此刻我們滅絕這些病症的能力也已經達到了超乎想像的高峰\n",
      "2022-04-03 13:30:56 | INFO | ml-hw5 | example hypothesis: but at this moment , our ability to extinct those symptoms has reached a peak of imagination .\n",
      "2022-04-03 13:30:56 | INFO | ml-hw5 | example reference: and yet we also live at the moment when our ability to eliminate those conditions has reached a height we never imagined before .\n",
      "2022-04-03 13:30:56 | INFO | ml-hw5 | validation loss:\t2.6151\n",
      "2022-04-03 13:30:56 | INFO | ml-hw5 | BLEU = 19.92 55.2/27.0/15.0/8.6 (BP = 0.950 ratio = 0.951 hyp_len = 73301 ref_len = 77050)\n",
      "2022-04-03 13:30:56 | INFO | ml-hw5 | saved epoch checkpoint: /home/user/homework/ML/hw5/checkpoints/transformer_zh-en1/checkpoint15.pt\n",
      "2022-04-03 13:30:57 | INFO | ml-hw5 | end of epoch 15\n",
      "2022-04-03 13:30:58 | INFO | fairseq.data.iterators | grouped total_num_itrs = 800\n",
      "2022-04-03 13:35:23 | INFO | ml-hw5 | training loss: 2.5390                 \n",
      "2022-04-03 13:35:23 | INFO | ml-hw5 | begin validation\n",
      "2022-04-03 13:35:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2022-04-03 13:35:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2022-04-03 13:35:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
      "2022-04-03 13:35:46 | INFO | ml-hw5 | example source: 是因為勤奮的工作 。 是因為我們發現了有關恐怖活動的情報並且以不同的方式禁止 , 通過執法 , 通過和其他國家的合作 , 而且有時候通過軍事活動 。\n",
      "2022-04-03 13:35:46 | INFO | ml-hw5 | example hypothesis: it's because of hard work , because we've discovered the intelligence on terror activity and ban it in a different way , through law enforcement , through collaboration with other countries , sometimes through military campaigns .\n",
      "2022-04-03 13:35:46 | INFO | ml-hw5 | example reference: that's hard work . that's us finding intelligence on terrorist activities and interdicting them through one way or another , through law enforcement , through cooperative activities with other countries and sometimes through military action .\n",
      "2022-04-03 13:35:46 | INFO | ml-hw5 | validation loss:\t2.5978\n",
      "2022-04-03 13:35:46 | INFO | ml-hw5 | BLEU = 20.10 57.5/28.7/16.2/9.4 (BP = 0.898 ratio = 0.903 hyp_len = 69549 ref_len = 77050)\n",
      "2022-04-03 13:35:47 | INFO | ml-hw5 | saved epoch checkpoint: /home/user/homework/ML/hw5/checkpoints/transformer_zh-en1/checkpoint16.pt\n",
      "2022-04-03 13:35:47 | INFO | ml-hw5 | end of epoch 16\n",
      "2022-04-03 13:35:48 | INFO | fairseq.data.iterators | grouped total_num_itrs = 800\n",
      "2022-04-03 13:40:13 | INFO | ml-hw5 | training loss: 2.5092                 \n",
      "2022-04-03 13:40:13 | INFO | ml-hw5 | begin validation\n",
      "2022-04-03 13:40:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2022-04-03 13:40:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2022-04-03 13:40:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
      "2022-04-03 13:40:36 | INFO | ml-hw5 | example source: 這是過去40年來女性不斷倡導的結果\n",
      "2022-04-03 13:40:36 | INFO | ml-hw5 | example hypothesis: this is the result of women over the last 40 years .\n",
      "2022-04-03 13:40:36 | INFO | ml-hw5 | example reference: and that is the 40 years that women have advocated .\n",
      "2022-04-03 13:40:36 | INFO | ml-hw5 | validation loss:\t2.6021\n",
      "2022-04-03 13:40:36 | INFO | ml-hw5 | BLEU = 19.66 57.6/28.6/16.1/9.3 (BP = 0.884 ratio = 0.890 hyp_len = 68560 ref_len = 77050)\n",
      "2022-04-03 13:40:37 | INFO | ml-hw5 | saved epoch checkpoint: /home/user/homework/ML/hw5/checkpoints/transformer_zh-en1/checkpoint17.pt\n",
      "2022-04-03 13:40:37 | INFO | ml-hw5 | end of epoch 17\n",
      "2022-04-03 13:40:37 | INFO | fairseq.data.iterators | grouped total_num_itrs = 800\n",
      "2022-04-03 13:45:01 | INFO | ml-hw5 | training loss: 2.4850                 \n",
      "2022-04-03 13:45:01 | INFO | ml-hw5 | begin validation\n",
      "2022-04-03 13:45:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2022-04-03 13:45:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2022-04-03 13:45:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
      "2022-04-03 13:45:24 | INFO | ml-hw5 | example source: 所有人都安全了 。\n",
      "2022-04-03 13:45:24 | INFO | ml-hw5 | example hypothesis: everyone is safe .\n",
      "2022-04-03 13:45:24 | INFO | ml-hw5 | example reference: and no one got killed .\n",
      "2022-04-03 13:45:24 | INFO | ml-hw5 | validation loss:\t2.5900\n",
      "2022-04-03 13:45:24 | INFO | ml-hw5 | BLEU = 20.15 57.8/28.9/16.3/9.4 (BP = 0.896 ratio = 0.901 hyp_len = 69413 ref_len = 77050)\n",
      "2022-04-03 13:45:25 | INFO | ml-hw5 | saved epoch checkpoint: /home/user/homework/ML/hw5/checkpoints/transformer_zh-en1/checkpoint18.pt\n",
      "2022-04-03 13:45:25 | INFO | ml-hw5 | end of epoch 18\n",
      "2022-04-03 13:45:26 | INFO | fairseq.data.iterators | grouped total_num_itrs = 800\n",
      "2022-04-03 13:49:51 | INFO | ml-hw5 | training loss: 2.4615                 \n",
      "2022-04-03 13:49:51 | INFO | ml-hw5 | begin validation\n",
      "2022-04-03 13:50:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2022-04-03 13:50:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2022-04-03 13:50:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
      "2022-04-03 13:50:14 | INFO | ml-hw5 | example source: 其他人則是靠著很不適合的獨木舟 , 孤注一擲試圖前往西班牙 。\n",
      "2022-04-03 13:50:14 | INFO | ml-hw5 | example hypothesis: others use very uncomfortable canoes , lonely attempts to go to spain .\n",
      "2022-04-03 13:50:14 | INFO | ml-hw5 | example reference: others end up on inadequate wooden canoes in desperate attempts to reach spain .\n",
      "2022-04-03 13:50:14 | INFO | ml-hw5 | validation loss:\t2.5816\n",
      "2022-04-03 13:50:14 | INFO | ml-hw5 | BLEU = 20.41 57.1/28.6/16.2/9.4 (BP = 0.913 ratio = 0.917 hyp_len = 70656 ref_len = 77050)\n",
      "2022-04-03 13:50:15 | INFO | ml-hw5 | saved epoch checkpoint: /home/user/homework/ML/hw5/checkpoints/transformer_zh-en1/checkpoint19.pt\n",
      "2022-04-03 13:50:16 | INFO | ml-hw5 | end of epoch 19\n",
      "2022-04-03 13:50:16 | INFO | fairseq.data.iterators | grouped total_num_itrs = 800\n",
      "2022-04-03 13:54:42 | INFO | ml-hw5 | training loss: 2.4408                 \n",
      "2022-04-03 13:54:42 | INFO | ml-hw5 | begin validation\n",
      "2022-04-03 13:55:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2022-04-03 13:55:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2022-04-03 13:55:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
      "2022-04-03 13:55:05 | INFO | ml-hw5 | example source: 對了 , 如果你還沒有注意到 , 我是黑人 , 謝謝 。 如果你像我一樣 , 生長在種族隔離的城市 , 例如芝加哥 , 你自然而然就相信膚色和種族永遠是分不開的 。\n",
      "2022-04-03 13:55:05 | INFO | ml-hw5 | example hypothesis: by the way , if you haven't yet noticed , i'm black , thank you . if you grow up in a segregated city like mine , like chicago , you're naturally believing that skin color and race are never separated .\n",
      "2022-04-03 13:55:05 | INFO | ml-hw5 | example reference: now , if you haven't noticed , i am black , thank you and when you grow up in a segregated city as i have , like chicago , you're conditioned to believe that color and race can never be separate .\n",
      "2022-04-03 13:55:05 | INFO | ml-hw5 | validation loss:\t2.5752\n",
      "2022-04-03 13:55:05 | INFO | ml-hw5 | BLEU = 20.75 56.9/28.6/16.2/9.4 (BP = 0.930 ratio = 0.932 hyp_len = 71806 ref_len = 77050)\n",
      "2022-04-03 13:55:06 | INFO | ml-hw5 | saved epoch checkpoint: /home/user/homework/ML/hw5/checkpoints/transformer_zh-en1/checkpoint20.pt\n",
      "2022-04-03 13:55:07 | INFO | ml-hw5 | end of epoch 20\n",
      "2022-04-03 13:55:07 | INFO | fairseq.data.iterators | grouped total_num_itrs = 800\n",
      "2022-04-03 13:59:31 | INFO | ml-hw5 | training loss: 2.4209                 \n",
      "2022-04-03 13:59:31 | INFO | ml-hw5 | begin validation\n",
      "2022-04-03 13:59:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2022-04-03 13:59:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2022-04-03 13:59:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
      "2022-04-03 13:59:56 | INFO | ml-hw5 | example source: 如果你是使用蘋果的keynote , 就有更好的版本能用\n",
      "2022-04-03 13:59:56 | INFO | ml-hw5 | example hypothesis: if you're using an apple's knote , there's a better version of it .\n",
      "2022-04-03 13:59:56 | INFO | ml-hw5 | example reference: if you use apple's keynote , it's got an even better version .\n",
      "2022-04-03 13:59:56 | INFO | ml-hw5 | validation loss:\t2.5723\n",
      "2022-04-03 13:59:56 | INFO | ml-hw5 | BLEU = 20.81 56.4/28.2/15.9/9.2 (BP = 0.947 ratio = 0.948 hyp_len = 73068 ref_len = 77050)\n",
      "2022-04-03 13:59:56 | INFO | ml-hw5 | saved epoch checkpoint: /home/user/homework/ML/hw5/checkpoints/transformer_zh-en1/checkpoint21.pt\n",
      "2022-04-03 13:59:57 | INFO | ml-hw5 | end of epoch 21\n",
      "2022-04-03 13:59:57 | INFO | fairseq.data.iterators | grouped total_num_itrs = 800\n",
      "2022-04-03 14:04:22 | INFO | ml-hw5 | training loss: 2.4037                 \n",
      "2022-04-03 14:04:22 | INFO | ml-hw5 | begin validation\n",
      "2022-04-03 14:04:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2022-04-03 14:04:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2022-04-03 14:04:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
      "2022-04-03 14:04:46 | INFO | ml-hw5 | example source: 這是1970年中國的收入分配\n",
      "2022-04-03 14:04:46 | INFO | ml-hw5 | example hypothesis: this is the income distribution of china in 1970 .\n",
      "2022-04-03 14:04:46 | INFO | ml-hw5 | example reference: this is the income distribution of china , 1970 .\n",
      "2022-04-03 14:04:46 | INFO | ml-hw5 | validation loss:\t2.5730\n",
      "2022-04-03 14:04:46 | INFO | ml-hw5 | BLEU = 20.62 57.4/28.9/16.3/9.6 (BP = 0.914 ratio = 0.918 hyp_len = 70708 ref_len = 77050)\n",
      "2022-04-03 14:04:46 | INFO | ml-hw5 | saved epoch checkpoint: /home/user/homework/ML/hw5/checkpoints/transformer_zh-en1/checkpoint22.pt\n",
      "2022-04-03 14:04:46 | INFO | ml-hw5 | end of epoch 22\n",
      "2022-04-03 14:04:47 | INFO | fairseq.data.iterators | grouped total_num_itrs = 800\n",
      "2022-04-03 14:09:11 | INFO | ml-hw5 | training loss: 2.3876                 \n",
      "2022-04-03 14:09:11 | INFO | ml-hw5 | begin validation\n",
      "2022-04-03 14:09:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2022-04-03 14:09:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2022-04-03 14:09:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
      "2022-04-03 14:09:35 | INFO | ml-hw5 | example source: 他是律師兼作家 , 笑的時候眼睛閃閃發光 , 我親他的時候 , 他緊緊閉上雙眼 , 在那晚的某一刻 , 我們的第零次約會\n",
      "2022-04-03 14:09:35 | INFO | ml-hw5 | example hypothesis: he was a lawyer and a writer , and he was laughing , and my eyes were flashing , and when i was kissing him , he closed his eyes closed , and at some point , our zero date .\n",
      "2022-04-03 14:09:35 | INFO | ml-hw5 | example reference: he was a lawyer and a writer , and his eyes twinkled when he laughed and they squeezed tight when i kissed him and at some point in the evening , our zero date became a first date .\n",
      "2022-04-03 14:09:35 | INFO | ml-hw5 | validation loss:\t2.5651\n",
      "2022-04-03 14:09:35 | INFO | ml-hw5 | BLEU = 20.78 57.3/28.8/16.4/9.6 (BP = 0.920 ratio = 0.923 hyp_len = 71110 ref_len = 77050)\n",
      "2022-04-03 14:09:36 | INFO | ml-hw5 | saved epoch checkpoint: /home/user/homework/ML/hw5/checkpoints/transformer_zh-en1/checkpoint23.pt\n",
      "2022-04-03 14:09:36 | INFO | ml-hw5 | end of epoch 23\n",
      "2022-04-03 14:09:36 | INFO | fairseq.data.iterators | grouped total_num_itrs = 800\n",
      "2022-04-03 14:14:01 | INFO | ml-hw5 | training loss: 2.3722                 \n",
      "2022-04-03 14:14:01 | INFO | ml-hw5 | begin validation\n",
      "2022-04-03 14:14:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2022-04-03 14:14:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2022-04-03 14:14:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
      "2022-04-03 14:14:25 | INFO | ml-hw5 | example source: 用特斯拉 , 因你要有永續能源 , 所以造出這麽勁爆的車子來實現你的目標 。\n",
      "2022-04-03 14:14:25 | INFO | ml-hw5 | example hypothesis: using tesla , because you have sustainable energy , you have to build this explosive car for your goal .\n",
      "2022-04-03 14:14:25 | INFO | ml-hw5 | example reference: with tesla , you want to have sustainable energy , so you made these super sexy , exciting cars to do it .\n",
      "2022-04-03 14:14:25 | INFO | ml-hw5 | validation loss:\t2.5679\n",
      "2022-04-03 14:14:25 | INFO | ml-hw5 | BLEU = 20.62 57.2/28.7/16.2/9.3 (BP = 0.925 ratio = 0.928 hyp_len = 71506 ref_len = 77050)\n",
      "2022-04-03 14:14:26 | INFO | ml-hw5 | saved epoch checkpoint: /home/user/homework/ML/hw5/checkpoints/transformer_zh-en1/checkpoint24.pt\n",
      "2022-04-03 14:14:26 | INFO | ml-hw5 | end of epoch 24\n",
      "2022-04-03 14:14:26 | INFO | fairseq.data.iterators | grouped total_num_itrs = 800\n",
      "2022-04-03 14:18:53 | INFO | ml-hw5 | training loss: 2.3592                 \n",
      "2022-04-03 14:18:53 | INFO | ml-hw5 | begin validation\n",
      "2022-04-03 14:19:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2022-04-03 14:19:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2022-04-03 14:19:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
      "2022-04-03 14:19:16 | INFO | ml-hw5 | example source: 你要做的 , 就是把你的問題和以前別人所遇到的問題做比對 , 再利用他們已經想出的辦法來解決 。\n",
      "2022-04-03 14:19:16 | INFO | ml-hw5 | example hypothesis: what you have to do is you compare your problems with the problems that people have faced before , and then use them to figure out how to do that .\n",
      "2022-04-03 14:19:16 | INFO | ml-hw5 | example reference: because what you can do is take your problem , and turn it into a problem that someone else has solved , and use their solutions .\n",
      "2022-04-03 14:19:16 | INFO | ml-hw5 | validation loss:\t2.5631\n",
      "2022-04-03 14:19:16 | INFO | ml-hw5 | BLEU = 20.75 56.9/28.5/16.2/9.5 (BP = 0.930 ratio = 0.933 hyp_len = 71851 ref_len = 77050)\n",
      "2022-04-03 14:19:17 | INFO | ml-hw5 | saved epoch checkpoint: /home/user/homework/ML/hw5/checkpoints/transformer_zh-en1/checkpoint25.pt\n",
      "2022-04-03 14:19:17 | INFO | ml-hw5 | end of epoch 25\n",
      "2022-04-03 14:19:17 | INFO | fairseq.data.iterators | grouped total_num_itrs = 800\n",
      "2022-04-03 14:23:41 | INFO | ml-hw5 | training loss: 2.3464                 \n",
      "2022-04-03 14:23:41 | INFO | ml-hw5 | begin validation\n",
      "2022-04-03 14:24:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2022-04-03 14:24:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2022-04-03 14:24:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
      "2022-04-03 14:24:05 | INFO | ml-hw5 | example source: 在同樣的狀況下他們該怎麼做 ?\n",
      "2022-04-03 14:24:05 | INFO | ml-hw5 | example hypothesis: what do they do in the same situation ?\n",
      "2022-04-03 14:24:05 | INFO | ml-hw5 | example reference: what would they do under the same conditions ?\n",
      "2022-04-03 14:24:05 | INFO | ml-hw5 | validation loss:\t2.5648\n",
      "2022-04-03 14:24:05 | INFO | ml-hw5 | BLEU = 20.79 58.0/29.3/16.6/9.6 (BP = 0.912 ratio = 0.915 hyp_len = 70530 ref_len = 77050)\n",
      "2022-04-03 14:24:06 | INFO | ml-hw5 | saved epoch checkpoint: /home/user/homework/ML/hw5/checkpoints/transformer_zh-en1/checkpoint26.pt\n",
      "2022-04-03 14:24:06 | INFO | ml-hw5 | end of epoch 26\n",
      "2022-04-03 14:24:06 | INFO | fairseq.data.iterators | grouped total_num_itrs = 800\n",
      "2022-04-03 14:28:31 | INFO | ml-hw5 | training loss: 2.3322                 \n",
      "2022-04-03 14:28:31 | INFO | ml-hw5 | begin validation\n",
      "2022-04-03 14:28:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2022-04-03 14:28:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2022-04-03 14:28:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
      "2022-04-03 14:28:54 | INFO | ml-hw5 | example source: 這帶給我想到第三個假設而這也許是問題最大的假設: \" 永遠不要對選擇說不 \" 。\n",
      "2022-04-03 14:28:54 | INFO | ml-hw5 | example hypothesis: and this brings me to my third assumption , which is perhaps the biggest assumption of the problem: \" never say no to the choices . \"\n",
      "2022-04-03 14:28:54 | INFO | ml-hw5 | example reference: this brings me to the third , and perhaps most problematic , assumption: \" you must never say no to choice . \"\n",
      "2022-04-03 14:28:54 | INFO | ml-hw5 | validation loss:\t2.5584\n",
      "2022-04-03 14:28:54 | INFO | ml-hw5 | BLEU = 20.98 57.9/29.3/16.8/9.9 (BP = 0.911 ratio = 0.915 hyp_len = 70502 ref_len = 77050)\n",
      "2022-04-03 14:28:55 | INFO | ml-hw5 | saved epoch checkpoint: /home/user/homework/ML/hw5/checkpoints/transformer_zh-en1/checkpoint27.pt\n",
      "2022-04-03 14:28:56 | INFO | ml-hw5 | end of epoch 27\n",
      "2022-04-03 14:28:56 | INFO | fairseq.data.iterators | grouped total_num_itrs = 800\n",
      "2022-04-03 14:33:20 | INFO | ml-hw5 | training loss: 2.3208                 \n",
      "2022-04-03 14:33:20 | INFO | ml-hw5 | begin validation\n",
      "2022-04-03 14:33:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2022-04-03 14:33:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2022-04-03 14:33:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
      "2022-04-03 14:33:44 | INFO | ml-hw5 | example source: 沒有錢乘車 , 他們通常都會坐在卡車頂上 , 在這裡則是坐在橫越南蘇丹的火車頂上 。\n",
      "2022-04-03 14:33:44 | INFO | ml-hw5 | example hypothesis: there are no money rides , and they're usually sitting on the top of a truck , and here they are sitting on top of a train across south sudan .\n",
      "2022-04-03 14:33:44 | INFO | ml-hw5 | example reference: with no money for rides , they often made the mzungu ride on the roof of the trucks , or in this case , on the top of the train going across south sudan .\n",
      "2022-04-03 14:33:44 | INFO | ml-hw5 | validation loss:\t2.5602\n",
      "2022-04-03 14:33:44 | INFO | ml-hw5 | BLEU = 20.89 58.2/29.5/16.8/9.9 (BP = 0.902 ratio = 0.907 hyp_len = 69864 ref_len = 77050)\n",
      "2022-04-03 14:33:44 | INFO | ml-hw5 | saved epoch checkpoint: /home/user/homework/ML/hw5/checkpoints/transformer_zh-en1/checkpoint28.pt\n",
      "2022-04-03 14:33:45 | INFO | ml-hw5 | end of epoch 28\n",
      "2022-04-03 14:33:45 | INFO | fairseq.data.iterators | grouped total_num_itrs = 800\n",
      "2022-04-03 14:38:11 | INFO | ml-hw5 | training loss: 2.3100                 \n",
      "2022-04-03 14:38:11 | INFO | ml-hw5 | begin validation\n",
      "2022-04-03 14:38:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2022-04-03 14:38:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2022-04-03 14:38:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
      "2022-04-03 14:38:35 | INFO | ml-hw5 | example source: 我可以把鏡頭向右旋轉一點 , 你就會失焦 , 而背景的人會凸顯出來 。\n",
      "2022-04-03 14:38:35 | INFO | ml-hw5 | example hypothesis: i can rotate the camera to the right , you're going to lose your focus , and the people in the background are going to come out .\n",
      "2022-04-03 14:38:35 | INFO | ml-hw5 | example reference: i could move the lens a little to the right , and you would go back and the folks in the background would come out .\n",
      "2022-04-03 14:38:35 | INFO | ml-hw5 | validation loss:\t2.5597\n",
      "2022-04-03 14:38:35 | INFO | ml-hw5 | BLEU = 20.57 57.8/29.2/16.7/9.8 (BP = 0.896 ratio = 0.901 hyp_len = 69441 ref_len = 77050)\n",
      "2022-04-03 14:38:36 | INFO | ml-hw5 | saved epoch checkpoint: /home/user/homework/ML/hw5/checkpoints/transformer_zh-en1/checkpoint29.pt\n",
      "2022-04-03 14:38:36 | INFO | ml-hw5 | end of epoch 29\n",
      "2022-04-03 14:38:36 | INFO | fairseq.data.iterators | grouped total_num_itrs = 800\n",
      "2022-04-03 14:43:00 | INFO | ml-hw5 | training loss: 2.2981                 \n",
      "2022-04-03 14:43:00 | INFO | ml-hw5 | begin validation\n",
      "2022-04-03 14:43:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2022-04-03 14:43:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2022-04-03 14:43:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
      "2022-04-03 14:43:24 | INFO | ml-hw5 | example source: 身為白人女性 , 我們得要做更多 , 因為種族主義、性別主義 , 和恐同性戀症 , 是影響我們所有人的議題 。\n",
      "2022-04-03 14:43:24 | INFO | ml-hw5 | example hypothesis: as white women , we need to do more because racism , genderism and terrorism are the issues that affect all of us .\n",
      "2022-04-03 14:43:24 | INFO | ml-hw5 | example reference: and as white women , we have to do more , because racism and sexism and homophobia , these are issues that affect all of us .\n",
      "2022-04-03 14:43:24 | INFO | ml-hw5 | validation loss:\t2.5599\n",
      "2022-04-03 14:43:24 | INFO | ml-hw5 | BLEU = 21.10 56.9/28.6/16.4/9.6 (BP = 0.938 ratio = 0.940 hyp_len = 72409 ref_len = 77050)\n",
      "2022-04-03 14:43:25 | INFO | ml-hw5 | saved epoch checkpoint: /home/user/homework/ML/hw5/checkpoints/transformer_zh-en1/checkpoint30.pt\n",
      "2022-04-03 14:43:26 | INFO | ml-hw5 | end of epoch 30\n",
      "2022-04-03 14:43:26 | INFO | fairseq.data.iterators | grouped total_num_itrs = 800\n",
      "2022-04-03 14:47:49 | INFO | ml-hw5 | training loss: 2.2888                 \n",
      "2022-04-03 14:47:49 | INFO | ml-hw5 | begin validation\n",
      "2022-04-03 14:48:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2022-04-03 14:48:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2022-04-03 14:48:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
      "2022-04-03 14:48:13 | INFO | ml-hw5 | example source: 他們見到一些神奇的事物 ,\n",
      "2022-04-03 14:48:13 | INFO | ml-hw5 | example hypothesis: they see some magic things .\n",
      "2022-04-03 14:48:13 | INFO | ml-hw5 | example reference: they were seeing something magical .\n",
      "2022-04-03 14:48:13 | INFO | ml-hw5 | validation loss:\t2.5629\n",
      "2022-04-03 14:48:13 | INFO | ml-hw5 | BLEU = 20.87 57.6/29.0/16.6/9.7 (BP = 0.917 ratio = 0.920 hyp_len = 70901 ref_len = 77050)\n",
      "2022-04-03 14:48:14 | INFO | ml-hw5 | saved epoch checkpoint: /home/user/homework/ML/hw5/checkpoints/transformer_zh-en1/checkpoint31.pt\n",
      "2022-04-03 14:48:14 | INFO | ml-hw5 | end of epoch 31\n",
      "2022-04-03 14:48:15 | INFO | fairseq.data.iterators | grouped total_num_itrs = 800\n",
      "2022-04-03 14:52:38 | INFO | ml-hw5 | training loss: 2.2797                 \n",
      "2022-04-03 14:52:38 | INFO | ml-hw5 | begin validation\n",
      "2022-04-03 14:53:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2022-04-03 14:53:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2022-04-03 14:53:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
      "2022-04-03 14:53:02 | INFO | ml-hw5 | example source: 我覺得沒人在乎我 , 鋃鐺入獄讓我滿腹怨恨 。\n",
      "2022-04-03 14:53:02 | INFO | ml-hw5 | example hypothesis: i don't think anybody cares about me , and i'm getting to prison in nigeria .\n",
      "2022-04-03 14:53:02 | INFO | ml-hw5 | example reference: i felt like nobody cared , and i reacted with hostility to my confinement .\n",
      "2022-04-03 14:53:02 | INFO | ml-hw5 | validation loss:\t2.5643\n",
      "2022-04-03 14:53:02 | INFO | ml-hw5 | BLEU = 20.84 57.4/28.9/16.4/9.6 (BP = 0.923 ratio = 0.926 hyp_len = 71335 ref_len = 77050)\n",
      "2022-04-03 14:53:03 | INFO | ml-hw5 | saved epoch checkpoint: /home/user/homework/ML/hw5/checkpoints/transformer_zh-en1/checkpoint32.pt\n",
      "2022-04-03 14:53:03 | INFO | ml-hw5 | end of epoch 32\n",
      "2022-04-03 14:53:03 | INFO | fairseq.data.iterators | grouped total_num_itrs = 800\n",
      "2022-04-03 14:57:27 | INFO | ml-hw5 | training loss: 2.2703                 \n",
      "2022-04-03 14:57:27 | INFO | ml-hw5 | begin validation\n",
      "2022-04-03 14:57:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2022-04-03 14:57:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2022-04-03 14:57:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
      "2022-04-03 14:57:50 | INFO | ml-hw5 | example source: 根據世界銀行的估計 , 每年賄賂的總額約為一兆美元 , 這讓原本就很糟的情況雪上加霜 。\n",
      "2022-04-03 14:57:50 | INFO | ml-hw5 | example hypothesis: according to the world bank estimates , the total bribe is about a trillion dollars per year , and that makes it worse onto the snow .\n",
      "2022-04-03 14:57:50 | INFO | ml-hw5 | example reference: according to world bank estimate , one trillion dollars is paid in bribes every year , worsening the condition of the already worse off .\n",
      "2022-04-03 14:57:50 | INFO | ml-hw5 | validation loss:\t2.5644\n",
      "2022-04-03 14:57:50 | INFO | ml-hw5 | BLEU = 21.01 57.8/29.3/16.7/9.9 (BP = 0.913 ratio = 0.916 hyp_len = 70599 ref_len = 77050)\n",
      "2022-04-03 14:57:51 | INFO | ml-hw5 | saved epoch checkpoint: /home/user/homework/ML/hw5/checkpoints/transformer_zh-en1/checkpoint33.pt\n",
      "2022-04-03 14:57:51 | INFO | ml-hw5 | end of epoch 33\n",
      "2022-04-03 14:57:51 | INFO | fairseq.data.iterators | grouped total_num_itrs = 800\n",
      "2022-04-03 15:02:17 | INFO | ml-hw5 | training loss: 2.2623                 \n",
      "2022-04-03 15:02:17 | INFO | ml-hw5 | begin validation\n",
      "2022-04-03 15:02:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2022-04-03 15:02:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2022-04-03 15:02:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
      "2022-04-03 15:02:40 | INFO | ml-hw5 | example source: 好 。 我是日本移民的第三代 , 我的祖父母來到美國 , 勇敢地踏進一個新奇的世界 , 尋找新的機會 。\n",
      "2022-04-03 15:02:40 | INFO | ml-hw5 | example hypothesis: ok . i'm the third generation of japanese immigrants , my grandparents came to the united states , bravely stepping into a world of novelties , looking for new opportunities .\n",
      "2022-04-03 15:02:40 | INFO | ml-hw5 | example reference: well — — i am the grandson of immigrants from japan who went to america , boldly going to a strange new world , seeking new opportunities .\n",
      "2022-04-03 15:02:40 | INFO | ml-hw5 | validation loss:\t2.5707\n",
      "2022-04-03 15:02:40 | INFO | ml-hw5 | BLEU = 21.02 57.7/29.3/16.7/9.8 (BP = 0.915 ratio = 0.918 hyp_len = 70749 ref_len = 77050)\n",
      "2022-04-03 15:02:41 | INFO | ml-hw5 | saved epoch checkpoint: /home/user/homework/ML/hw5/checkpoints/transformer_zh-en1/checkpoint34.pt\n",
      "2022-04-03 15:02:41 | INFO | ml-hw5 | end of epoch 34\n",
      "2022-04-03 15:02:42 | INFO | fairseq.data.iterators | grouped total_num_itrs = 800\n",
      "2022-04-03 15:07:06 | INFO | ml-hw5 | training loss: 2.2541                 \n",
      "2022-04-03 15:07:06 | INFO | ml-hw5 | begin validation\n",
      "2022-04-03 15:07:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2022-04-03 15:07:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2022-04-03 15:07:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
      "2022-04-03 15:07:30 | INFO | ml-hw5 | example source: 這有點像是獨白 , 在很多我做的錄音訪談裡都有獨白 。\n",
      "2022-04-03 15:07:30 | INFO | ml-hw5 | example hypothesis: it's kind of like monologues and monologues in many of my interviews .\n",
      "2022-04-03 15:07:30 | INFO | ml-hw5 | example reference: it's a kind of an aria , i would say , and in many tapes that i have .\n",
      "2022-04-03 15:07:30 | INFO | ml-hw5 | validation loss:\t2.5649\n",
      "2022-04-03 15:07:30 | INFO | ml-hw5 | BLEU = 21.24 57.2/28.9/16.5/9.7 (BP = 0.937 ratio = 0.938 hyp_len = 72310 ref_len = 77050)\n",
      "2022-04-03 15:07:31 | INFO | ml-hw5 | saved epoch checkpoint: /home/user/homework/ML/hw5/checkpoints/transformer_zh-en1/checkpoint35.pt\n",
      "2022-04-03 15:07:32 | INFO | ml-hw5 | end of epoch 35\n",
      "2022-04-03 15:07:32 | INFO | fairseq.data.iterators | grouped total_num_itrs = 800\n",
      "2022-04-03 15:11:56 | INFO | ml-hw5 | training loss: 2.2447                 \n",
      "2022-04-03 15:11:56 | INFO | ml-hw5 | begin validation\n",
      "2022-04-03 15:12:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2022-04-03 15:12:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2022-04-03 15:12:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
      "2022-04-03 15:12:20 | INFO | ml-hw5 | example source: 人們知道我很熱心 , 我是個快樂的人 。 」\n",
      "2022-04-03 15:12:20 | INFO | ml-hw5 | example hypothesis: people know that i'm passionate . i'm a happy person . \"\n",
      "2022-04-03 15:12:20 | INFO | ml-hw5 | example reference: people know now that i'm enthusiastic , that i'm a happy person . \"\n",
      "2022-04-03 15:12:20 | INFO | ml-hw5 | validation loss:\t2.5703\n",
      "2022-04-03 15:12:20 | INFO | ml-hw5 | BLEU = 21.13 58.0/29.5/16.8/9.9 (BP = 0.915 ratio = 0.919 hyp_len = 70791 ref_len = 77050)\n",
      "2022-04-03 15:12:21 | INFO | ml-hw5 | saved epoch checkpoint: /home/user/homework/ML/hw5/checkpoints/transformer_zh-en1/checkpoint36.pt\n",
      "2022-04-03 15:12:21 | INFO | ml-hw5 | end of epoch 36\n",
      "2022-04-03 15:12:21 | INFO | fairseq.data.iterators | grouped total_num_itrs = 800\n",
      "2022-04-03 15:16:46 | INFO | ml-hw5 | training loss: 2.2375                 \n",
      "2022-04-03 15:16:46 | INFO | ml-hw5 | begin validation\n",
      "2022-04-03 15:17:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2022-04-03 15:17:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2022-04-03 15:17:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
      "2022-04-03 15:17:10 | INFO | ml-hw5 | example source: 所以我並沒有辦法解決 。\n",
      "2022-04-03 15:17:10 | INFO | ml-hw5 | example hypothesis: so i didn't .\n",
      "2022-04-03 15:17:10 | INFO | ml-hw5 | example reference: so i couldn't handle it .\n",
      "2022-04-03 15:17:10 | INFO | ml-hw5 | validation loss:\t2.5671\n",
      "2022-04-03 15:17:10 | INFO | ml-hw5 | BLEU = 21.13 57.6/29.1/16.6/9.8 (BP = 0.924 ratio = 0.927 hyp_len = 71429 ref_len = 77050)\n",
      "2022-04-03 15:17:11 | INFO | ml-hw5 | saved epoch checkpoint: /home/user/homework/ML/hw5/checkpoints/transformer_zh-en1/checkpoint37.pt\n",
      "2022-04-03 15:17:11 | INFO | ml-hw5 | end of epoch 37\n",
      "2022-04-03 15:17:11 | INFO | fairseq.data.iterators | grouped total_num_itrs = 800\n",
      "2022-04-03 15:21:35 | INFO | ml-hw5 | training loss: 2.2302                 \n",
      "2022-04-03 15:21:35 | INFO | ml-hw5 | begin validation\n",
      "2022-04-03 15:21:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2022-04-03 15:21:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2022-04-03 15:21:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
      "2022-04-03 15:21:59 | INFO | ml-hw5 | example source: 但如果人人都是報導人的話真相便難以追蹤我們難以核實不同的線索不僅無法獲知真實意見更難以查明事實真相\n",
      "2022-04-03 15:21:59 | INFO | ml-hw5 | example hypothesis: but the truth is hard to track when everyone is covering the truth , and it's hard to track the fact that we can't just get the truth out there , and it's harder to check the truth .\n",
      "2022-04-03 15:21:59 | INFO | ml-hw5 | example reference: but if everyone is a reporter , nobody is , and different sources may disagree , not only opinions , but on the facts themselves .\n",
      "2022-04-03 15:21:59 | INFO | ml-hw5 | validation loss:\t2.5666\n",
      "2022-04-03 15:21:59 | INFO | ml-hw5 | BLEU = 21.36 57.7/29.3/16.9/10.0 (BP = 0.923 ratio = 0.926 hyp_len = 71336 ref_len = 77050)\n",
      "2022-04-03 15:22:00 | INFO | ml-hw5 | saved epoch checkpoint: /home/user/homework/ML/hw5/checkpoints/transformer_zh-en1/checkpoint38.pt\n",
      "2022-04-03 15:22:01 | INFO | ml-hw5 | end of epoch 38\n",
      "2022-04-03 15:22:01 | INFO | fairseq.data.iterators | grouped total_num_itrs = 800\n",
      "2022-04-03 15:26:26 | INFO | ml-hw5 | training loss: 2.2243                 \n",
      "2022-04-03 15:26:26 | INFO | ml-hw5 | begin validation\n",
      "2022-04-03 15:26:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2022-04-03 15:26:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2022-04-03 15:26:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
      "2022-04-03 15:26:50 | INFO | ml-hw5 | example source: 因此從二月開始 , 我們開始一項基本收入的演示 , 在未來18個月 , 實驗隨機挑選130個家庭 , 選自市內收入低於中位數的地區 , 每個月給他們五百美金 。\n",
      "2022-04-03 15:26:50 | INFO | ml-hw5 | example hypothesis: so starting in february , we started a basic income demo , and in the next 18 months , experimentation randomly picked 130 families , selecting regions that are below the middle , giving them 500 dollars per month .\n",
      "2022-04-03 15:26:50 | INFO | ml-hw5 | example reference: so starting in february , we launched a basic income demonstration , where for the next 18 months , as a pilot , 130 families , randomly selected , who live in zip codes at or below the median income of the city , are given 500 dollars a month .\n",
      "2022-04-03 15:26:50 | INFO | ml-hw5 | validation loss:\t2.5732\n",
      "2022-04-03 15:26:50 | INFO | ml-hw5 | BLEU = 21.29 57.5/29.2/16.8/9.9 (BP = 0.926 ratio = 0.929 hyp_len = 71581 ref_len = 77050)\n",
      "2022-04-03 15:26:51 | INFO | ml-hw5 | saved epoch checkpoint: /home/user/homework/ML/hw5/checkpoints/transformer_zh-en1/checkpoint39.pt\n",
      "2022-04-03 15:26:51 | INFO | ml-hw5 | end of epoch 39\n",
      "2022-04-03 15:26:51 | INFO | fairseq.data.iterators | grouped total_num_itrs = 800\n",
      "2022-04-03 15:31:17 | INFO | ml-hw5 | training loss: 2.2176                 \n",
      "2022-04-03 15:31:17 | INFO | ml-hw5 | begin validation\n",
      "2022-04-03 15:31:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2022-04-03 15:31:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2022-04-03 15:31:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
      "2022-04-03 15:31:41 | INFO | ml-hw5 | example source: 另外一件事 。\n",
      "2022-04-03 15:31:41 | INFO | ml-hw5 | example hypothesis: another thing .\n",
      "2022-04-03 15:31:41 | INFO | ml-hw5 | example reference: then another thing .\n",
      "2022-04-03 15:31:41 | INFO | ml-hw5 | validation loss:\t2.5827\n",
      "2022-04-03 15:31:41 | INFO | ml-hw5 | BLEU = 21.31 57.7/29.2/16.8/9.9 (BP = 0.925 ratio = 0.928 hyp_len = 71465 ref_len = 77050)\n",
      "2022-04-03 15:31:42 | INFO | ml-hw5 | saved epoch checkpoint: /home/user/homework/ML/hw5/checkpoints/transformer_zh-en1/checkpoint40.pt\n",
      "2022-04-03 15:31:42 | INFO | ml-hw5 | end of epoch 40\n"
     ]
    }
   ],
   "source": [
    "epoch_itr = load_data_iterator(task, \"train\", config.start_epoch, config.max_tokens, config.num_workers)\n",
    "try_load_checkpoint(model, optimizer, name=config.resume)\n",
    "while epoch_itr.next_epoch_idx <= config.max_epoch:\n",
    "    # train for one epoch\n",
    "    train_one_epoch(epoch_itr, model, task, criterion, optimizer, config.accum_steps)\n",
    "    stats = validate_and_save(model, task, criterion, optimizer, epoch=epoch_itr.epoch)\n",
    "    logger.info(\"end of epoch {}\".format(epoch_itr.epoch))    \n",
    "    epoch_itr = load_data_iterator(task, \"train\", epoch_itr.next_epoch_idx, config.max_tokens, config.num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KyjRwllxPjtf"
   },
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "N70Gc6smPi1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-03 15:31:43 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
      "Namespace(checkpoint_upper_bound=None, inputs=['./checkpoints/transformer_zh-en1'], num_epoch_checkpoints=5, num_update_checkpoints=None, output='./checkpoints/transformer_zh-en1/avg_last_5_checkpoint.pt')\n",
      "averaging checkpoints:  ['./checkpoints/transformer_zh-en1/checkpoint40.pt', './checkpoints/transformer_zh-en1/checkpoint39.pt', './checkpoints/transformer_zh-en1/checkpoint38.pt', './checkpoints/transformer_zh-en1/checkpoint37.pt', './checkpoints/transformer_zh-en1/checkpoint36.pt']\n",
      "Finished writing averaged checkpoint to ./checkpoints/transformer_zh-en1/avg_last_5_checkpoint.pt\n"
     ]
    }
   ],
   "source": [
    "# averaging a few checkpoints can have a similar effect to ensemble\n",
    "checkdir=config.savedir\n",
    "!python ./fairseq/scripts/average_checkpoints.py \\\n",
    "--inputs {checkdir} \\\n",
    "--num-epoch-checkpoints 5 \\\n",
    "--output {checkdir}/avg_last_5_checkpoint.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BAGMiun8PnZy"
   },
   "source": [
    "## Confirm model weights used to generate submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "tvRdivVUPnsU"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-03 15:31:44 | INFO | ml-hw5 | loaded checkpoint checkpoints/transformer_zh-en1/avg_last_5_checkpoint.pt: step=unknown loss=2.5827107429504395 bleu=21.31254113460424\n",
      "2022-04-03 15:31:44 | INFO | ml-hw5 | begin validation\n",
      "2022-04-03 15:32:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2022-04-03 15:32:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2022-04-03 15:32:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
      "2022-04-03 15:32:08 | INFO | ml-hw5 | example source: 這個是豐田的超輕型強力車型 , 408匹馬力很輕易就能在四秒內從0碼加速到60碼一加侖油仍然能跑32公里 。 等一下我再說這個\n",
      "2022-04-03 15:32:08 | INFO | ml-hw5 | example hypothesis: this is a toyota super lightweight vehicle , 408 horsepower , easily speeding up from zero in four seconds to 60 yards a gallon of oil still runs 32 kilometers .\n",
      "2022-04-03 15:32:08 | INFO | ml-hw5 | example reference: this muscle car from toyota: 408 horsepower in an ultralight that does zero to 60 in well under four seconds , and still gets 32 miles a gallon . i'll say more later about this .\n",
      "2022-04-03 15:32:08 | INFO | ml-hw5 | validation loss:\t2.5514\n",
      "2022-04-03 15:32:08 | INFO | ml-hw5 | BLEU = 21.61 58.1/29.7/17.1/10.2 (BP = 0.922 ratio = 0.925 hyp_len = 71297 ref_len = 77050)\n"
     ]
    }
   ],
   "source": [
    "# checkpoint_last.pt : latest epoch\n",
    "# checkpoint_best.pt : highest validation bleu\n",
    "# avg_last_5_checkpoint.pt:　the average of last 5 epochs\n",
    "try_load_checkpoint(model, name=\"avg_last_5_checkpoint.pt\")\n",
    "validate(model, task, criterion, log_to_wandb=False)\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ioAIflXpPsxt"
   },
   "source": [
    "## Generate Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "oYMxA8FlPtIq"
   },
   "outputs": [],
   "source": [
    "def generate_prediction(model, task, split=\"test\", outfile=\"./prediction.txt\"):    \n",
    "    task.load_dataset(split=split, epoch=1)\n",
    "    itr = load_data_iterator(task, split, 1, config.max_tokens, config.num_workers).next_epoch_itr(shuffle=False)\n",
    "    \n",
    "    idxs = []\n",
    "    hyps = []\n",
    "\n",
    "    model.eval()\n",
    "    progress = tqdm.tqdm(itr, desc=f\"prediction\")\n",
    "    with torch.no_grad():\n",
    "        for i, sample in enumerate(progress):\n",
    "            # validation loss\n",
    "            sample = utils.move_to_cuda(sample, device=device)\n",
    "\n",
    "            # do inference\n",
    "            s, h, r = inference_step(sample, model)\n",
    "            \n",
    "            hyps.extend(h)\n",
    "            idxs.extend(list(sample['id']))\n",
    "            \n",
    "    # sort based on the order before preprocess\n",
    "    hyps = [x for _,x in sorted(zip(idxs,hyps))]\n",
    "    \n",
    "    with open(outfile, \"w\") as f:\n",
    "        for h in hyps:\n",
    "            f.write(h+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "Le4RFWXxjmm0"
   },
   "outputs": [],
   "source": [
    "# generate_prediction(model, task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1z0cJE-wPzaU"
   },
   "source": [
    "# Back-translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5-7uPJ2CP0sm"
   },
   "source": [
    "## Train a backward translation model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ppGHjg2ZP3sV"
   },
   "source": [
    "1. Switch the source_lang and target_lang in **config** \n",
    "2. Change the savedir in **config** (eg. \"./checkpoints/transformer-back\")\n",
    "3. Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "waTGz29UP6WI"
   },
   "source": [
    "## Generate synthetic data with backward model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sIeTsPexP8FL"
   },
   "source": [
    "### Download monolingual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "i7N4QlsbP8fh"
   },
   "outputs": [],
   "source": [
    "mono_dataset_name = 'mono'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "396saD9-QBPY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ted_zh_corpus.deduped.gz is exist, skip downloading\n"
     ]
    }
   ],
   "source": [
    "mono_prefix = Path(data_dir).absolute() / mono_dataset_name\n",
    "mono_prefix.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "urls = (\n",
    "    \"https://github.com/yuhsinchan/ML2022-HW5Dataset/releases/download/v1.0.2/ted_zh_corpus.deduped.gz\",\n",
    ")\n",
    "file_names = (\n",
    "    'ted_zh_corpus.deduped.gz',\n",
    ")\n",
    "\n",
    "for u, f in zip(urls, file_names):\n",
    "    path = mono_prefix/f\n",
    "    if not path.exists():\n",
    "        !wget {u} -O {path}\n",
    "    else:\n",
    "        print(f'{f} is exist, skip downloading')\n",
    "    if path.suffix == \".tgz\":\n",
    "        !tar -xvf {path} -C {prefix}\n",
    "    elif path.suffix == \".zip\":\n",
    "        !unzip -o {path} -d {prefix}\n",
    "    elif path.suffix == \".gz\":\n",
    "        !gzip -fkd {path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JOVQRHzGQU4-"
   },
   "source": [
    "### TODO: clean corpus\n",
    "\n",
    "1. remove sentences that are too long or too short\n",
    "2. unify punctuation\n",
    "\n",
    "hint: you can use clean_s() defined above to do this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "eIYmxfUOQSov"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/user/homework/ML/hw5/DATA/rawdata/mono/ted_zh_corpus.deduped.clean.zh & en exists. skipping clean.\n"
     ]
    }
   ],
   "source": [
    "def clean_mono(mono_prefix, max_len=512, min_len=3):\n",
    "    l1 = 'zh'\n",
    "    l2 =  'en'\n",
    "    if Path(f'{mono_prefix}/ted_zh_corpus.deduped.clean.{l1}').exists() and Path(f'{mono_prefix}/ted_zh_corpus.deduped.clean.{l2}').exists():\n",
    "        print(f'{mono_prefix}/ted_zh_corpus.deduped.clean.{l1} & {l2} exists. skipping clean.')\n",
    "        return\n",
    "    with open(f'{mono_prefix}/ted_zh_corpus.deduped', 'r') as l1_in_f:\n",
    "        with open(f'{mono_prefix}/ted_zh_corpus.deduped.clean.{l1}', 'w') as l1_out_f:\n",
    "            with open(f'{mono_prefix}/ted_zh_corpus.deduped.clean.{l2}', 'w') as l2_out_f:\n",
    "                for s1 in tqdm.tqdm(l1_in_f):\n",
    "                    s1 = s1.strip()\n",
    "                    s1 = clean_s(s1, l1)\n",
    "                    s1_len = len_s(s1, l1)\n",
    "                    if min_len > 0: # remove short sentence\n",
    "                        if s1_len < min_len:\n",
    "                            continue\n",
    "                    if max_len > 0: # remove long sentence\n",
    "                        if s1_len > max_len:\n",
    "                            continue\n",
    "                    print(s1, file=l1_out_f)\n",
    "                    print('.', file=l2_out_f)\n",
    "\n",
    "clean_mono(mono_prefix=mono_prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jegH0bvMQVmR"
   },
   "source": [
    "### TODO: Subword Units\n",
    "\n",
    "Use the spm model of the backward model to tokenize the data into subword units\n",
    "\n",
    "hint: spm model is located at DATA/raw-data/\\[dataset\\]/spm\\[vocab_num\\].model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "vqgR4uUMQZGY"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "782527it [00:08, 86971.11it/s] \n",
      "782527it [00:09, 85939.87it/s] \n"
     ]
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "vocab_size = 8000\n",
    "spm_model = spm.SentencePieceProcessor(model_file=f'{prefix}/spm8000.model')\n",
    "for lang in ['zh', 'en']:\n",
    "    out_path = mono_prefix / f'mono.tok.{lang}'\n",
    "    with open(out_path, 'w') as out_f:\n",
    "        with open(mono_prefix / 'ted_zh_corpus.cleaned', 'r') as in_f:\n",
    "            for line in tqdm.tqdm(in_f):\n",
    "                line = line.strip()\n",
    "                tok = spm_model.encode(line, out_type=str)\n",
    "                print(' '.join(tok), file=out_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a65glBVXQZiE"
   },
   "source": [
    "### Binarize\n",
    "\n",
    "use fairseq to binarize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "b803qA5aQaEu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA/data-bin/mono exists, will not overwrite!\n"
     ]
    }
   ],
   "source": [
    "binpath = Path('./DATA/data-bin', mono_dataset_name)\n",
    "src_dict_file = './DATA/data-bin/ted2020/dict.en.txt'\n",
    "tgt_dict_file = src_dict_file\n",
    "monopref = str(mono_prefix / 'mono.tok') # whatever filepath you get after applying subword tokenization\n",
    "if binpath.exists():\n",
    "    print(binpath, \"exists, will not overwrite!\")\n",
    "else:\n",
    "    !python -m fairseq_cli.preprocess\\\n",
    "        --source-lang 'zh'\\\n",
    "        --target-lang 'en'\\\n",
    "        --trainpref {monopref}\\\n",
    "        --destdir {binpath}\\\n",
    "        --srcdict {src_dict_file}\\\n",
    "        --tgtdict {tgt_dict_file}\\\n",
    "        --workers 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "smA0JraEQdxz"
   },
   "source": [
    "### TODO: Generate synthetic data with backward model\n",
    "\n",
    "Add binarized monolingual data to the original data directory, and name it with \"split_name\"\n",
    "\n",
    "ex. ./DATA/data-bin/ted2020/\\[split_name\\].zh-en.\\[\"en\", \"zh\"\\].\\[\"bin\", \"idx\"\\]\n",
    "\n",
    "then you can use 'generate_prediction(model, task, split=\"split_name\")' to generate translation prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "jvaOVHeoQfkB"
   },
   "outputs": [],
   "source": [
    "# Add binarized monolingual data to the original data directory, and name it with \"split_name\"\n",
    "# ex. ./DATA/data-bin/ted2020/\\[split_name\\].zh-en.\\[\"en\", \"zh\"\\].\\[\"bin\", \"idx\"\\]\n",
    "!cp ./DATA/data-bin/mono/train.zh-en.zh.bin ./DATA/data-bin/ted2020/mono.zh-en.zh.bin\n",
    "!cp ./DATA/data-bin/mono/train.zh-en.zh.idx ./DATA/data-bin/ted2020/mono.zh-en.zh.idx\n",
    "!cp ./DATA/data-bin/mono/train.zh-en.en.bin ./DATA/data-bin/ted2020/mono.zh-en.en.bin\n",
    "!cp ./DATA/data-bin/mono/train.zh-en.en.idx ./DATA/data-bin/ted2020/mono.zh-en.en.idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "fFEkxPu-Qhlc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-03 15:32:29 | INFO | fairseq.data.data_utils | loaded 782,527 examples from: ./DATA/data-bin/ted2020/mono.zh-en.zh\n",
      "2022-04-03 15:32:29 | INFO | fairseq.data.data_utils | loaded 782,527 examples from: ./DATA/data-bin/ted2020/mono.zh-en.en\n",
      "2022-04-03 15:32:29 | INFO | fairseq.tasks.translation | ./DATA/data-bin/ted2020 mono zh-en 782527 examples\n",
      "prediction: 100%|██████████| 1715/1715 [41:58<00:00,  1.47s/it]\n"
     ]
    }
   ],
   "source": [
    "# hint: do prediction on split='mono' to create prediction_file\n",
    "generate_prediction(model, task ,split='mono' ,outfile=mono_prefix / 'mono_pred.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in the mid16th century , italians were obsessed with a kind of male singer vast , including notes that normal adult men couldn't achieve .\n",
      "but there's a very high price for this gift .\n",
      "to prevent them from turning their voices , these singers were castrated before puberty , to stop the hormonal changes , to keep their voices lower .\n",
      "it's called castrati , and their light , angellike voices are famous throughout europe , until this cruel process was banned in the 19th century .\n",
      "while blocking the growth of the vocal folds can produce an extraordinary range of sound areas , naturally developing voices are already possibilities .\n"
     ]
    }
   ],
   "source": [
    "!head {'./DATA/rawdata/mono/mono_pred.txt'} -n 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jn4XeawpQjLk"
   },
   "source": [
    "### TODO: Create new dataset\n",
    "\n",
    "1. Combine the prediction data with monolingual data\n",
    "2. Use the original spm model to tokenize data into Subword Units\n",
    "3. Binarize data with fairseq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "3R35JTaTQjkm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-03 16:28:09 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
      "2022-04-03 16:28:09 | INFO | fairseq_cli.preprocess | Namespace(aim_repo=None, aim_run_hash=None, align_suffix=None, alignfile=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, azureml_logging=False, bf16=False, bpe=None, cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='DATA/data-bin/synthetic', dict_only=False, empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_file=None, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, on_cpu_convert_precision=False, only_source=False, optimizer=None, padding_factor=8, plasma_path='/tmp/plasma', profile=False, quantization_config_path=None, reset_logging=False, scoring='bleu', seed=1, simul_type=None, source_lang='zh', srcdict='./DATA/data-bin/ted2020/dict.en.txt', suppress_crashes=False, target_lang='en', task='translation', tensorboard_logdir=None, testpref=None, tgtdict='./DATA/data-bin/ted2020/dict.en.txt', threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref='./DATA/rawdata/mono/mono.tok', use_plasma_view=False, user_dir=None, validpref=None, wandb_project=None, workers=10)\n",
      "2022-04-03 16:28:09 | INFO | fairseq_cli.preprocess | [zh] Dictionary: 8000 types\n",
      "2022-04-03 16:28:31 | INFO | fairseq_cli.preprocess | [zh] ./DATA/rawdata/mono/mono.tok.zh: 782527 sents, 14004837 tokens, 0.0023% replaced (by <unk>)\n",
      "2022-04-03 16:28:31 | INFO | fairseq_cli.preprocess | [en] Dictionary: 8000 types\n",
      "2022-04-03 16:28:54 | INFO | fairseq_cli.preprocess | [en] ./DATA/rawdata/mono/mono.tok.en: 782527 sents, 17428503 tokens, 0.0% replaced (by <unk>)\n",
      "2022-04-03 16:28:54 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to DATA/data-bin/synthetic\n"
     ]
    }
   ],
   "source": [
    "# Combine prediction_file (.en) and mono.zh (.zh) into a new dataset.\n",
    "# \n",
    "# hint: tokenize prediction_file with the spm model\n",
    "# spm_model.encode(line, out_type=str)\n",
    "# output: ./DATA/rawdata/mono/mono.tok.en & mono.tok.zh\n",
    "\n",
    "with open(mono_prefix/f'mono.tok.en', 'w') as out_f:\n",
    "    with open(mono_prefix / 'mono_pred.txt', 'r') as in_f:\n",
    "        for line in in_f:\n",
    "            line = line.strip()\n",
    "            tok = spm_model.encode(line, out_type=str)\n",
    "            print(' '.join(tok), file=out_f)\n",
    "\n",
    "# hint: use fairseq to binarize these two files again\n",
    "binpath = Path('./DATA/data-bin/synthetic')\n",
    "src_dict_file = './DATA/data-bin/ted2020/dict.en.txt'\n",
    "tgt_dict_file = src_dict_file\n",
    "monopref = './DATA/rawdata/mono/mono.tok' # or whatever path after applying subword tokenization, w/o the suffix (.zh/.en)\n",
    "if binpath.exists():\n",
    "    print(binpath, \"exists, will not overwrite!\")\n",
    "else:\n",
    "    !python -m fairseq_cli.preprocess\\\n",
    "        --source-lang 'zh'\\\n",
    "        --target-lang 'en'\\\n",
    "        --trainpref {monopref}\\\n",
    "        --destdir {binpath}\\\n",
    "        --srcdict {src_dict_file}\\\n",
    "        --tgtdict {tgt_dict_file}\\\n",
    "        --workers 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "MSkse1tyQnsR"
   },
   "outputs": [],
   "source": [
    "# create a new dataset from all the files prepared above\n",
    "!cp -r ./DATA/data-bin/ted2020/ ./DATA/data-bin/ted2020_with_mono/\n",
    "\n",
    "!cp ./DATA/data-bin/synthetic/train.zh-en.zh.bin ./DATA/data-bin/ted2020_with_mono/train1.en-zh.zh.bin\n",
    "!cp ./DATA/data-bin/synthetic/train.zh-en.zh.idx ./DATA/data-bin/ted2020_with_mono/train1.en-zh.zh.idx\n",
    "!cp ./DATA/data-bin/synthetic/train.zh-en.en.bin ./DATA/data-bin/ted2020_with_mono/train1.en-zh.en.bin\n",
    "!cp ./DATA/data-bin/synthetic/train.zh-en.en.idx ./DATA/data-bin/ted2020_with_mono/train1.en-zh.en.idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YVdxVGO3QrSs"
   },
   "source": [
    "Created new dataset \"ted2020_with_mono\"\n",
    "\n",
    "1. Change the datadir in **config** (\"./DATA/data-bin/ted2020_with_mono\")\n",
    "2. Switch back the source_lang and target_lang in **config** (\"en\", \"zh\")\n",
    "2. Change the savedir in **config** (eg. \"./checkpoints/transformer-bt\")\n",
    "3. Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_CZU2beUQtl3"
   },
   "source": [
    "1. <a name=ott2019fairseq></a>Ott, M., Edunov, S., Baevski, A., Fan, A., Gross, S., Ng, N., ... & Auli, M. (2019, June). fairseq: A Fast, Extensible Toolkit for Sequence Modeling. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics (Demonstrations) (pp. 48-53).\n",
    "2. <a name=vaswani2017></a>Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., ... & Polosukhin, I. (2017, December). Attention is all you need. In Proceedings of the 31st International Conference on Neural Information Processing Systems (pp. 6000-6010).\n",
    "3. <a name=reimers-2020-multilingual-sentence-bert></a>Reimers, N., & Gurevych, I. (2020, November). Making Monolingual Sentence Embeddings Multilingual Using Knowledge Distillation. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP) (pp. 4512-4525).\n",
    "4. <a name=tiedemann2012parallel></a>Tiedemann, J. (2012, May). Parallel Data, Tools and Interfaces in OPUS. In Lrec (Vol. 2012, pp. 2214-2218).\n",
    "5. <a name=kudo-richardson-2018-sentencepiece></a>Kudo, T., & Richardson, J. (2018, November). SentencePiece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing: System Demonstrations (pp. 66-71).\n",
    "6. <a name=sennrich-etal-2016-improving></a>Sennrich, R., Haddow, B., & Birch, A. (2016, August). Improving Neural Machine Translation Models with Monolingual Data. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) (pp. 86-96).\n",
    "7. <a name=edunov-etal-2018-understanding></a>Edunov, S., Ott, M., Auli, M., & Grangier, D. (2018). Understanding Back-Translation at Scale. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing (pp. 489-500).\n",
    "8. https://github.com/ajinkyakulkarni14/TED-Multilingual-Parallel-Corpus\n",
    "9. https://ithelp.ithome.com.tw/articles/10233122\n",
    "10. https://nlp.seas.harvard.edu/2018/04/03/attention.html\n",
    "11. https://colab.research.google.com/github/ga642381/ML2021-Spring/blob/main/HW05/HW05.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rrfm6iLJQ0tS"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "nKb4u67-sT_Z",
    "n1rwQysTsdJq",
    "59si_C0Wsms7",
    "oOpG4EBRLwe_",
    "6ZlE_1JnMv56",
    "UDAPmxjRNEEL",
    "ce5n4eS7NQNy",
    "rUB9f1WCNgMH",
    "VFJlkOMONsc6",
    "Gt1lX3DRO_yU",
    "BAGMiun8PnZy",
    "JOVQRHzGQU4-",
    "jegH0bvMQVmR",
    "a65glBVXQZiE",
    "smA0JraEQdxz",
    "Jn4XeawpQjLk"
   ],
   "name": "HW05.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
