{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYlaRwNu7ojq"
      },
      "source": [
        "# **Homework 2 Phoneme Classification**\n",
        "\n",
        "* Slides: https://docs.google.com/presentation/d/1v6HkBWiJb8WNDcJ9_-2kwVstxUWml87b9CnA16Gdoio/edit?usp=sharing\n",
        "* Kaggle: https://www.kaggle.com/c/ml2022spring-hw2\n",
        "* Video: TBA\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLQI0mNcmM-O",
        "outputId": "7d5b4d81-9438-4d50-8153-cd235c47ee21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fri Mar 11 01:20:27 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 511.65       Driver Version: 511.65       CUDA Version: 11.6     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  NVIDIA GeForce ... WDDM  | 00000000:09:00.0  On |                  N/A |\n",
            "|  0%   44C    P8    30W / 215W |    859MiB /  8192MiB |     19%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|    0   N/A  N/A      1720    C+G                                   N/A      |\n",
            "|    0   N/A  N/A      1892    C+G   ...5n1h2txyewy\\SearchApp.exe    N/A      |\n",
            "|    0   N/A  N/A      3092    C+G   C:\\Windows\\explorer.exe         N/A      |\n",
            "|    0   N/A  N/A      3412    C+G   ...8wekyb3d8bbwe\\GameBar.exe    N/A      |\n",
            "|    0   N/A  N/A      3980    C+G   ...LINE\\bin\\current\\LINE.exe    N/A      |\n",
            "|    0   N/A  N/A      4020    C+G   ...bbwe\\Microsoft.Photos.exe    N/A      |\n",
            "|    0   N/A  N/A      5592    C+G   ...Battle.net\\Battle.net.exe    N/A      |\n",
            "|    0   N/A  N/A      5872    C+G   ...\\app-1.0.9004\\Discord.exe    N/A      |\n",
            "|    0   N/A  N/A      6704    C+G   ...2txyewy\\TextInputHost.exe    N/A      |\n",
            "|    0   N/A  N/A      8812    C+G   ...icrosoft VS Code\\Code.exe    N/A      |\n",
            "|    0   N/A  N/A      8820    C+G   ...ge\\Application\\msedge.exe    N/A      |\n",
            "|    0   N/A  N/A      9856    C+G   ...y\\ShellExperienceHost.exe    N/A      |\n",
            "|    0   N/A  N/A     12828    C+G   ...lPanel\\SystemSettings.exe    N/A      |\n",
            "|    0   N/A  N/A     13188    C+G   ...earthstoneDeckTracker.exe    N/A      |\n",
            "|    0   N/A  N/A     13552    C+G   ...ll\\1.0.0.403\\LineCall.exe    N/A      |\n",
            "|    0   N/A  N/A     15388    C+G   ...cw5n1h2txyewy\\LockApp.exe    N/A      |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import os\n",
        "\n",
        "\n",
        "os.environ['NEPTUNE_API_TOKEN'] = \"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiJhMmJkNDllNC0yYjEzLTQwZDQtYmUyZi02YmM3MTA3YzMzZTEifQ==\"\n",
        "seed = 87                        # random seed\n",
        "\n",
        "#fix seed\n",
        "def same_seeds(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)  \n",
        "    np.random.seed(seed)  \n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "same_seeds(seed)\n",
        "# !pip install pytorch-lightning\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TlIq8JeqvvHC"
      },
      "source": [
        "## Hyper-parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "iIHn79Iav1ri"
      },
      "outputs": [],
      "source": [
        "# data prarameters\n",
        "train_ratio = 0.8  # the ratio of data used for training, the rest will be used for validation\n",
        "\n",
        "# training parameters\n",
        "batch_size = 8  # batch size\n",
        "num_epoch = 100  # maximum number of training epoch\n",
        "learning_rate = 5e-4  # learning rate\n",
        "weight_decay = 1e-3\n",
        "model_path = './model.ckpt'  # the path where the checkpoint will be saved\n",
        "early_stop_patient = 5\n",
        "\n",
        "# model parameters\n",
        "\n",
        "input_dim = 39  # the input dim of the model, you should not change the value\n",
        "hidden_layers = 3  # the number of hidden layers\n",
        "hidden_dim = 512  # the hidden dim\n",
        "bidirectional = True\n",
        "dropout = 0.3\n",
        "reconstruct_alpha = 0.\n",
        "random_swap = 10\n",
        "# pooling_method = 'attn'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVUGfWTo7_Oj"
      },
      "source": [
        "## Download Data\n",
        "Download data from google drive, then unzip it.\n",
        "\n",
        "You should have\n",
        "- `libriphone/train_split.txt`\n",
        "- `libriphone/train_labels`\n",
        "- `libriphone/test_split.txt`\n",
        "- `libriphone/feat/train/*.pt`: training feature<br>\n",
        "- `libriphone/feat/test/*.pt`:  testing feature<br>\n",
        "\n",
        "after running the following block.\n",
        "\n",
        "> **Notes: if the links are dead, you can download the data directly from [Kaggle](https://www.kaggle.com/c/ml2022spring-hw2/data) and upload it to the workspace, or you can use [the Kaggle API](https://www.kaggle.com/general/74235) to directly download the data into colab.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bj5jYXsD9Ef3"
      },
      "source": [
        "### Download train/test metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzkiMEcC3Foq",
        "outputId": "cc90c16c-ee21-400e-ec08-dfcd422212a6"
      },
      "outputs": [],
      "source": [
        "# Main link\n",
        "# !wget -O libriphone.zip \"https://github.com/xraychen/shiny-robot/releases/download/v1.0/libriphone.zip\"\n",
        "\n",
        "# # Backup Link 0\n",
        "# # !pip install --upgrade gdown\n",
        "# # !gdown --id '1o6Ag-G3qItSmYhTheX6DYiuyNzWyHyTc' --output libriphone.zip\n",
        "\n",
        "# # Backup link 1\n",
        "# # !pip install --upgrade gdown\n",
        "# # !gdown --id '1R1uQYi4QpX0tBfUWt2mbZcncdBsJkxeW' --output libriphone.zip\n",
        "\n",
        "# # Backup link 2\n",
        "# # !wget -O libriphone.zip \"https://www.dropbox.com/s/wqww8c5dbrl2ka9/libriphone.zip?dl=1\"\n",
        "\n",
        "# # Backup link 3\n",
        "# # !wget -O libriphone.zip \"https://www.dropbox.com/s/p2ljbtb2bam13in/libriphone.zip?dl=1\"\n",
        "\n",
        "# !unzip -q libriphone.zip\n",
        "# !ls libriphone"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_L_4anls8Drv"
      },
      "source": [
        "### Preparing Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "po4N3C-AWuWl"
      },
      "source": [
        "**Helper functions to pre-process the training data from raw MFCC features of each utterance.**\n",
        "\n",
        "A phoneme may span several frames and is dependent to past and future frames. \\\n",
        "Hence we concatenate neighboring phonemes for training to achieve higher accuracy. The **concat_feat** function concatenates past and future k frames (total 2k+1 = n frames), and we predict the center frame.\n",
        "\n",
        "Feel free to modify the data preprocess functions, but **do not drop any frame** (if you modify the functions, remember to check that the number of frames are the same as mentioned in the slides)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "IJjLT8em-y9G"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Dataset] - # phone classes: 41, number of utterances for train: 3428\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "3428it [00:01, 3340.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] train set\n",
            "3428 torch.Size([936, 39])\n",
            "3428 torch.Size([936])\n",
            "[Dataset] - # phone classes: 41, number of utterances for val: 858\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "858it [00:00, 3243.07it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] val set\n",
            "858 torch.Size([831, 39])\n",
            "858 torch.Size([831])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def load_feat(path):\n",
        "    feat = torch.load(path)\n",
        "    return feat\n",
        "\n",
        "\n",
        "def shift(x, n):\n",
        "    if n < 0:\n",
        "        left = x[0].repeat(-n, 1)\n",
        "        right = x[:n]\n",
        "\n",
        "    elif n > 0:\n",
        "        right = x[-1].repeat(n, 1)\n",
        "        left = x[n:]\n",
        "    else:\n",
        "        return x\n",
        "\n",
        "    return torch.cat((left, right), dim=0)\n",
        "\n",
        "\n",
        "def concat_feat(x, concat_n: int):\n",
        "    assert concat_n % 2 == 1  # n must be odd\n",
        "    if concat_n < 2:\n",
        "        return x\n",
        "    seq_len, feature_dim = x.size(0), x.size(1)\n",
        "    x = x.repeat(1, concat_n)\n",
        "    x = x.view(seq_len, concat_n,\n",
        "               feature_dim).permute(1, 0, 2)  # concat_n, seq_len, feature_dim\n",
        "    mid = (concat_n // 2)\n",
        "    for r_idx in range(1, mid + 1):\n",
        "        x[mid + r_idx, :] = shift(x[mid + r_idx], r_idx)\n",
        "        x[mid - r_idx, :] = shift(x[mid - r_idx], -r_idx)\n",
        "\n",
        "    return x.permute(1, 0, 2).view(seq_len, concat_n * feature_dim)\n",
        "\n",
        "\n",
        "def preprocess_data(split,\n",
        "                    feat_dir,\n",
        "                    phone_path,\n",
        "                    train_ratio=0.8,\n",
        "                    train_val_seed=1337):\n",
        "    class_num = 41  # NOTE: pre-computed, should not need change\n",
        "    mode = 'train' if (split == 'train' or split == 'val') else 'test'\n",
        "\n",
        "    label_dict = {}\n",
        "    if mode != 'test':\n",
        "        phone_file = open(os.path.join(phone_path,\n",
        "                                       f'{mode}_labels.txt')).readlines()\n",
        "\n",
        "        for line in phone_file:\n",
        "            line = line.strip('\\n').split(' ')\n",
        "            label_dict[line[0]] = [int(p) for p in line[1:]]\n",
        "\n",
        "    if split == 'train' or split == 'val':\n",
        "        # split training and validation data\n",
        "        usage_list = open(os.path.join(phone_path,\n",
        "                                       'train_split.txt')).readlines()\n",
        "        random.seed(train_val_seed)\n",
        "        random.shuffle(usage_list)\n",
        "        percent = int(len(usage_list) * train_ratio)\n",
        "        usage_list = usage_list[:percent] if split == 'train' else usage_list[\n",
        "            percent:]\n",
        "    elif split == 'test':\n",
        "        usage_list = open(os.path.join(phone_path,\n",
        "                                       'test_split.txt')).readlines()\n",
        "    else:\n",
        "        raise ValueError(\n",
        "            'Invalid \\'split\\' argument for dataset: PhoneDataset!')\n",
        "\n",
        "    usage_list = [line.strip('\\n') for line in usage_list]\n",
        "    print('[Dataset] - # phone classes: ' + str(class_num) +\n",
        "          ', number of utterances for ' + split + ': ' + str(len(usage_list)))\n",
        "\n",
        "    X = []\n",
        "    if mode != 'test':\n",
        "        y = []\n",
        "\n",
        "    idx = 0\n",
        "    for i, fname in tqdm(enumerate(usage_list)):\n",
        "        feat = load_feat(os.path.join(feat_dir, mode, f'{fname}.pt'))\n",
        "        cur_len = len(feat)\n",
        "        if mode != 'test':\n",
        "            label = torch.LongTensor(label_dict[fname])\n",
        "            y.append(label)\n",
        "\n",
        "        X.append(feat)\n",
        "\n",
        "        idx += cur_len\n",
        "\n",
        "    print(f'[INFO] {split} set')\n",
        "    print(len(X), X[0].shape)\n",
        "    if mode != 'test':\n",
        "        print(len(y), y[0].shape)\n",
        "        return X, y\n",
        "    else:\n",
        "        return X\n",
        "\n",
        "\n",
        "# preprocess data\n",
        "train_X, train_y = preprocess_data(split='train',\n",
        "                                   feat_dir='./libriphone/feat',\n",
        "                                   phone_path='./libriphone',\n",
        "                                   train_ratio=train_ratio)\n",
        "val_X, val_y = preprocess_data(split='val',\n",
        "                               feat_dir='./libriphone/feat',\n",
        "                               phone_path='./libriphone',\n",
        "                               train_ratio=train_ratio)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "us5XW_x6udZQ"
      },
      "source": [
        "## Define Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Fjf5EcmJtf4e"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "class LibriDataset(Dataset):\n",
        "    def __init__(self, X, y=None, num_swaps=0):\n",
        "        self.data = X\n",
        "        self.num_swaps = num_swaps\n",
        "        if y is not None:\n",
        "            self.label = y\n",
        "        else:\n",
        "            self.label = None\n",
        "        \n",
        "    def rand_swap(self, x):\n",
        "        a, b = torch.randint(0, x.shape[-1] - 1, size=(2, ))\n",
        "        x[a], x[b] = x[b], x[a]\n",
        "        return x\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        x = torch.tensor(self.data[idx])\n",
        "        \n",
        "        if self.label is not None:       \n",
        "            for _ in range(self.num_swaps):\n",
        "                x = self.rand_swap(x)\n",
        "            return x, self.label[idx]\n",
        "        else:\n",
        "            return x, None\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRqKNvNZwe3V"
      },
      "source": [
        "## Define Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Bg-GRd7ywdrL"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, dropout):\n",
        "        super(BasicBlock, self).__init__()\n",
        "\n",
        "        self.block = nn.Sequential(\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(input_dim, output_dim),\n",
        "            nn.LeakyReLU(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.block(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class AdditiveAttention(torch.nn.Module):\n",
        "    def __init__(self, in_dim=100, v_size=200):\n",
        "        super().__init__()\n",
        "\n",
        "        self.in_dim = in_dim\n",
        "        self.v_size = v_size\n",
        "        self.proj = nn.Sequential(nn.Linear(self.in_dim, self.v_size),\n",
        "                                  nn.Tanh(), nn.Linear(self.v_size, 1))\n",
        "\n",
        "    def forward(self, context):\n",
        "        \"\"\"Additive Attention\n",
        "        Args:\n",
        "            context (tensor): [B, seq_len, in_dim]\n",
        "        Returns:\n",
        "            outputs, weights: [B, seq_len, out_dim], [B, seq_len]\n",
        "        \"\"\"\n",
        "        # weights = self.proj(context) @ self.v\n",
        "        weights = self.proj(context).squeeze(-1)\n",
        "        weights = torch.softmax(weights, dim=-1)  # [B, seq_len]\n",
        "        return torch.bmm(weights.unsqueeze(1), context).squeeze(\n",
        "            1)  # [B, 1, seq_len], [B, seq_len, dim]\n",
        "\n",
        "\n",
        "class Reconstruction(nn.Module):\n",
        "    def __init__(self, hidden_dim, inp_dim, dropout) -> None:\n",
        "        super().__init__()\n",
        "        self.down = nn.Sequential(nn.Linear(hidden_dim, hidden_dim // 2),\n",
        "                                  nn.Dropout(dropout), nn.LeakyReLU(),\n",
        "                                  nn.Linear(hidden_dim // 2, inp_dim))\n",
        "\n",
        "    def forward(self, hidden: torch.Tensor, x_original: torch.Tensor):\n",
        "        hidden = self.down(hidden)\n",
        "        return F.mse_loss(hidden, x_original)\n",
        "\n",
        "\n",
        "class LstmClassifier(nn.Module):\n",
        "    def __init__(self,\n",
        "                 input_dim,\n",
        "                 output_dim=41,\n",
        "                 hidden_layers=1,\n",
        "                 hidden_dim=256,\n",
        "                 bidirectional=True,\n",
        "                 dropout=.3,\n",
        "                 reconstruct_alpha=0):\n",
        "        super().__init__()\n",
        "        self.output_dim = output_dim\n",
        "        self.reconstruct_alpha = reconstruct_alpha\n",
        "\n",
        "        self.lstm = nn.LSTM(input_dim,\n",
        "                            hidden_dim,\n",
        "                            hidden_layers,\n",
        "                            batch_first=True,\n",
        "                            bidirectional=bidirectional,\n",
        "                            dropout=dropout)\n",
        "        lstm_size = hidden_dim * 2 if bidirectional else hidden_dim\n",
        "        # self.conv1d = nn.LazyConv1d(lstm_size // 2, 5, padding=2)\n",
        "        # self.mha = nn.MultiheadAttention(input_dim, 13, dropout=dropout, batch_first=True, )\n",
        "        self.fc = nn.Sequential(BasicBlock(lstm_size, lstm_size // 4, dropout),\n",
        "                                nn.Linear(lstm_size // 4, output_dim))\n",
        "        if reconstruct_alpha > 0:\n",
        "            self.recons = Reconstruction(hidden_dim, input_dim, dropout)\n",
        "        self.loss = nn.CrossEntropyLoss()\n",
        "\n",
        "    def forward(self, x, y=None):\n",
        "        x = nn.utils.rnn.pad_sequence(x, batch_first=True)\n",
        "        hidden, _ = self.lstm(x)  # [B, maxlen, his_size]\n",
        "        # hidden, _ = self.mha(hidden, hidden, hidden)\n",
        "        # hidden_2, _ = self.mha(x, x, x)\n",
        "        # hidden = torch.cat((hidden, hidden_2), dim=-1)\n",
        "        # hidden = self.conv1d(hidden.transpose(1, 2)).transpose(1, 2)\n",
        "        logits = self.fc(hidden)\n",
        "\n",
        "        if y is None:\n",
        "            return logits\n",
        "        else:\n",
        "            y = nn.utils.rnn.pad_sequence(y,\n",
        "                                          batch_first=True,\n",
        "                                          padding_value=-1).reshape(-1)\n",
        "\n",
        "            mask = y != -1\n",
        "            logits = logits.reshape(-1, self.output_dim)[mask]\n",
        "            loss = self.loss(logits, y[mask])\n",
        "\n",
        "            if self.reconstruct_alpha != 0:\n",
        "                loss += self.reconstruct_alpha * self.recons(hidden, x)\n",
        "            return logits, loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIUFRgG5yoDn"
      },
      "source": [
        "## Prepare dataset and model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1zI3v5jyrDn",
        "outputId": "3ea2823a-83f3-42d9-ef05-2f2c002f9538"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "\n",
        "\n",
        "def my_collate(batch):\n",
        "    data = [item[0] for item in batch]\n",
        "    target = [item[1] for item in batch]\n",
        "\n",
        "    if target[0] == None:\n",
        "        return data\n",
        "    return [data, target]\n",
        "\n",
        "\n",
        "# get dataset\n",
        "train_set = LibriDataset(train_X, train_y, num_swaps=random_swap)\n",
        "val_set = LibriDataset(val_X, val_y)\n",
        "\n",
        "# remove raw feature to save memory\n",
        "del train_X, train_y, val_X, val_y\n",
        "gc.collect()\n",
        "\n",
        "# get dataloader\n",
        "train_loader = DataLoader(train_set,\n",
        "                          batch_size=batch_size,\n",
        "                          shuffle=True,\n",
        "                          collate_fn=my_collate)\n",
        "val_loader = DataLoader(val_set,\n",
        "                        batch_size=batch_size,\n",
        "                        shuffle=False,\n",
        "                        collate_fn=my_collate)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\keddy\\AppData\\Local\\Temp\\ipykernel_16552\\728591749.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(self.data[idx])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(tensor([[0.0272, 0.0172, 0.0517,  ..., 0.0401, 0.0523, 0.0224],\n",
            "        [0.0189, 0.0165, 0.0488,  ..., 0.0384, 0.0572, 0.0210],\n",
            "        [0.0218, 0.0138, 0.0558,  ..., 0.0412, 0.0526, 0.0186],\n",
            "        ...,\n",
            "        [0.0158, 0.0156, 0.0478,  ..., 0.0411, 0.0563, 0.0181],\n",
            "        [0.0162, 0.0147, 0.0530,  ..., 0.0383, 0.0546, 0.0191],\n",
            "        [0.0162, 0.0191, 0.0485,  ..., 0.0429, 0.0528, 0.0189]],\n",
            "       grad_fn=<IndexBackward0>), tensor(3.7061, grad_fn=<NllLossBackward0>))\n"
          ]
        }
      ],
      "source": [
        "model = LstmClassifier(input_dim,\n",
        "                       hidden_layers=hidden_layers,\n",
        "                       hidden_dim=hidden_dim,\n",
        "                       bidirectional=bidirectional,\n",
        "                       dropout=dropout)\n",
        "for dl in train_loader:\n",
        "    print(model(dl[0], dl[1]))\n",
        "    break\n",
        "del model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CfRUEgC0GxUV",
        "outputId": "f9804711-72b1-4717-896b-821a300cfe87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEVICE: cuda:0\n"
          ]
        }
      ],
      "source": [
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "print(f'DEVICE: {device}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "QTp3ZXg1yO9Y"
      },
      "outputs": [],
      "source": [
        "# fix random seed\n",
        "\n",
        "# create model, define a loss function, and optimizer\n",
        "# model = Classifier(input_dim=input_dim, hidden_layers=hidden_layers, hidden_dim=hidden_dim).to(device)\n",
        "# model = LstmClassifier(input_dim,\n",
        "#                        hidden_layers=hidden_layers,\n",
        "#                        hidden_dim=hidden_dim,\n",
        "#                        bidirectional=bidirectional,\n",
        "#                        dropout=dropout,\n",
        "#                        pooling_method=pooling_method).to(device)\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "# optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwWH1KIqzxEr"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdMWsBs7zzNs",
        "outputId": "17922ad2-a319-4253-8783-3e4939d0a7cf"
      },
      "outputs": [],
      "source": [
        "import pytorch_lightning as pl\n",
        "\n",
        "\n",
        "class Model(pl.LightningModule):\n",
        "    best_acc = 0.\n",
        "\n",
        "    def __init__(self, lr, weight_decay, input_dim, hidden_layers, hidden_dim,\n",
        "                 bidirectional, dropout, reconstruct_alpha):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters(\n",
        "            dict(lr=lr,\n",
        "                 weight_decay=weight_decay,\n",
        "                 input_dim=input_dim,\n",
        "                 hidden_layers=hidden_layers,\n",
        "                 hidden_dim=hidden_dim,\n",
        "                 bidirectional=bidirectional,\n",
        "                 dropout=dropout,\n",
        "                 reconstruct_alpha=reconstruct_alpha))\n",
        "        self.lr = lr\n",
        "        self.weight_decay = weight_decay\n",
        "        self.model = LstmClassifier(input_dim,\n",
        "                                    hidden_layers=hidden_layers,\n",
        "                                    hidden_dim=hidden_dim,\n",
        "                                    bidirectional=bidirectional,\n",
        "                                    dropout=dropout)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def forward(self, x):\n",
        "        self.model.eval()\n",
        "        return self.model(x)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.AdamW(self.model.parameters(),\n",
        "                                      lr=self.lr,\n",
        "                                      weight_decay=self.weight_decay)\n",
        "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer,\n",
        "                                                               20,\n",
        "                                                               eta_min=1e-5)\n",
        "        return [optimizer], [scheduler]\n",
        "\n",
        "    def training_step(self, batch, _):\n",
        "        pred, loss = self.model(batch[0], batch[1])\n",
        "        return {'loss': loss, 'preds': pred.detach(), 'ground': batch[1]}\n",
        "\n",
        "    def training_epoch_end(self, outputs):\n",
        "        loss = torch.tensor([o['loss'] for o in outputs]).reshape(-1)\n",
        "        self.log('train_mean_loss', loss.mean().item(), prog_bar=True)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def validation_step(self, batch, _):\n",
        "        pred, loss = self.model(batch[0], batch[1])\n",
        "        ground = torch.cat([b for b in batch[1]], dim=0)\n",
        "        return {'preds': pred, 'ground': ground}\n",
        "\n",
        "    def validation_epoch_end(self, outputs):\n",
        "        preds = torch.cat([o['preds'] for o in outputs], dim=0)\n",
        "        preds = preds.argmax(-1)\n",
        "        ground = torch.cat([o['ground'] for o in outputs], dim=0).reshape(-1)\n",
        "        acc = (preds == ground).sum() / len(preds)\n",
        "        self.best_acc = max(self.best_acc, acc.item())\n",
        "        self.log('val_acc', acc, prog_bar=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Hyperparmeters Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "import optuna\n",
        "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "import warnings\n",
        "from pytorch_lightning.loggers import NeptuneLogger\n",
        "\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def objective(trial: optuna.trial.Trial) -> float:\n",
        "    hidden_layers = trial.suggest_categorical('hidden_layers', [2, 3, 4])\n",
        "    hidden_dim = trial.suggest_categorical('hidden_dim', [128, 256, 384])\n",
        "    reconstruct_alpha = trial.suggest_categorical('reconstruct_alpha',\n",
        "                                                  [0, 0.2, 0.4])\n",
        "    dropout = trial.suggest_categorical('dropout', [0.2, 0.4])\n",
        "    weight_decay = trial.suggest_categorical('weight_deacay',\n",
        "                                             [1e-3, 1e-4, 5e-4, 2e-3])\n",
        "    learning_rate = trial.suggest_categorical('lr',\n",
        "                                              [1e-4, 2e-4, 5e-4, 1e-3, 2e-3])\n",
        "    model = Model(learning_rate,\n",
        "                  weight_decay,\n",
        "                  input_dim,\n",
        "                  hidden_layers=hidden_layers,\n",
        "                  hidden_dim=hidden_dim,\n",
        "                  bidirectional=bidirectional,\n",
        "                  dropout=dropout,\n",
        "                  reconstruct_alpha=reconstruct_alpha)\n",
        "    neptune_logger = NeptuneLogger(\n",
        "        project=\"aqweteddy/NTUML-HW2\",  # format \"<WORKSPACE/PROJECT>\"\n",
        "        tags=[f\"hidden_layers_{hidden_layers}\", f\"hidden_dim_{hidden_dim}\", \n",
        "              f'reconstruct_alpha_{reconstruct_alpha}', f'learning_rate_{learning_rate}'],  # optional\n",
        "        log_model_checkpoints=False\n",
        "    )\n",
        "    trainer = pl.Trainer(gpus=1,\n",
        "                         enable_progress_bar=True,\n",
        "                         max_epochs=num_epoch,\n",
        "                         reload_dataloaders_every_n_epochs=1,\n",
        "                         checkpoint_callback=False,\n",
        "                         weights_summary=None,\n",
        "                        logger=neptune_logger,\n",
        "                         callbacks=[\n",
        "                             EarlyStopping(monitor=\"val_acc\",\n",
        "                                           patience=early_stop_patient,\n",
        "                                           mode='max')\n",
        "                         ])\n",
        "    trainer.fit(\n",
        "        model,\n",
        "        train_dataloaders=train_loader,\n",
        "        val_dataloaders=val_loader,\n",
        "    )\n",
        "    neptune_logger.experiment.stop()\n",
        "    \n",
        "    return model.best_acc\n",
        "\n",
        "\n",
        "# study = optuna.create_study('sqlite:///tune.db',\n",
        "#                             direction=\"maximize\",\n",
        "#                             load_if_exists=True,\n",
        "#                             study_name='lstm_seq')\n",
        "# study.optimize(objective, n_trials=20)\n",
        "# print(f'best_trial: {study.best_trial.value}')\n",
        "# print(f'best_params:')\n",
        "# for key, value in study.best_trial.params.items():\n",
        "#     print(\"    {}: {}\".format(key, value))\n",
        "# params = study.best_trial.params"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name  | Type           | Params\n",
            "-----------------------------------------\n",
            "0 | model | LstmClassifier | 7.0 M \n",
            "-----------------------------------------\n",
            "7.0 M     Trainable params\n",
            "0         Non-trainable params\n",
            "7.0 M     Total params\n",
            "27.948    Total estimated model params size (MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 26: 100%|██████████| 537/537 [01:57<00:00,  4.57it/s, loss=0.265, v_num=11, val_acc=0.836, train_mean_loss=0.249]\n"
          ]
        }
      ],
      "source": [
        "params =  {'hidden_layers': 5, 'hidden_dim': 256, 'reconstruct_alpha': 0, 'dropout': 0.4, 'weight_decay': 0.0001, 'lr': 0.002}\n",
        "model = Model(params['lr'],\n",
        "              params['weight_decay'],\n",
        "              input_dim,\n",
        "              hidden_layers=params['hidden_layers'],\n",
        "              hidden_dim=params['hidden_dim'],\n",
        "              bidirectional=bidirectional,\n",
        "              dropout=params['dropout'],\n",
        "              reconstruct_alpha=params['reconstruct_alpha'])\n",
        "# model = Model(learning_rate,\n",
        "#               weight_decay,\n",
        "#               input_dim,\n",
        "#               hidden_layers=hidden_layers,\n",
        "#               hidden_dim=hidden_dim,\n",
        "#               bidirectional=bidirectional,\n",
        "#               dropout=dropout,\n",
        "#               reconstruct_alpha=reconstruct_alpha)\n",
        "checkpoint_callback = ModelCheckpoint(monitor=\"val_acc\",\n",
        "                                      save_top_k=2,\n",
        "                                      mode='max')\n",
        "trainer = pl.Trainer(gpus=1,\n",
        "                     enable_progress_bar=True,\n",
        "                     max_epochs=num_epoch,\n",
        "                     reload_dataloaders_every_n_epochs=1,\n",
        "                     callbacks=[\n",
        "                         EarlyStopping(monitor=\"val_acc\",\n",
        "                                       patience=early_stop_patient,\n",
        "                                       mode='max'), checkpoint_callback\n",
        "                     ])\n",
        "trainer.fit(\n",
        "    model,\n",
        "    train_dataloaders=train_loader,\n",
        "    val_dataloaders=val_loader,\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Hi7jTn3PX-m"
      },
      "source": [
        "## Testing\n",
        "Create a testing dataset, and load model from the saved checkpoint."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOG1Ou0PGrhc",
        "outputId": "abaaa25b-a93c-49b0-d228-9eca1e2ab2e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Dataset] - # phone classes: 41, number of utterances for test: 1078\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "1078it [00:00, 3703.54it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] test set\n",
            "1078 torch.Size([818, 39])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# load data\n",
        "test_X = preprocess_data(split='test',\n",
        "                         feat_dir='./libriphone/feat',\n",
        "                         phone_path='./libriphone')\n",
        "test_set = LibriDataset(test_X, None)\n",
        "test_loader = DataLoader(test_set,\n",
        "                         batch_size=batch_size,\n",
        "                         shuffle=False,\n",
        "                         collate_fn=my_collate)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ay0Fu8Ovkdad",
        "outputId": "e5b20aa7-4d8b-43a9-e068-f5c89706a360"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Model(\n",
              "  (model): LstmClassifier(\n",
              "    (lstm): LSTM(39, 256, num_layers=5, batch_first=True, dropout=0.4, bidirectional=True)\n",
              "    (fc): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (block): Sequential(\n",
              "          (0): Dropout(p=0.4, inplace=False)\n",
              "          (1): Linear(in_features=512, out_features=128, bias=True)\n",
              "          (2): LeakyReLU(negative_slope=0.01)\n",
              "        )\n",
              "      )\n",
              "      (1): Linear(in_features=128, out_features=41, bias=True)\n",
              "    )\n",
              "    (loss): CrossEntropyLoss()\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# load model\n",
        "best_path = checkpoint_callback.best_model_path\n",
        "model.load_from_checkpoint(best_path)\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zp-DV1p4r7Nz"
      },
      "source": [
        "Make prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84HU5GGjPqR0",
        "outputId": "cebd6694-8f74-44ff-f922-96ca4385acb8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 135/135 [00:13<00:00, 10.18it/s]\n"
          ]
        }
      ],
      "source": [
        "test_acc = 0.0\n",
        "test_lengths = 0\n",
        "pred = []\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for i, batch in enumerate(tqdm(test_loader)):\n",
        "        features = batch\n",
        "        features = [f.to(device) for f in features]\n",
        "\n",
        "        outputs = model(features)\n",
        "\n",
        "        _, test_pred = torch.max(\n",
        "            outputs,\n",
        "            -1)  # get the index of the class with the highest probability\n",
        "        for p, f in zip(test_pred, features):\n",
        "            p = p[:len(f)]\n",
        "            pred.extend(p.detach().cpu().tolist())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wyZqy40Prz0v"
      },
      "source": [
        "Write prediction to a CSV file.\n",
        "\n",
        "After finish running this block, download the file `prediction.csv` from the files section on the left-hand side and submit it to Kaggle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "GuljYSPHcZir"
      },
      "outputs": [],
      "source": [
        "with open('prediction.csv', 'w') as f:\n",
        "    f.write('Id,Class\\n')\n",
        "    for i, y in enumerate(pred):\n",
        "        f.write('{},{}\\n'.format(i, y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "ML2022Spring - HW2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
